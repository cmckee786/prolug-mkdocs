{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<ul> <li> <p> ProLUG</p> <p>Welcome to The Professional Linux Users Group, hopefully this stuff is useful to ya</p> <p> Getting started</p> </li> <li> <p> Killer Coda Labs</p> <p>Many of the labs in the course material leverage Killer Coda</p> <p> Killer Coda</p> </li> <li> <p> Linux Course</p> <p>The ProLUG Linux Administration course, designed to build foundational knowledge in Linux</p> <p> Admin Course</p> </li> <li> <p> Security Course</p> <p>The ProLUG Linux Security course, an advanced course that focuses on systems security</p> <p> Security Course</p> </li> </ul>"},{"location":"#in-the-beginning","title":"In the Beginning","text":"<p>Founded approximately 15 years ago, the Professional Linux User Group (ProLUG) began as a vision of Het Tanis, known by his community alias 'Scott Champine.' Het identified the need for an informal yet structured space where Linux professionals could share knowledge, collaborate, and grow together. What started as local in-person meetups quickly gained traction, thanks to the increasing demand for open-source collaboration and the widespread adoption of Linux in both enterprises and personal projects.</p>"},{"location":"#why-prolug-started","title":"Why ProLUG Started","text":"<p>ProLUG was born out of the recognition that Linux professionals often face challenges that are best solved through peer collaboration and hands-on experience. The community\u2019s founding principles were rooted in creating an environment where newcomers could learn from experienced professionals, and seasoned users could gain exposure to advanced topics and emerging technologies. Its core mission was simple yet impactful: to provide continuous growth opportunities in Linux system administration, automation, and cloud technologies.</p> <p>Some of the key motivations behind ProLUG's formation include:</p> <ul> <li>Peer Support: Helping members solve technical challenges through discussion and advice from experts.</li> <li>Knowledge Sharing: Encouraging open sharing of tips, tricks, configurations, and scripts related to Linux and open-source tools.</li> <li>Hands-on Learning: Providing access to practical labs, exercises, and real-world scenarios for hands-on training.</li> <li>Community Mentorship: Offering a space for members to mentor and be mentored by others in different stages of their careers.</li> <li>Certification Prep: Assisting members in preparing for recognized industry certifications.</li> </ul>"},{"location":"#the-expansion-into-an-online-community","title":"The Expansion into an Online Community","text":"<p>While initially focused on local in-person meetings, ProLUG embraced online platforms to extend its reach globally. The switch to a virtual model enabled:</p> <ul> <li>Global Networking: Professionals and enthusiasts from around the world could now connect, learn, and collaborate without geographical limitations.</li> <li>24/7 Discussion: Via platforms like Discord, members could share insights, discuss Linux problems, and exchange ideas anytime, anywhere.</li> <li>Greater Diversity: The online expansion diversified the member base, incorporating individuals from various industries and technical backgrounds, creating a rich environment for problem-solving.</li> </ul>"},{"location":"#interactive-labs-and-training-programs","title":"Interactive Labs and Training Programs","text":"<p>One of ProLUG\u2019s most successful expansions has been its focus on interactive, hands-on labs. To bridge the gap between theory and practice, Het Tanis launched a series of labs on platforms like Killercoda, covering a variety of topics including:</p> <ul> <li>Linux Essentials and System Administration</li> <li>Ansible Automation</li> <li>Kubernetes and Container Orchestration</li> <li>Security and Network Hardening</li> </ul> <p>With over 50 interactive labs available and more being continuously developed, members benefit from practical scenarios that simulate real-world challenges. The labs cater to beginners, intermediates, and experts, ensuring everyone has something to gain.</p>"},{"location":"#certification-and-career-development","title":"Certification and Career Development","text":"<p>In 2024, ProLUG launched its first structured certification course: Enterprise Linux Administration. This program was designed to provide a comprehensive curriculum covering topics such as:</p> <ul> <li>Advanced Linux system configuration</li> <li>Enterprise networking and services</li> <li>Security management</li> <li>Scripting and automation</li> </ul> <p>The first cohort of graduates successfully completed the program in January 2025, marking a major milestone in ProLUG\u2019s commitment to professional development. Many graduates have reported success stories, such as landing new jobs, securing promotions, or gaining confidence in their Linux expertise.</p>"},{"location":"#what-is-a-user-group","title":"What is a User Group?","text":"<p>A user group is a community of individuals who come together to share common interests, typically in a specific area of technology, such as Linux. These groups can be local or online and serve as platforms for:</p> <ul> <li>Collaboration: Members work together to troubleshoot, build projects, and share experiences.</li> <li>Networking: Opportunities to connect with professionals, mentors, and employers within the field.</li> <li>Learning: Workshops, presentations, and discussions that cover new and emerging technologies.</li> <li>Career Growth: Access to resources, training programs, and job opportunities.</li> </ul> <p>ProLUG is a prime example of how a user group can grow beyond its initial purpose, evolving into a vibrant global community with practical learning opportunities and real-world outcomes.</p>"},{"location":"#success-stories","title":"Success Stories","text":"<p>Being part of ProLUG has proven highly beneficial for many members, with success stories ranging from career advancements to personal growth:</p> <ul> <li>Job Opportunities: Members have found jobs in system administration, DevOps, and cloud engineering roles through networking within ProLUG.</li> <li>Certifications: Many members have successfully obtained Linux-related certifications, including RHCSA, RHCE, and LFCS, using ProLUG\u2019s resources and mentorship programs.</li> <li>Skill Development: Through interactive labs and group discussions, members have honed skills in automation (Ansible), scripting (Bash, Python), containerization (Docker, Kubernetes), and more.</li> <li>Mentorship Relationships: Senior professionals have mentored newcomers, creating a cycle of continuous learning and knowledge sharing.</li> </ul>"},{"location":"#current-milestones","title":"Current Milestones","text":"<ul> <li>3,000+ Members: ProLUG\u2019s global community continues to grow rapidly, attracting Linux enthusiasts and professionals from various backgrounds.</li> <li>50+ Interactive Labs: Covering diverse topics, from basic Linux administration to advanced enterprise systems management.</li> <li>Ongoing Training Programs: Continuous updates to certification preparation courses, interactive workshops, and guided lab exercises.</li> </ul> <p>ProLUG\u2019s commitment to fostering a collaborative environment has made it a go-to community for anyone interested in Linux. Whether you're a beginner looking to learn the basics or an experienced professional aiming to advance your career, ProLUG offers a pathway to success.</p>"},{"location":"lac/contributing/","title":"Contributing","text":"<p>The Professional Linux Users Group (ProLUG) provides a set of requirements and guidelines to contribute to this project. Below are steps to ensure contributors are adhering to those guidelines and fostering a productive version control environment.</p>"},{"location":"lac/contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How to be a Successful Contributor</li> <li>Signing your Git Commits with SSH</li> <li>Syncing your Fork with the Upstream ProLUG Repo</li> <li>Basic Contribution Workflow</li> <li>Comment First</li> <li>Create a Fork</li> <li>Clone the Fork to your Local Machine</li> <li>Create a New Branch</li> <li>Understand a few Best Practices</li> <li>Commit and Push your Changes</li> <li>Comment your Changes</li> <li>Create a Pull Request</li> <li>Supporting Material</li> </ul>"},{"location":"lac/contributing/#how-to-be-a-successful-contributor","title":"How to be a Successful Contributor","text":"<p>To be an effective contributor understanding Git, whether through the command line or an external tool, will be an important part of contributing. To this effect it is important that any individual who contributes to this project have a working understanding of committing, merging, and other fundamental Git workflows.</p> <p>For clarity this project utilizes GitHub for remote repositories and CI/CD testing pipeline workflows. Git and GitHub are two separate entities where GitHub provides the hosting services and Git provides the version control.</p> <p>Prospective contributors are directed to several resources should they feel their competency with Git or GitHub falls short:</p> <p>Git documentation:</p> <ul> <li>https://git-scm.com/doc</li> </ul> <p>Git and GitHub video tutorials:</p> <ul> <li>ByteByteGo's Git Explained in 4 Minutes (4m)</li> <li>Fireship's How to use Git and Github (12m)</li> <li>freeCodeCamp's Git and GitHub Crash Course (1hr)</li> </ul>"},{"location":"lac/contributing/#signing-your-git-commits-with-ssh","title":"Signing your Git Commits with SSH","text":"<p>Contributors who elect to contribute through the command line will need to verify their identities before their commits can be accepted. This step is not required if contributors will be submitting changes via GitHub.com itself since users will have verified their identities with GitHub's own verification process.</p> <p>To reiterate, individuals contributing via command line will need to sign their commits through SSH. Signing GitHub commits helps ProLUG validate incoming commits from trusted contributors that reside outside the GitHub ecosystem. It can be quite trivial to impersonate users on GitHub and it is in the best interest of the project and contributors to observe this security practice.</p> <p>It should also be noted that GitHub supplies tools like GitHub CLI that abstract away the process of signing and verifying commits from the command line. GitHub provides a <code>gh auth login</code> function to facilitate the procedure which contributors can employ without the necessary changes suggested below.</p> <p>To Sign your Git Commits with SSH:</p> <p>Generate an SSH key pair if you don't have one:</p> <pre><code>ssh-keygen -t ed25519\n</code></pre> <p>Add SSH public key ('.pub' suffix) to GitHub as \"Signing Key\". </p> <p>* GitHub.com -&gt; Profile -&gt; Settings -&gt; GPG and SSH Keys -&gt; Add SSH Key -&gt; Drop down -&gt; Signing Key</p> <p>Below is a bash script that will attempt to configure signing Git commits on a localhost:</p> <pre><code>#!/bin/bash\nGH_USERNAME=\"YourUsername\"\ngit config --global gpg.format ssh\ngit config --global user.signingkey ~/.ssh/id_ed25519.pub\ngit config --global tag.gpgSign true\ngit config --global commit.gpgSign true\nmkdir -p ~/.config/git\ntouch ~/.config/git/allowed_signers\necho \"${GH_USERNAME} $(cat ~/.ssh/id_ed25519.pub)\" &gt; ~/.config/git/allowed_signers\ngit config --global gpg.ssh.allowedSignersFile ~/.config/git/allowed_signers\n# Make a commit to verify\ngit log --show-signature -1\n</code></pre> <p>Make a commit after running those commands and then use <code>git log --show-signature -1</code>. You should see something like <code>Good \"git\" signature for &lt;yourname&gt; with ED25519 key SHA256:abcdef...</code> if it worked.</p> <p></p> <p>Your commits should now be verified from your account. This helps us ensure that valid users are contributing to this project. Unverified commits will be scrutinized and likely discarded.</p>"},{"location":"lac/contributing/#syncing-your-fork-with-the-upstream-prolug-repo","title":"Syncing your Fork with the Upstream ProLUG Repo","text":"<p>In an effort to minimize merge conflicts we strongly suggest forks remain up to date with the original repository before committing changes. This will help us reduce pull request management overhead.</p>  Pull requests with substantial merge conflicts may be rejected.  <p>You can do this from the GitHub web UI easily with the <code>Sync Fork</code> button. If you want to do this from the terminal, you can add a new <code>git remote</code> called <code>upstream</code>.</p> <pre><code>git remote add upstream https://github.com/ProfessionalLinuxUsersGroup/lac.git\n</code></pre> <p>Then, to sync your local fork with the original repo, do a <code>git pull</code> from the <code>upstream</code> remote.</p> <pre><code>git pull upstream main\n</code></pre> <p>This fork should now be up to date with the original upstream repository.</p>"},{"location":"lac/contributing/#basic-contribution-workflow","title":"Basic Contribution Workflow","text":"<p>You'll create your own fork of the repository using the GitHub web UI, create a branch, make changes, push to your fork, then open a pull request.</p>"},{"location":"lac/contributing/#comment-first","title":"Comment First","text":"<p>If you'd like to work on a specific worksheet or lab, please let us know first by commenting on the issue so you can be assigned to it. This way, other contributors can see that someone is already working on it.</p> <p>This helps the repository maintainers and contributors attain a high degree of visibility and collaboration before merging changes.</p>"},{"location":"lac/contributing/#create-a-fork","title":"Create a Fork","text":"<p>Go to the original repository link. Click on \"Fork\" on the top right. Now you'll have your own version of the repository that you can clone.</p> <pre><code>git clone git@github.com:YOUR_USERNAME/lac.git\n# Or, with https:\ngit clone https://github.com/YOUR_USERNAME/lac.git\n</code></pre>"},{"location":"lac/contributing/#clone-the-fork-to-your-local-machine","title":"Clone the Fork to your Local Machine","text":"<p>Then you'll need to clone your fork down to your local machine in order to work on it.</p> <pre><code>git clone git@github.com:yourname/lac.git\n</code></pre>"},{"location":"lac/contributing/#create-a-new-branch","title":"Create a New Branch","text":"<p>Whenever making changes contributors are highly encouraged to create a branch with an appropriate name. Switch to that branch, then make changes there.</p> <p>For example, if you're working on the Unit 1 Worksheet:</p> <pre><code>git branch unit1-worksheet\ngit switch unit1-worksheet\n# Or, simply:\ngit switch -c unit1-worksheet\n</code></pre> <p>Make changes to the <code>u1ws.md</code>.</p>"},{"location":"lac/contributing/#consider-a-few-useful-practices","title":"Consider a few Useful Practices","text":"<p>The practices presented below are not required to contribute to the ProLUG course books but can streamline contributing to any project and are considered to some as best practice or incredibly useful when engaging in version control with Git.</p>"},{"location":"lac/contributing/#git-rebasing","title":"Git Rebasing","text":"FIRST AND FOREMOST, ONLY REBASE IN LOCAL REPOSITORIES. NEVER REBASE   A PUBLIC BRANCH OR REPOSITORY UNLESS YOU FULLY UNDERSTAND THE CONSEQUENCES.   YOU HAVE BEEN WARNED. <p>Proper implementation of rebasing can leave a clean, and easily readable commit history for all concerned parties. Rebasing can also facilitate the management of branches and working directories in a notably active project.</p> <p>The Git documentation provides a succinct explanation of its utility but also how it could potentially ruin a project and erase the work of other contributors.</p> <p>Rebasing also plays a role in facilitating any commit reverts that may need to be made in the future. More on that will follow.</p> USE REBASING WISELY <p>Git Rebasing documentation: https://git-scm.com/book/en/v2/Git-Branching-Rebasing</p>"},{"location":"lac/contributing/#commit-early-often-and-squashing-commits","title":"Commit Early, Often, and Squashing Commits","text":"<p>It is great practice to commit early, and often. This however can produce hard to read commits for repo maintainers and contributors. Squashing commits, which is a type of rebasing, can be utilized to compress a large number of commits made in a local repository before being pushed into a remote repository and eventual pull requests.</p> <p>Below is an example of 4 local commits squashed into a single commit that was pushed remotely:</p> <p></p> <p>Squashing commits can improve readability, but its primary utility, especially for larger projects, may be in addressing an event where rolling back several commits due to a bug or test can be done with a single commit revert.</p> <p>freeCodeCamp has a great write-up on this procedure. When done appropriately this can greatly facilitate the development process. Contributors are strongly encouraged to begin exploring these types of workflows if they never have.</p> AGAIN, USE REBASING AND SQUASHING WISELY"},{"location":"lac/contributing/#git-stashing","title":"Git Stashing","text":"<p>Another useful practice is to employ \"stashing\" uncommitted files in a local repository. This is useful in many contexts including stashing local changes to resolve recently introduced remote vs. local repo conflicts, or quickly switching working spaces.</p> <p>Stashing effectively unstages any changes made in the local repo and saves them to be applied later. This can further help facilitate a rebase or merge before committing changes upstream for instance.</p> <p>More on this here:</p> <p>https://www.atlassian.com/git/tutorials/saving-changes/git-stash</p> <p>https://git-scm.com/book/en/v2/Git-Tools-Stashing-and-Cleaning</p>"},{"location":"lac/contributing/#commit-and-push-your-changes","title":"Commit and Push your Changes","text":"<p>First make sure your forked repo is up-to-date with the original. Create your commit (make sure it's signed!), then push changes to your own fork on the new branch.</p> <pre><code>git commit -m \"descriptive commit message\"\ngit push origin unit1-worksheet\n</code></pre>"},{"location":"lac/contributing/#comment-your-changes","title":"Comment your Changes","text":"<p>Before creating a pull request, make a comment on the issue containing your changes. We're doing this since the GitHub organization feature is paid and we are doing this for free, so there is only one person who is able to merge pull requests at the moment.</p>"},{"location":"lac/contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Now you'll be able to go to the original repository link and go to the \"Pull Requests\" tab and create a new pull request. Select your branch <code>unit1-worksheet</code>, and create a description and mention an issue by number (e.g., <code>#5</code>).</p>"},{"location":"lac/contributing/#supporting-material","title":"Supporting Material","text":"<p>Below are links to the necessary materials to build out the course templates:</p> <ul> <li>Look over the template pages wiki, or directly here:</li> <li>Pages: intro,     bonus,     lab,     worksheet</li> </ul> <p>Ancillary unit videos provided by Scott:</p> <ul> <li>https://www.youtube.com/watch?v=eHB8WKWz2eQ&amp;list=PLyuZ_vuAWmprPIqsG11yoUG49Z5dE5TDu</li> </ul> <p>PDF and docs directly related to each Unit of the course:</p> <ul> <li>https://discord.com/channels/611027490848374811/1098309490681598072</li> </ul>"},{"location":"lac/contributors/","title":"Contributors","text":""},{"location":"lac/contributors/#under-construction","title":"Under Construction","text":""},{"location":"lac/development/","title":"Development","text":"<p>It is strongly encouraged that contributors test their changes before making commits. To help facilitate this process a set of instructions and guidelines are provided below. These guidelines are by no means a requirement or the only set of procedures to locally develop on this project.</p> <p>The examples, code, and commands provided below were developed using such technologies as Ansible, containers, bash scripts, and more.</p>"},{"location":"lac/development/#build-dependencies","title":"Build Dependencies","text":"<p>The ProLUG Linux Administration Course (LAC) utilizes mdBook (markdown Book), a friendly and popular markdown utility that quickly exports files and web structures for documentation or general website use cases.</p> <p>Utilizing mdBook this course then deploys the exported web structure to a Git Pages workflow and runner that then produces an easily navigable website.</p> <p>Below is the current workflow that deploys the Git Page for the course:</p> <p>To achieve this deployment locally the following environment and dependencies are required:</p> 1. A localhost, this could be a container, virtual machine, or local machine 2. The following packages installed on such machine: - httpd or apache - git - gcc - rust - cargo 3. And a clone of a ProLUG repository"},{"location":"lac/development/#building-deploying-and-developing-locally","title":"Building, Deploying, and Developing Locally","text":"<p>Below is a set of scripts and Ansible-Playbooks that can quickly achieve this environment in an automated fashion. They are only designed to \"standup\" these machines, they are otherwise unintelligent and will not manage or cleanup environments if things go awry.</p>"},{"location":"lac/development/#ansible-playbook","title":"Ansible-Playbook","text":"<p>https://github.com/ProfessionalLinuxUsersGroup/lac/blob/main/src/assets/deploy/ansible-playbook.yml</p> <p>To use this playbook, your machine(s)/containers must be configured correctly for Ansible. If you don't know the requirements to administer a machine via Ansible documentation has been provided below.</p>  This playbook will need to be modified based on which distribution or package management tool is configured.  <p>Getting started with Ansible: https://docs.ansible.com/ansible/latest/getting_started/index.html</p>"},{"location":"lac/development/#bash-script","title":"Bash Script","text":"<p>Many of these commands assume a root user.</p> <p>Export and execute this script to your machine/container.</p>   Dependencies can total over ~500MB compressed and 1-2GB unpackaged or more.  Debian containers/machines will require building many of these packages from source or adding additional repositories as Debian has a far slower package version adoption rate for stability, thus is not recommended for deploying mdBook.   <p>These scripts will take up to 5-7 minutes to download the necessary dependencies and compile mdBook depending on the machine/container's capabilities.</p> <p>Tested with Rocky 9 and Ubuntu 24.04 Containers.</p> <p>APT frontends:</p> <pre><code>#!/usr/bin/env bash\napt-get update\napt-get -y install apache2 git gcc rustc-1.80 cargo-1.80\ncargo-1.80 install --locked mdbook\nsystemctl enable apache2 &amp;&amp; systemctl start apache2\ncd &amp;&amp; git clone https://github.com/ProfessionalLinuxUsersGroup/lac\necho 'PATH=$PATH:~/.cargo/bin/' | tee -a ~/.profile\nexport PATH=$PATH:~/.cargo/bin/ &amp;&amp; echo $PATH\ncd ~/lac &amp;&amp; mdbook build -d /var/www/html\nsystemctl restart apache2\n</code></pre> <p>DNF frontends:</p> <pre><code>#!/usr/bin/env bash\ndnf update\ndnf install -y httpd git gcc rust cargo\ncargo install --locked mdbook\nsystemctl enable httpd &amp;&amp; systemctl start httpd\ncd &amp;&amp; git clone https://github.com/ProfessionalLinuxUsersGroup/lac\necho 'PATH=$PATH:~/.cargo/bin/' | tee -a ~/.bash_profile\nexport PATH=$PATH:~/.cargo/bin/ &amp;&amp; echo $PATH\ncd ~/lac &amp;&amp; mdbook build -d /var/www/html\nsystemctl restart httpd\n</code></pre>"},{"location":"lac/development/#from-here-you-can-use-such-commands-from-your-localhost-to-implement-changes","title":"From here you can use such commands from your localhost to implement changes:","text":"<pre><code>cd {working lac directory} #for example: /root/lac or ~/lac\nmdbook build -d /var/www/html\nsystemctl restart {httpd or apache}\n</code></pre> <p>These commands will switch your shell into the appropriate directory, execute the necessary cargo binaries located in its installed PATH, build the mdBook from any files that were changed, and then finally restart the web server.</p> <p>From there you should be able to see any changes you have made are reflected.</p>"},{"location":"lac/development/#or-send-commands-over-to-a-networked-container-or-machine","title":"Or send commands over to a networked container or machine:","text":"<p>Note: To minimize complexity and given the nature of commands over SSH, these commands will need to utilize absolute paths.</p> <pre><code>scp {working directory}/{targeted document} {TARGET_IP}:/root/lac/src/{targeted document}\nssh {TARGET_IP} \"cd /root/lac &amp;&amp; ~/.cargo/bin/mdbook build -d /var/www/html &amp;&amp; systemctl restart httpd\"\n</code></pre> <p>An example of the workflow after making changes:</p> <pre><code>scp src/development.md 172.16.15.8:/root/lac/src/\nssh 172.16.15.8 \"cd /root/lac &amp;&amp; ~/.cargo/bin/mdbook build -d /var/www/html &amp;&amp; systemctl restart httpd\"\n</code></pre> <p></p>"},{"location":"lac/downloads/","title":"Downloads","text":""},{"location":"lac/downloads/#unit-1","title":"Unit 1","text":""},{"location":"lac/downloads/#-download-txt-worksheet","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-txt-lab","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-lab","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#unit-2","title":"Unit 2","text":""},{"location":"lac/downloads/#-download-txt-worksheet_1","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_1","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-txt-lab_1","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_1","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#unit-3","title":"Unit 3","text":""},{"location":"lac/downloads/#-download-txt-worksheet_2","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_2","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-pdf-lab_1","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_2","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_2","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#unit-4","title":"Unit 4","text":""},{"location":"lac/downloads/#-download-txt-worksheet_3","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_3","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-pdf-lab_2","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_3","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_3","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#unit-5","title":"Unit 5","text":""},{"location":"lac/downloads/#-download-pdf-lab_3","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_4","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_4","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-worksheet_4","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_4","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-6","title":"Unit 6","text":""},{"location":"lac/downloads/#-download-txt-worksheet_5","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_5","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-txt-lab_5","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_5","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-lab_4","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#unit-7","title":"Unit 7","text":""},{"location":"lac/downloads/#-download-pdf-lab_5","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_6","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_6","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-worksheet_6","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_6","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-8","title":"Unit 8","text":""},{"location":"lac/downloads/#-download-txt-worksheet_7","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_7","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-lab_7","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_7","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#unit-9","title":"Unit 9","text":""},{"location":"lac/downloads/#-download-pdf-worksheet","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_8","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-txt-worksheet_8","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-pdf-lab_6","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_8","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-txt-lab_8","title":"- \ud83d\udce5 Download (<code>.txt</code>) - Lab","text":""},{"location":"lac/downloads/#unit-10","title":"Unit 10","text":""},{"location":"lac/downloads/#-download-docx-lab_9","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-lab_7","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-worksheet_9","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_1","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-11","title":"Unit 11","text":""},{"location":"lac/downloads/#-download-pdf-lab_8","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_10","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-worksheet_10","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_2","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-12","title":"Unit 12","text":""},{"location":"lac/downloads/#-download-docx-lab_11","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-lab_9","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_3","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_11","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-13","title":"Unit 13","text":""},{"location":"lac/downloads/#-download-pdf-lab_10","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_12","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_4","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_12","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-14","title":"Unit 14","text":""},{"location":"lac/downloads/#-download-pdf-lab_11","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_13","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_5","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_13","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-15","title":"Unit 15","text":""},{"location":"lac/downloads/#-download-pdf-lab_12","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/downloads/#-download-docx-lab_14","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-worksheet_6","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Worksheet","text":""},{"location":"lac/downloads/#-download-docx-worksheet_14","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Worksheet","text":""},{"location":"lac/downloads/#unit-16","title":"Unit 16","text":""},{"location":"lac/downloads/#-download-docx-lab_15","title":"- \ud83d\udce5 Download (<code>.docx</code>) - Lab","text":""},{"location":"lac/downloads/#-download-pdf-lab_13","title":"- \ud83d\udce5 Download (<code>.pdf</code>) - Lab","text":""},{"location":"lac/outro/","title":"Outro","text":""},{"location":"lac/outro/#under-construction","title":"Under Construction","text":""},{"location":"lac/project/","title":"Project","text":"<p>Students aiming to complete the Linux Systems Administration course are expected to devise and complete a capstone project, to be turned in at the end of the course.</p> <p>The instructions, expectations, and deliverables for the project are listed on this page.</p>"},{"location":"lac/project/#instructions","title":"Instructions","text":"<ol> <li>Select a topic to research about a project that you are going to build.</li> </ol> <p>Topics:</p> <ol> <li>System Stability</li> <li>System Performance</li> <li>System Security</li> <li>System monitoring</li> <li>Kubernetes</li> <li> <p>Programming/Automation</p> </li> <li> <p>Plan the project</p> </li> <li>Find documentation or similar projects and build off of what was done there.</li> <li>Document</li> <li>First pass, what does it take to build this?</li> <li>Diagram</li> <li>Draw the thing<ol> <li>Excalidraw.com</li> <li>Draw.io</li> </ol> </li> <li>Build</li> <li>Get screen shots</li> <li>Make a video?</li> <li>Basically prove you built it.</li> <li>Finalize documentation</li> <li>Redline the documentation</li> <li> <p>Prepare to Present (overleaf.com is a great alternative to Powerpoint)</p> </li> <li> <p>Setup a 15-20 slide deck on what you did</p> <ol> <li>Project purpose</li> <li>Diagram</li> <li>Build Process</li> <li>What did you learn?</li> <li>How are you going to apply this?</li> </ol> </li> <li> <p>Do any of you want to present?</p> </li> <li>Let me (Scott) know and we\u2019ll get you a slot in the last few weeks.</li> </ol>"},{"location":"lac/project/#deliverables","title":"Deliverables","text":"<ol> <li> <p>Build Documentation for your project that works in either the ProLUG labs, or in    the Killercoda environment.</p> </li> <li> <p>A diagram of what you built. This should be both a physical and a logical    representation of the system (if applicable).</p> </li> <li> <p>Examples of the running system, screen shots, or other proof that you built it and    show it in a running state.</p> </li> <li> <p>A 15-20 slide presentation of the above material that you would present to a group (presenting    to us is voluntary, but definitely possible.)</p> </li> </ol>"},{"location":"lac/prolug/","title":"Prolug","text":""},{"location":"lac/prolug/#in-the-beginning","title":"In the Beginning","text":"<p>Founded approximately 15 years ago, the Professional Linux User Group (ProLUG) began as a vision of Het Tanis, known by his community alias 'Scott Champine.' Het identified the need for an informal yet structured space where Linux professionals could share knowledge, collaborate, and grow together. What started as local in-person meetups quickly gained traction, thanks to the increasing demand for open-source collaboration and the widespread adoption of Linux in both enterprises and personal projects.</p>"},{"location":"lac/prolug/#why-prolug-started","title":"Why ProLUG Started","text":"<p>ProLUG was born out of the recognition that Linux professionals often face challenges that are best solved through peer collaboration and hands-on experience. The community\u2019s founding principles were rooted in creating an environment where newcomers could learn from experienced professionals, and seasoned users could gain exposure to advanced topics and emerging technologies. Its core mission was simple yet impactful: to provide continuous growth opportunities in Linux system administration, automation, and cloud technologies.</p> <p>Some of the key motivations behind ProLUG's formation include:</p> <ul> <li>Peer Support: Helping members solve technical challenges through discussion and advice from experts.</li> <li>Knowledge Sharing: Encouraging open sharing of tips, tricks, configurations, and scripts related to Linux and open-source tools.</li> <li>Hands-on Learning: Providing access to practical labs, exercises, and real-world scenarios for hands-on training.</li> <li>Community Mentorship: Offering a space for members to mentor and be mentored by others in different stages of their careers.</li> <li>Certification Prep: Assisting members in preparing for recognized industry certifications.</li> </ul>"},{"location":"lac/prolug/#the-expansion-into-an-online-community","title":"The Expansion into an Online Community","text":"<p>While initially focused on local in-person meetings, ProLUG embraced online platforms to extend its reach globally. The switch to a virtual model enabled:</p> <ul> <li>Global Networking: Professionals and enthusiasts from around the world could now connect, learn, and collaborate without geographical limitations.</li> <li>24/7 Discussion: Via platforms like Discord, members could share insights, discuss Linux problems, and exchange ideas anytime, anywhere.</li> <li>Greater Diversity: The online expansion diversified the member base, incorporating individuals from various industries and technical backgrounds, creating a rich environment for problem-solving.</li> </ul>"},{"location":"lac/prolug/#interactive-labs-and-training-programs","title":"Interactive Labs and Training Programs","text":"<p>One of ProLUG\u2019s most successful expansions has been its focus on interactive, hands-on labs. To bridge the gap between theory and practice, Het Tanis launched a series of labs on platforms like Killercoda, covering a variety of topics including:</p> <ul> <li>Linux Essentials and System Administration</li> <li>Ansible Automation</li> <li>Kubernetes and Container Orchestration</li> <li>Security and Network Hardening</li> </ul> <p>With over 50 interactive labs available and more being continuously developed, members benefit from practical scenarios that simulate real-world challenges. The labs cater to beginners, intermediates, and experts, ensuring everyone has something to gain.</p>"},{"location":"lac/prolug/#certification-and-career-development","title":"Certification and Career Development","text":"<p>In 2024, ProLUG launched its first structured certification course: Enterprise Linux Administration. This program was designed to provide a comprehensive curriculum covering topics such as:</p> <ul> <li>Advanced Linux system configuration</li> <li>Enterprise networking and services</li> <li>Security management</li> <li>Scripting and automation</li> </ul> <p>The first cohort of graduates successfully completed the program in January 2025, marking a major milestone in ProLUG\u2019s commitment to professional development. Many graduates have reported success stories, such as landing new jobs, securing promotions, or gaining confidence in their Linux expertise.</p>"},{"location":"lac/prolug/#what-is-a-user-group","title":"What is a User Group?","text":"<p>A user group is a community of individuals who come together to share common interests, typically in a specific area of technology, such as Linux. These groups can be local or online and serve as platforms for:</p> <ul> <li>Collaboration: Members work together to troubleshoot, build projects, and share experiences.</li> <li>Networking: Opportunities to connect with professionals, mentors, and employers within the field.</li> <li>Learning: Workshops, presentations, and discussions that cover new and emerging technologies.</li> <li>Career Growth: Access to resources, training programs, and job opportunities.</li> </ul> <p>ProLUG is a prime example of how a user group can grow beyond its initial purpose, evolving into a vibrant global community with practical learning opportunities and real-world outcomes.</p>"},{"location":"lac/prolug/#success-stories","title":"Success Stories","text":"<p>Being part of ProLUG has proven highly beneficial for many members, with success stories ranging from career advancements to personal growth:</p> <ul> <li>Job Opportunities: Members have found jobs in system administration, DevOps, and cloud engineering roles through networking within ProLUG.</li> <li>Certifications: Many members have successfully obtained Linux-related certifications, including RHCSA, RHCE, and LFCS, using ProLUG\u2019s resources and mentorship programs.</li> <li>Skill Development: Through interactive labs and group discussions, members have honed skills in automation (Ansible), scripting (Bash, Python), containerization (Docker, Kubernetes), and more.</li> <li>Mentorship Relationships: Senior professionals have mentored newcomers, creating a cycle of continuous learning and knowledge sharing.</li> </ul>"},{"location":"lac/prolug/#current-milestones","title":"Current Milestones","text":"<ul> <li>3,000+ Members: ProLUG\u2019s global community continues to grow rapidly, attracting Linux enthusiasts and professionals from various backgrounds.</li> <li>50+ Interactive Labs: Covering diverse topics, from basic Linux administration to advanced enterprise systems management.</li> <li>Ongoing Training Programs: Continuous updates to certification preparation courses, interactive workshops, and guided lab exercises.</li> </ul> <p>ProLUG\u2019s commitment to fostering a collaborative environment has made it a go-to community for anyone interested in Linux. Whether you're a beginner looking to learn the basics or an experienced professional aiming to advance your career, ProLUG offers a pathway to success.</p>"},{"location":"lac/resources/","title":"Resources","text":"<p>Running list of all links, may need further categorization at a later date.</p> Description Link LAC Youtube Playlist https://www.youtube.com/watch?v=eHB8WKWz2eQ&amp;list=PLyuZ_vuAWmprPIqsG11yoUG49Z5dE5TDu What is Vim? https://github.com/vim/vim The Linux Foundation https://www.linux.org/pages/download/ Linux CLI Cheatsheets https://www.digitalocean.com/community/tutorials/linux-commands Vim Adventures https://vim-adventures.com/ Vim Instructional Video https://www.youtube.com/watch?v=d8XtNXutVto Cron Wiki Page https://en.wikipedia.org/wiki/Cron Git https://git-scm.com/ Fireship's How to use Git and Github (12m) https://youtu.be/HkdAHXoRtos freeCodeCamp's Git and GitHub Crash Course (1hr) https://youtu.be/RGOj5yH7evk Git Rebasing documentation https://git-scm.com/book/en/v2/Git-Branching-Rebasing Google SRE Book - Implementing SLOs https://sre.google/workbook/implementing-slos/ AWS High Availability Architecture Guide https://docs.aws.amazon.com/pdfs/whitepapers/latest/real-time-communication-on-aws/real-time-communication-on-aws.pdf Red Hat High Availability Cluster Configuration https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_high_availability_clusters/index Building Secure and Reliable Systems: Crisis Management https://google.github.io/building-secure-and-reliable-systems/raw/ch17.html Building Secure and Reliable Systems: Operation Security https://google.github.io/building-secure-and-reliable-systems/raw/ch17.html#operational_security AWS Real-Time Communication Whitepaper https://docs.aws.amazon.com/pdfs/whitepapers/latest/real-time-communication-on-aws/real-time-communication-on-aws.pdf#high-availability-and-scalability-on-aws Implementing SLOs https://sre.google/workbook/implementing-slos/ OWASP Top Ten https://owasp.org/www-project-top-ten/ Attack Vectors https://www.cobalt.io/blog/defending-against-23-common-attack-vectors mitre.org https://attack.mitre.org/ OWASP Top Ten https://owasp.org/www-project-top-ten/ Common Attack Vectors https://www.cobalt.io/blog/defending-against-23-common-attack-vectors Operations Bridge https://cio-wiki.org/wiki/Operations_Bridge Security Incident Cheatsheet https://zeltser.com/media/docs/security-incident-survey-cheat-sheet.pdf?msc=Cheat+Sheet+Blog Battle Drills https://en.wikipedia.org/wiki/Battle_drill Operations Bridges https://cio-wiki.org/wiki/Operations_Bridge Security Incident Cheat Sheet https://zeltser.com/media/docs/security-incident-survey-cheat-sheet.pdf?msc=Cheat+Sheet+Blog Battle Drill https://en.wikipedia.org/wiki/Battle_drill Tmux Wiki https://github.com/tmux/tmux/wiki Tmux Cheatsheet https://tmuxcheatsheet.com/ GNU Screen Site https://www.gnu.org/software/screen/ GNU Screen Manual https://www.gnu.org/software/screen/manual/screen.html Zellij Site https://zellij.dev/ Link to Killercoda https://killercoda.com/ RedHat: User and Group Management https://www.redhat.com/en/blog/linux-user-group-management Rocky Linux User Admin Guide https://docs.rockylinux.org/books/admin_guide/06-users/ Killercoda lab by FishermanGuyBro https://killercoda.com/fishermanguybro Official Firewalld Documentation https://firewalld.org/documentation/ Official UFW Documentation https://help.ubuntu.com/community/UFW Wikipedia entry for Next-Gen Firewalls https://en.wikipedia.org/wiki/Next-generation_firewall DNF package manager https://en.wikipedia.org/wiki/DNF_(software) RedHat Docs: DNF https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/managing_software_with_the_dnf_tool/index RedHat Docs: Repositories/RHEL 8 https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/considerations_in_adopting_rhel_8/repositories_considerations-in-adopting-rhel-8 Yellow Dog Linux Wiki https://en.wikipedia.org/wiki/Yellow_Dog_Linux Git Pages workflow https://docs.github.com/en/pages/getting-started-with-github-pages/using-custom-workflows-with-github-pages Getting Started with Ansible https://docs.ansible.com/ansible/latest/getting_started/index.html Dockerfile Reference Page https://docs.docker.com/reference/dockerfile/ Podman Command List https://docs.podman.io/en/latest/Commands.html TBD TBD TBD TBD TBD TBD"},{"location":"lac/syllabus/","title":"Course Syllabus","text":"<p>Welcome to the ProLUG Enterprise Linux Systems Administration Course Book.</p>"},{"location":"lac/syllabus/#this-book","title":"This Book","text":"<p>Contains all materials pertaining to the course including links to external resources. It has been put together with care by a number of ProLUG group members referencing original instructional materials produce by Scott Champine (het_tanis).</p> <p>The content is version controlled with Git and stored here: https://github.com/ProfessionalLinuxUsersGroup/lac/</p> <p>Furthermore, the book has been built with mdbook for ease of navigation. Be sure to try the search functionality.</p> <p>Course Description:</p> <p>This course addresses how the Linux systems work for administration level tasks inside a corporate environment. This course will explore everything from the administration of a Linux server and fundamental command line tasks to advanced topics such as patching and web administration.</p> <p>Prerequisite(s) and/or Co-requisite(s):</p> <p>Prerequisites: None</p> <p>Credit hours: N/A</p> <p>Contact hours: 120 (50 Theory Hours, 70 Lab Hours)</p>"},{"location":"lac/syllabus/#course-summary","title":"Course Summary","text":""},{"location":"lac/syllabus/#major-instructional-areas","title":"Major Instructional Areas","text":"<ol> <li>Server build and Hardware components</li> <li>Command Line tools and Syntax</li> <li>Basic Scripting</li> <li>Linux networking</li> <li>Linux security practices</li> <li>Automation and repeating tasks</li> <li>Implement Networking in Linux</li> <li>Troubleshooting</li> <li>Benchmarking and Baselining</li> </ol>"},{"location":"lac/syllabus/#course-objectives","title":"Course Objectives","text":"<ol> <li>Explain the server build process and hardware system components.</li> <li>Analyze system security and implement basic hardening of system.</li> <li>Construct command line syntax to explore the system and gather resource information.</li> <li>Construct scripting structures of assigning variables, conditional tests, and recording output to generate    scripts that do basic system tasks.</li> <li>Analyze and troubleshoot the Apache Web Server</li> <li>Analyze and troubleshoot the NFS/Samba File Shares.</li> <li>Analyze Docker and Kubernetes components and workflows.</li> <li>Describe and troubleshoot network services.</li> <li>Write and perform Ansible tasks to automate deployments to servers.</li> </ol>"},{"location":"lac/syllabus/#learning-materials-and-references","title":"Learning Materials and References","text":""},{"location":"lac/syllabus/#required-resources","title":"Required Resources","text":"<p>Cloud Lab server running Ubuntu on Killercoda.</p> <ul> <li>Minimal resources can accomplish our tasks</li> <li>1 CPU</li> <li>2 GB Ram</li> <li>30 GB Hard Drive</li> <li>Network Interface (IP already setup)</li> </ul> <p>Local VM server running: RHEL, Fedora, Rocky</p> <ul> <li>Minimal resources</li> <li>1 CPU</li> <li>2GB RAM</li> <li>3 3-5GB Hard Drives</li> <li>Network Interface (Bridged)</li> </ul> <p>ProLUG Lab access to Rocky 9.4+ instance.</p> <ul> <li>Minimal resources can accomplish our tasks</li> <li>1 CPU</li> <li>4 GB RAM</li> <li>15 GB Hard Drive</li> <li>3 x 3GB hard drives (for raid and disk labs)</li> <li>Network Interface (IP already setup)</li> </ul> <p></p>"},{"location":"lac/syllabus/#course-plan","title":"Course Plan","text":""},{"location":"lac/syllabus/#instructional-methods","title":"Instructional Methods","text":"<p>This course is designed to promote learner-centered activities and support the development of fundamental Linux skills. The course utilizes individual and group learning activities, performance-driven assignments, problem-based cases, projects, and discussions. These methods focus on building engaging learning experiences conducive to development of critical knowledge and skills that can be effectively applied in professional contexts.</p>"},{"location":"lac/syllabus/#class-size","title":"Class size","text":"<p>This class will effectively engage 40-60 learners.</p>"},{"location":"lac/syllabus/#class-schedule","title":"Class Schedule","text":"<p>Class will meet over weekend (Brown bag) sessions. 1 time per week, for 16 weeks. There will be a total of 16 sessions.</p> Session Topic 1 Get Linux Lab Access - CLI Primer - vi/vim/nano basics 2 Essential Tools - Files, Redirects, and Permissions 3 Storage - Logical Volume Management and RAID 4 Operating Running Systems 5 Security - Manage users and groups 6 Security - Firewalld/UFW 7 Security - Patching the system/ Package Management - yum, dnf, rpm 8 Scripting - System checks 9 Docker - K3s Setup and basics 10 K3s advanced w/ microservices 11 Monitoring systems 12 Engineering - System baselining/benchmarking and testing 13 System Hardening 14 Ansible Automation 15 Engineering Troubleshooting 16 Incident Response - Actual incident callout and information gathering"},{"location":"lac/syllabus/#suggested-learning-approach","title":"Suggested Learning Approach","text":"<p>In this course, you will be studying individually and within a group of your peers, primarily in a lab environment. As you work on the course deliverables, you are encouraged to share ideas with your peers and instructor, work collaboratively on projects and team assignments, raise critical questions, and provide constructive feedback.</p>"},{"location":"lac/u10b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p> <p>This section provides advanced troubleshooting techniques, security best practices, and real-world challenges to strengthen your Kubernetes knowledge.</p>"},{"location":"lac/u10b/#step-1-troubleshooting-kubernetes-cluster-issues","title":"Step 1: Troubleshooting Kubernetes Cluster Issues","text":"<p>When things go wrong, systematic troubleshooting is key. Here\u2019s how you diagnose common Kubernetes issues.</p>"},{"location":"lac/u10b/#node-not-ready","title":"Node Not Ready","text":"<p>Check node status</p> <pre><code>kubectl get nodes\nkubectl describe node &lt;node-name&gt;\n</code></pre> <p>Investigate Kubelet logs</p> <pre><code>journalctl -u k3s -n 50 --no-pager\n</code></pre> <p>Verify system resources</p> <pre><code>free -m     # Check available memory\ndf -h       # Check disk space\nhtop        # Monitor CPU usage\n</code></pre> <p>Possible Fixes</p> <ul> <li>Restart K3s on the failing node:   <pre><code>systemctl restart k3s\n</code></pre></li> <li>Ensure network connectivity:   <pre><code>ping &lt;control-plane-ip&gt;\n</code></pre></li> </ul>"},{"location":"lac/u10b/#pods-stuck-in-pending-or-crashloopbackoff","title":"Pods Stuck in \"Pending\" or \"CrashLoopBackOff\"","text":"<p>Check pod status</p> <pre><code>kubectl get pods -A\nkubectl describe pod &lt;pod-name&gt;\nkubectl logs &lt;pod-name&gt;\n</code></pre> <p>Possible Fixes</p> <ul> <li>If insufficient resources, scale up the cluster.</li> <li>If missing images, check container registry authentication.</li> <li>If misconfigured storage, inspect volumes:   <pre><code>kubectl get pvc\n</code></pre></li> </ul>"},{"location":"lac/u10b/#step-2-securing-kubernetes-deployments","title":"Step 2: Securing Kubernetes Deployments","text":"<p>Security is crucial in enterprise environments. Here are quick wins for a more secure Kubernetes cluster.</p>"},{"location":"lac/u10b/#limit-pod-privileges","title":"Limit Pod Privileges","text":"<p>Disable privileged containers</p> <pre><code>securityContext:\n  privileged: false\n</code></pre> <p>Enforce read-only file system</p> <pre><code>securityContext:\n  readOnlyRootFilesystem: true\n</code></pre>"},{"location":"lac/u10b/#restrict-network-access","title":"Restrict Network Access","text":"<p>Use Network Policies to restrict pod communication</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\nspec:\n  podSelector: {}\n  policyTypes:\n    - Ingress\n</code></pre>"},{"location":"lac/u10b/#use-pod-security-admission-psa","title":"Use Pod Security Admission (PSA)","text":"<p>Enable PSA to enforce security levels:</p> <pre><code>kubectl label --overwrite ns my-namespace pod-security.kubernetes.io/enforce=restricted\n</code></pre>"},{"location":"lac/u10b/#step-3-performance-optimization-tips","title":"Step 3: Performance Optimization Tips","text":"<p>Enhance Kubernetes efficiency with these quick optimizations:</p>"},{"location":"lac/u10b/#optimize-resource-requests-limits","title":"Optimize Resource Requests &amp; Limits","text":"<p>Set appropriate CPU &amp; Memory limits in deployments:</p> <pre><code>resources:\n  requests:\n    cpu: \"250m\"\n    memory: \"256Mi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n</code></pre> <p>Why? Prevents a single pod from consuming excessive resources.</p>"},{"location":"lac/u10b/#enable-horizontal-pod-autoscaling-hpa","title":"Enable Horizontal Pod Autoscaling (HPA)","text":"<p>Auto-scale pods based on CPU or memory usage:</p> <pre><code>kubectl autoscale deployment my-app --cpu-percent=50 --min=2 --max=10\n</code></pre>"},{"location":"lac/u10b/#step-4-bonus-challenge-build-a-secure-scalable-app","title":"Step 4: Bonus Challenge - Build a Secure, Scalable App","text":"<p>Challenge:</p> <ul> <li>Create a secure containerized app</li> <li>Deploy it in Kubernetes</li> <li>Implement Network Policies</li> <li>Apply Pod Security Standards</li> </ul> <p>Helpful Resources:</p> <ul> <li>Pod Security Standards</li> <li>Kubernetes Hardening Guide</li> <li>Kubernetes Security Best Practices</li> </ul>"},{"location":"lac/u10b/#conclusion","title":"Conclusion","text":"<p>This bonus section strengthens your Kubernetes troubleshooting, security, and performance tuning skills. Apply these principles in real-world deployments!</p>"},{"location":"lac/u10b/#downloads","title":"Downloads","text":""},{"location":"lac/u10intro/","title":"Kubernetes","text":""},{"location":"lac/u10intro/#overview","title":"Overview","text":"<p>This unit introduces Kubernetes (K8s), an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. The unit covers:</p> <ul> <li>Understanding Kubernetes Architecture - Nodes, Control Plane, and Cluster Components.</li> <li>Installing K3s - A lightweight Kubernetes distribution optimized for resource efficiency.</li> <li>Interacting with Kubernetes - Using <code>kubectl</code> to manage and troubleshoot clusters.</li> <li>Deploying Applications - Creating and managing Pods, Deployments, and Services.</li> <li>Security and Best Practices - Implementing security measures and troubleshooting issues.</li> </ul> <p>Kubernetes plays a critical role in modern enterprise infrastructure, enabling scalability, high availability, and automation in cloud-native applications.</p>"},{"location":"lac/u10intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, learners will:</p> <ol> <li> <p>Understand the Core Concepts of Kubernetes:</p> </li> <li> <p>Define Kubernetes and explain its role in container orchestration.</p> </li> <li> <p>Differentiate between Kubernetes vs. PaaS (Platform as a Service).</p> </li> <li> <p>Deploy and Manage Kubernetes Clusters:</p> </li> <li> <p>Install K3s and verify its functionality.</p> </li> <li> <p>Manage cluster resources using <code>kubectl</code>.</p> </li> <li> <p>Perform Basic Kubernetes Operations:</p> </li> <li> <p>Create and manage Pods, Deployments, and Services.</p> </li> <li> <p>Understand the role of Namespaces, ConfigMaps, and Secrets.</p> </li> <li> <p>Troubleshoot Kubernetes Clusters:</p> </li> <li> <p>Identify common cluster issues and validate node status.</p> </li> <li> <p>Diagnose networking and pod scheduling problems.</p> </li> <li> <p>Apply Security Best Practices in Kubernetes:</p> </li> <li> <p>Secure containerized applications using best practices.</p> </li> <li>Implement Kubernetes Pod Security Standards.</li> </ol>"},{"location":"lac/u10intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Kubernetes is a foundational technology in modern DevOps and cloud computing. Understanding it is critical for system administrators, DevOps engineers, and site reliability engineers (SREs) for several reasons:</p> <ul> <li>Scalability &amp; Automation - Automates containerized application deployments, scaling, and management.</li> <li>Resource Efficiency - Optimizes workload distribution across multiple nodes.</li> <li>Infrastructure as Code (IaC) - Kubernetes configurations can be defined declaratively using YAML.</li> <li>Cross-Cloud Compatibility - Supports deployment across on-premises, hybrid, and multi-cloud environments.</li> <li>High Availability &amp; Self-Healing - Detects and replaces failed instances automatically.</li> </ul>"},{"location":"lac/u10intro/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this unit, learners should have:</p> <ul> <li>A working knowledge of Linux system administration.</li> <li>Experience using the command line (<code>bash</code>, <code>ssh</code>, <code>vim</code>).</li> <li>Familiarity with containers and tools like Docker.</li> <li>Basic networking knowledge, including IP addressing and port management.</li> </ul>"},{"location":"lac/u10intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Kubernetes (K8s)</p> <p>K3s</p> <p>Control Plane</p> <p>Nodes</p> <p>Pods</p> <p>Deployments</p> <p>Services</p> <p>Kubelet</p> <p>Scheduler</p> <p>ETCD</p> <p>Kube-proxy</p> <p>Static Pod</p>"},{"location":"lac/u10lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u10lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Kubernetes Documentation</li> <li>K3s Official Site</li> <li>Pod Security Standards</li> <li>Kubernetes Troubleshooting Guide</li> </ul>"},{"location":"lac/u10lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u10lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u10_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u10_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u10lab/#pre-lab-quick-warmup-and-system-checks","title":"Pre-Lab: Quick Warmup and System Checks","text":"<p>Before installing K3s, verify system compatibility and gather initial data.</p>"},{"location":"lac/u10lab/#step-1-download-and-inspect-k3s-installer","title":"Step 1: Download and Inspect K3s Installer","text":"<pre><code>curl -sfL https://get.k3s.io &gt; /tmp/k3_installer.sh\nmore /tmp/k3_installer.sh\n</code></pre>"},{"location":"lac/u10lab/#questions","title":"Questions:","text":"<ul> <li>What system checks does the installer perform?</li> <li>What environment variables does it check?</li> </ul>"},{"location":"lac/u10lab/#step-2-system-architecture-check","title":"Step 2: System Architecture Check","text":"<pre><code>uname -m\ngrep -i arch /tmp/k3_installer.sh\n</code></pre>"},{"location":"lac/u10lab/#questions_1","title":"Questions:","text":"<ul> <li>What is the variable holding the system architecture?</li> <li>How does K3s determine system compatibility?</li> </ul>"},{"location":"lac/u10lab/#step-3-selinux-status-check","title":"Step 3: SELinux Status Check","text":"<pre><code>grep -iE \"selinux|sestatus\" /tmp/k3_installer.sh\nsestatus\n</code></pre>"},{"location":"lac/u10lab/#questions_2","title":"Questions:","text":"<ul> <li>Does K3s check if SELinux is enabled?</li> <li>What are the implications of SELinux on Kubernetes deployments?</li> </ul>"},{"location":"lac/u10lab/#installing-k3s-and-verifying-the-service","title":"Installing K3s and Verifying the Service","text":""},{"location":"lac/u10lab/#step-4-install-k3s","title":"Step 4: Install K3s","text":"<pre><code>curl -sfL https://get.k3s.io | sh -\n</code></pre>"},{"location":"lac/u10lab/#step-5-verify-installation","title":"Step 5: Verify Installation","text":"<pre><code>systemctl status k3s\nsystemctl is-enabled k3s\n</code></pre> <ul> <li>What files and services were installed?</li> <li>Is K3s set to start on boot?</li> </ul>"},{"location":"lac/u10lab/#step-6-explore-system-services","title":"Step 6: Explore System Services","text":"<pre><code>systemctl cat k3s\n</code></pre> <ul> <li>What startup configurations does K3s have?</li> <li>Does it rely on any dependencies?</li> </ul>"},{"location":"lac/u10lab/#exploring-kubernetes-environment","title":"Exploring Kubernetes Environment","text":""},{"location":"lac/u10lab/#step-7-checking-kubernetes-components","title":"Step 7: Checking Kubernetes Components","text":"<pre><code>kubectl version\nkubectl get nodes\nkubectl get pods -A\nkubectl get namespaces\nkubectl get configmaps -A\nkubectl get secrets -A\n</code></pre>"},{"location":"lac/u10lab/#questions_3","title":"Questions:","text":"<ul> <li>What namespaces exist by default?</li> <li>What secrets are stored in the cluster?</li> </ul>"},{"location":"lac/u10lab/#deploying-applications-pods-services-and-deployments","title":"Deploying Applications: Pods, Services, and Deployments","text":""},{"location":"lac/u10lab/#step-8-create-a-simple-web-server-pod","title":"Step 8: Create a Simple Web Server Pod","text":"<pre><code>kubectl run webpage --image=nginx\n</code></pre> <ul> <li>Verify pod creation:   <pre><code>kubectl get pods\nkubectl describe pod webpage\n</code></pre></li> </ul>"},{"location":"lac/u10lab/#step-9-deploy-a-redis-database-with-labels","title":"Step 9: Deploy a Redis Database with Labels","text":"<pre><code>kubectl run database --image=redis --labels=tier=database\n</code></pre> <ul> <li>Verify labels:   <pre><code>kubectl get pods --show-labels\n</code></pre></li> </ul>"},{"location":"lac/u10lab/#step-10-expose-the-redis-database","title":"Step 10: Expose the Redis Database","text":"<pre><code>kubectl expose pod database --port=6379 --name=redis-service --type=ClusterIP\n</code></pre> <ul> <li>Verify service:   <pre><code>kubectl get services\n</code></pre></li> </ul>"},{"location":"lac/u10lab/#step-11-create-a-web-deployment-with-replicas","title":"Step 11: Create a Web Deployment with Replicas","text":"<pre><code>kubectl create deployment web-deployment --image=nginx --replicas=3\n</code></pre> <ul> <li>Check status:   <pre><code>kubectl get deployments\n</code></pre></li> </ul>"},{"location":"lac/u10lab/#step-12-create-a-new-namespace-and-deploy-an-app","title":"Step 12: Create a New Namespace and Deploy an App","text":"<pre><code>kubectl create namespace my-test\nkubectl create deployment redis-deploy -n my-test --image=redis --replicas=2\n</code></pre> <ul> <li>Verify deployment:   <pre><code>kubectl get pods -n my-test\n</code></pre></li> </ul>"},{"location":"lac/u10lab/#troubleshooting-cluster-issues","title":"Troubleshooting Cluster Issues","text":"<p>Your team reports an issue with the cluster:</p> <pre><code>[root@Test_Cluster1 ~]# kubectl get nodes\nNAME            STATUS      ROLES                AGE     VERSION\nTest_Cluster1   Ready       control-plane,master 17h     v1.30.6+k3s1\nTest_Cluster2   NotReady    worker               33m     v1.29.6+k3s1\nTest_Cluster3   Ready       worker               17h     v1.28.6+k3s1\n</code></pre>"},{"location":"lac/u10lab/#step-13-investigate-node-health","title":"Step 13: Investigate Node Health","text":"<pre><code>kubectl describe node Test_Cluster2\nkubectl get pods -A\n</code></pre> <ul> <li>What errors do you notice?</li> <li>Is there a resource constraint or version mismatch?</li> </ul>"},{"location":"lac/u10lab/#step-14-restart-k3s-and-check-logs","title":"Step 14: Restart K3s and Check Logs","text":"<pre><code>systemctl restart k3s\njournalctl -xeu k3s\n</code></pre> <ul> <li>What errors appear in the logs?</li> <li>Does restarting resolve the issue?</li> </ul>"},{"location":"lac/u10lab/#reflection-and-additional-challenges","title":"Reflection and Additional Challenges","text":"<ol> <li> <p>Deploy your own container:</p> </li> <li> <p>Build a custom Docker container and deploy it in the cluster.</p> </li> <li> <p>Ensure it\u2019s secure and scalable.</p> </li> <li> <p>Read about securing Kubernetes deployments:</p> </li> <li> <p>Pod Security Standards</p> </li> <li> <p>Docker Security Best Practices</p> </li> <li> <p>Secure Kubernetes in Practice:</p> </li> <li> <p>Try this security lab: Killercoda Kubernetes Security</p> </li> </ol>"},{"location":"lac/u10lab/#conclusion","title":"Conclusion","text":"<p>At the end of this lab, you should:</p> <p>\u2705 Have a fully operational K3s Kubernetes cluster. \u2705 Be able to deploy and expose containerized applications. \u2705 Know how to troubleshoot common Kubernetes errors. \u2705 Understand security best practices for Kubernetes deployments.</p> <p>\ud83d\udccc Next Steps: Continue testing deployments, set up monitoring tools like Prometheus or Grafana, and explore Ingress Controllers to manage external access.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u10ws/","title":"Worksheet","text":""},{"location":"lac/u10ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u10ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Kubernetes Overview</li> <li>K3s Official Documentation</li> <li>Kubernetes Security Best Practices</li> <li>Pod Security Standards</li> <li>Interactive Kubernetes Labs</li> </ul>"},{"location":"lac/u10ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u10_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u10_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u10ws/#unit-10-recording","title":"Unit 10 Recording","text":""},{"location":"lac/u10ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Read: Kubernetes Overview</p> <ol> <li> <p>What are the two most compelling reasons to implement Kubernetes in your organization?</p> </li> <li> <p>The article states that Kubernetes is not a PaaS. What does that mean? How does Kubernetes compare to a traditional PaaS?</p> </li> </ol>"},{"location":"lac/u10ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   Your team is troubleshooting a Kubernetes cluster where applications are failing to deploy. They send you the following output:  <pre><code>[root@Test_Cluster1 ~]# kubectl version\nClient Version: v1.31.6+k3s3\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.30.6+k3s1\n\n[root@rocky15 ~]# kubectl get nodes\nNAME            STATUS      ROLES                  AGE   VERSION\nTest_Cluster1   Ready       control-plane,master   17h   v1.30.6+k3s1\nTest_Cluster2   NotReady    worker                 33m   v1.29.6+k3s1\nTest_Cluster3   Ready       worker                 17h   v1.28.6+k3s1\n</code></pre> <ol> <li> <p>How would you validate the error?</p> </li> <li> <p>What do you suspect is causing the problem?</p> </li> <li> <p>Has someone already attempted to fix this problem? Why or why not?</p> </li> </ol>"},{"location":"lac/u10ws/#discussion-post-3","title":"Discussion Post #3","text":"<p>Scenario:</p>   You are the Network Operations Center (NOC) lead, and your team is responsible for monitoring development, test, and QA Kubernetes clusters.   <p>Write a basic cluster health check procedure for new NOC personnel.</p> <ol> <li> <p>What online resources did you use to figure this out?</p> </li> <li> <p>What did you learn during this process?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u10ws/#key-terminology-definitions","title":"Key Terminology &amp; Definitions","text":"<p>Define the following Kubernetes terms:</p> <ul> <li> <p>Kubernetes/K8s:</p> </li> <li> <p>K3s:</p> </li> <li> <p>Control Plane:</p> </li> <li> <p>Node:</p> </li> <li> <p>Pod:</p> </li> <li> <p>Deployment:</p> </li> <li> <p>Service:</p> </li> <li> <p>ETCD:</p> </li> <li> <p>Kubelet:</p> </li> <li> <p>Kube-proxy:</p> </li> <li> <p>Scheduler:</p> </li> <li> <p>API Server:</p> </li> </ul>"},{"location":"lac/u10ws/#lab-and-assignment","title":"Lab and Assignment","text":"<p>Unit 10 Lab k3s</p> <p>Continue working on your project from the Project Guide</p> <p>Topics:</p> <ol> <li>System Stability</li> <li>System Performance</li> <li>System Security</li> <li>System monitoring</li> <li>Kubernetes</li> <li>Programming/Automation     You will research, design, deploy, and document a system that improves your administration of Linux systems in some way.</li> </ol>"},{"location":"lac/u10ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>Build a custom container and deploy it in Kubernetes securely.</li> <li>Read about container security:</li> <li>Docker Security Best Practices</li> <li>Pod Security Standards</li> <li>Complete this Kubernetes security lab:</li> <li>KillerShell Kubernetes Security</li> </ol>"},{"location":"lac/u10ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about Kubernetes?</p> </li> <li> <p>How can you apply this knowledge in your current IT role?</p> </li> <li> <p>If you\u2019re not in IT, how could this experience contribute to your resume or portfolio?</p> </li> </ol>"},{"location":"lac/u11intro/","title":"Monitoring","text":""},{"location":"lac/u11intro/#overview","title":"Overview","text":"<p>In this unit, we focus on Linux system monitoring, using modern tools like Grafana, Prometheus, Node Exporter, and Loki. As Linux administrators, monitoring is essential to ensure system stability, performance, and security across environments.</p> <p>We will explore how to collect, analyze, and visualize system metrics, and discuss best practices for monitoring and dashboard design that can improve troubleshooting and proactive system management.</p>"},{"location":"lac/u11intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you will be able to:</p> <ul> <li>Explain core monitoring concepts like metrics, logs, SLOs, SLIs, and KPIs</li> <li>Set up Prometheus and Node Exporter to collect system metrics</li> <li>Use Grafana to create dashboards for visualizing system health and performance</li> <li>Write and execute PromQL queries to analyze system data</li> <li>Interpret monitoring data to diagnose system issues and support teams with actionable insights</li> </ul>"},{"location":"lac/u11intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Monitoring is a core responsibility of Linux system administration, ensuring you know what\u2019s happening under the hood before issues escalate. Modern IT environments rely on monitoring to track system performance, security events, and overall stability \u2014 whether in production, development, or cloud environments.</p> <p>This unit focuses on Grafana for visualization and Prometheus with Node Exporter for telemetry and metrics collection \u2014 tools commonly used in enterprise, cloud, and HPC (High-Performance Computing) environments.</p> <p>Whether you're in a NOC, SysAdmin, or DevOps role, understanding monitoring and telemetry makes you a key contributor to system reliability and performance.</p>"},{"location":"lac/u11intro/#prerequisites","title":"Prerequisites","text":"<p>Before starting Unit 11, you should have:</p> <ul> <li>Basic understanding of Linux system administration and networking</li> <li>Familiarity with system processes, performance metrics, and logs</li> <li>Root or sudo access to a Linux system (Rocky 9 or equivalent)</li> <li>Internet access to run labs via Killercoda and online resources</li> <li>(Optional but recommended): Exposure to containers and services like Grafana or Prometheus</li> </ul>"},{"location":"lac/u11intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>SLO (Service Level Objective)</p> <p>SLA (Service Level Agreement)</p> <p>SLI (Service Level Indicator)</p> <p>KPI (Key Performance Indicator)</p> <p>MTTD (Mean Time to Detect)</p> <p>MTTR (Mean Time to Repair)</p>"},{"location":"lac/u11lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u11lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> </ul>"},{"location":"lac/u11lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u11lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u11_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u11_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u11lab/#setup-monitoring-with-grafana","title":"Setup monitoring with Grafana","text":"<ol> <li> <p>Run through each of the three labs below in Killercoda:</p> </li> <li> <p>https://killercoda.com/het-tanis/course/Linux-Labs/102-monitoring-linux-logs</p> </li> <li>https://killercoda.com/het-tanis/course/Linux-Labs/103-monitoring-linux-telemetry</li> <li> <p>https://killercoda.com/het-tanis/course/Linux-Labs/104-monitoring-linux-Influx-Grafana</p> </li> <li> <p>While completing each lab think about the following:</p> </li> <li> <p>a. How does it tie into the diagram below?</p> </li> <li>b. What could you improve, or what would you change based on your previous administration experience.</li> </ol> <p></p>"},{"location":"lac/u11lab/#conclusion","title":"Conclusion","text":"<p>In the end monitoring is more an art than engineering. Sure, we can design all the systems to track all the things, but there\u2019s no equation on what is the one right answer for any of this. You have to spend time with the systems, know what is important and what is an indicator of problems. Then, you have to consider your audience and how to best show them what they need to see.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u11ws/","title":"Worksheet","text":""},{"location":"lac/u11ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u11ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>How to easily monitor your Linux server | Grafana Labs</li> <li>30 Linux System Monitoring Tools Every SysAdmin Should Know</li> <li>Monitoring Linux Using SNMP - Nagios</li> </ul>"},{"location":"lac/u11ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u11_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u11_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u11ws/#unit-11-recording","title":"Unit 11 Recording","text":""},{"location":"lac/u11ws/#discussion-post-1","title":"Discussion Post #1","text":"You\u2019ve heard the term \u201cloose coupling\u201d thrown around the office about a new monitoring solution coming down the pike. You find a good resource and read the section on \u201cPrefer Loose Coupling\u201d .   <ol> <li> <p>What does \u201cloose coupling\u201d mean, if you had to summarize to your junior team    members?</p> </li> <li> <p>What is the advantage given for why you might want to implement this type of    tooling in your monitoring? Do you agree? Why or why not?</p> </li> <li> <p>They mention \u201cexposing metrics\u201d what does it mean to expose metrics? What    happens to metrics that are exposed but never collected?</p> </li> </ol>"},{"location":"lac/u11ws/#discussion-post-2","title":"Discussion Post #2","text":"Your HPC team is asking for more information about how CPU0 is behaving on a set of servers. Your team has node exporter writing data out to Prometheus (Use this to simulate ).   <ol> <li> <p>Can you see the usage of CPU0 and what is the query?</p> </li> <li> <p>Can you see the usage of CPU0 for just the last 5 minutes and what is the query?</p> </li> <li> <p>You know that CPU0 is excluded from Slurm, can you exclude that and only pull the    user and system for the remaining CPUs and what is that query?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u11ws/#definitions","title":"Definitions","text":"<p>SLO</p> <p>SLA</p> <p>SLIKPI</p> <p>Span</p> <p>Trace</p> <p>Prometheus</p> <p>Node_Exporter</p> <p>Grafana</p> <p>Dashboard</p> <p>Heads up Display</p>"},{"location":"lac/u11ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Read the rest of the chapter https://sre.google/workbook/monitoring/    and note anything else of interest when it comes to monitoring and dashboarding.</p> </li> <li> <p>Look up the \u201cProLUG Prometheus Certified Associate Prep 2024\u201d in Resources -&gt;    Presentations in our ProLUG Discord. Study that for a deep dive into Prometheus.</p> </li> <li> <p>Complete the project section of \u201cMonitoring Deep Dive Project Guide\u201d from the    prolug-projects section of the Discord. We have a Youtube video on that project as    well. https://www.youtube.com/watch?v=54VgGHr99Qg</p> </li> </ol>"},{"location":"lac/u11ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How can you apply this now in your current role in IT? If you\u2019re not in IT, how can you    look to put something like this into your resume or portfolio?</p> </li> </ol>"},{"location":"lac/u12intro/","title":"Baselines & Benchmarks","text":""},{"location":"lac/u12intro/#overview","title":"Overview","text":"<p>In this unit, we focus on baselining, benchmarking, testing methodology, and data analytics \u2014 all essential skills for Linux system administrators. These topics allow us to understand the current state of our systems, measure performance under varying loads, and validate improvements with real data.</p> <p>We\u2019ll explore how to gather accurate system information using tools like iostat, sar, stress, and iperf3, and learn how to develop test plans that can support decision-making and capacity planning. Whether you're justifying budget increases or validating a new storage solution, knowing how to gather and present performance data makes you a more effective administrator.</p>"},{"location":"lac/u12intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you will be able to:</p> <ul> <li>Define and use key concepts: baseline, benchmark, high watermark, scope, and methodology</li> <li>Use tools like sar, iostat, stress, and iperf3 to collect performance data</li> <li>Create and execute test plans to evaluate system behavior under different loads</li> <li>Apply data analytics concepts: descriptive, diagnostic, predictive, and prescriptive</li> <li>Communicate system performance clearly with stakeholders through objective evidence</li> </ul>"},{"location":"lac/u12intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Understanding how your systems behave under normal and stressful conditions is a cornerstone of professional Linux administration. In today\u2019s environments, decisions about agents, updates, or infrastructure changes require proof \u2014 not guesswork.</p> <p>This unit prepares you to be the voice of data in meetings with architects and management. From proving system utilization for budget requests to testing performance claims from vendors, these skills help you become a confident, evidence-driven engineer.</p>"},{"location":"lac/u12intro/#prerequisites","title":"Prerequisites","text":"<p>Before starting Unit 12, you should have:</p> <ul> <li>Basic Linux administration skills and terminal comfort</li> <li>Familiarity with resource categories: CPU, memory, disk, and networking</li> <li>Access to a Rocky 9 (or similar) Linux system with sudo or root access</li> <li>Ability to install and use CLI tools (<code>dnf install</code>, <code>rpm</code>, etc.)</li> </ul>"},{"location":"lac/u12intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Baseline</p> <p>Benchmark</p> <p>High Watermark</p> <p>Scope</p> <p>Methodology</p> <p>Testing</p> <p>Control</p> <p>Experiment</p> <p>Analytics</p> <ul> <li>Descriptive</li> <li>Diagnostic</li> <li>Predictive</li> <li>Prescriptive</li> </ul>"},{"location":"lac/u12lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u12lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>SAR Documentation</li> <li>iostat Manual</li> <li>stress GitHub</li> <li>iperf3 Documentation</li> </ul>"},{"location":"lac/u12lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u12lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u12_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u12_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u12lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<ol> <li>Create a working directory</li> </ol> <pre><code>mkdir lab_baseline\ncd lab_baseline\n</code></pre> <ol> <li>Verify if <code>iostat</code> is available</li> </ol> <pre><code>which iostat\n</code></pre> <p>If it\u2019s not there:</p> <pre><code># Find which package provides iostat\ndnf whatprovides iostat\n\n# This should tell you it's sysstat\nrpm -qa | grep -i sysstat\n\n# Install sysstat if needed\ndnf install sysstat\n\n# Verify installation\nrpm -qa | grep -i sysstat\n</code></pre> <ol> <li>Verify if <code>stress</code> is available</li> </ol> <pre><code>which stress\n</code></pre> <p>If it\u2019s not there:</p> <pre><code># Find which package provides stress\ndnf whatprovides stress\n\n# Install stress\ndnf install stress\n\n# Verify installation\nrpm -qa | grep -i stress\nrpm -qi stress  # Read the package description\n</code></pre> <ol> <li>Verify if <code>iperf3</code> is available</li> </ol> <pre><code>which iperf3\n</code></pre> <p>If it\u2019s not there:</p> <pre><code># Find which package provides iperf3\ndnf whatprovides iperf\n\n# Install iperf3\ndnf install iperf\n\n# Verify installation\nrpm -qa | grep -i iperf\nrpm -qi iperf\n</code></pre>"},{"location":"lac/u12lab/#lab","title":"Lab \ud83e\uddea","text":""},{"location":"lac/u12lab/#baseline-information-gathering","title":"Baseline Information Gathering","text":"<p>The purpose of a baseline is not to find fault, load, or to take corrective action. A baseline simply determines what is. You must know what is so that you can test against that when you make a change to be able to objectively say there was or wasn't an improvement. You must know where you are at to be able to properly plan where you are going. A poor baseline assessment, because of inflated numbers or inaccurate testing, does a disservice to the rest of your project. You must accurately draw the first line and understand your system's performance.</p>"},{"location":"lac/u12lab/#using-sar-cpu-and-memory-statistics","title":"Using SAR (CPU and memory statistics)","text":"<p>Some useful sar tracking commands. 10 minute increments.</p> <pre><code># By itself, this gives the last day's processing numbers\nsar\n\n# Gives memory statistics\nsar -r\n\n# Gives swapping statistics (useful to check if system runs out of physical memory)\nsar -W\n\n# List SAR log files\nls /var/log/sa/\n\n# View SAR data from a specific day of the month\nsar -f /var/log/sa/sa28\n</code></pre> <p>For your later labs, you need to collect <code>sar</code> data in real time to compare with the baseline data.</p> <pre><code># View how SAR collects data every 10 minutes\nsystemctl cat sysstat-collect.timer\n\n# Collect SAR data in real time (every 2 seconds, 10 samples)\nsar 2 10\n\n# Memory statistics (every 2 seconds, 10 samples)\nsar -r 2 10\n</code></pre>"},{"location":"lac/u12lab/#using-iostat-cpu-and-device-statistics","title":"Using IOSTAT (CPU and device statistics)","text":"<p><code>iostat</code> will give you either processing or device statistics for your system.</p> <pre><code># Gives all information (CPU and device)\niostat\n\n# CPU statistics only\niostat -c\n\n# Device statistics only\niostat -d\n\n# 1-second CPU stats until interrupted\niostat -c 1\n\n# 1-second CPU stats, 5 times\niostat -c 1 5\n</code></pre>"},{"location":"lac/u12lab/#using-iperf3-network-speed-testing","title":"Using iperf3 (network speed testing)","text":"<p>In the ProLUG lab, <code>red1</code> is the iperf3 server, so we can bounce connections off it (<code>192.168.200.101</code>).</p> <pre><code># TCP connection with 128 connections\ntime iperf3 -c 192.168.200.101 -n 1G -P 128\n\n# UDP connection with 128 connections\ntime iperf3 -c 192.168.200.101 -u -n 1G -P 128\n</code></pre>"},{"location":"lac/u12lab/#using-stress-to-generate-load","title":"Using STRESS to generate load","text":"<p><code>stress</code> will produce extra load on a system. It can run against proc, ram, and disk I/O.</p> <pre><code># View stress usage information\nstress\n\n# Stress CPU with 1 process (will run indefinitely)\nstress -c 1\n\n# Stress multiple subsystems (this will do a lot of things)\nstress --cpu 8 --io 4 --vm 2 --vm-bytes 128M -d 1 --timeout 10s\n</code></pre> <p>Read the usage output and try to figure out what each option does.</p>"},{"location":"lac/u12lab/#developing-a-test-plan","title":"Developing a Test Plan","text":"<p>The company has decided we are going to add a new agent to all machines. Management has given this directive to you because of PCI compliance standards with no regard for what it may do to the system. You want to validate if there are any problems and be able to express your concerns as an engineer, if there are actual issues. No one cares what you think, they care what you can show, or prove.</p>"},{"location":"lac/u12lab/#determine-the-right-question-to-ask","title":"Determine the right question to ask:","text":"<ul> <li> <p>Do we have a system baseline to compare against?</p> </li> <li> <p>No? Make a baseline.     <pre><code>iostat -xh 1 10\n</code></pre></p> </li> <li> <p>Can we say that this system is not under heavy load?</p> </li> <li> <p>What does a system under no load look like permorning tasks in our environment?</p> </li> <li> <p>Assuming our systems are running not under load, capture SAR and baseline stats.</p> </li> <li> <p>Perform some basic tasks and get their completion times.</p> <ul> <li>Writing/deleting 3000 empty files #modify as needed for your system</li> </ul> <pre><code># Speed: ~10s\ntime for i in `seq 1 3000`; do touch testfile$i; done\n\n# Removing them\ntime for i in `seq 1 3000`; do rm -rf testfile$i; done\n\n# Writing large files\nfor i in `seq 1 5`; do time dd if=/dev/zero of=/root/lab_baseline/sizetest$i bs=1024k count=1000; done\n\n# Removing the files\nfor i in `seq 1 5`; do rm -rf sizetest$i ; done\n</code></pre> <ul> <li>Testing processor speed</li> </ul> <pre><code>time $(i=0; while (( i &lt; 999999 )); do (( i ++ )); done)\n# if this takes your system under 10 seconds, add a 9\n</code></pre> <ul> <li>Alternate processor speed test</li> </ul> <pre><code>time dd if=/dev/urandom bs=1024k count=20 | bzip2 -9 &gt;&gt; /dev/null\n</code></pre> <p>This takes random numbers in blocks, zips them, and then throws them away.  Tune to about ~10 seconds as needed</p> </li> <li> <p>What is the difference between systems under load with and without the agent?</p> </li> </ul> <p>Run a load test (with <code>stress</code>) of what the agent is going to do against the system.</p> <p>While the load test is running, do your same functions and see if they perform differently.</p>"},{"location":"lac/u12lab/#execute-the-plan-and-gather-data","title":"Execute the plan and gather data","text":"<p>Edit these as you see fit, add columns or rows to increase understanding of system performance. This is your chance to test and record these things.</p>"},{"location":"lac/u12lab/#system-baseline-tests","title":"System Baseline Tests","text":"Metric Server 1 SAR average load (past week) IOSTAT test (10 min) IOSTAT test (2s x 10 samples) Disk write - small files Disk write - small files (retry) Disk write - large files Processor benchmark <p>You may baseline more than once, more data is rarely bad.</p> <p>Make 3 different assumptions for how load may look on your system with the agent and design your stress commands around them (examples):</p> <ol> <li>I assume no load on hdd, light load on processors</li> </ol> <pre><code>while true; do stress --cpu 2 --io 4 --vm 2 --vm-bytes 128M --timeout 30; done #\n</code></pre> <ol> <li>I assume low load on hdd, light load on processors</li> </ol> <pre><code>while true; do stress --cpu 2-io 4 --vm 2 --vm-bytes 128M -d 1 --timeout 30; done\n</code></pre> <ol> <li>I just assume everything is high load and it's a mess    <pre><code>while true; do stress --cpu 4 --io 4 --vm 2 --vm-bytes 256M -d 4 --timeout 30; done\n</code></pre></li> </ol> <p>In one window start your load tests (YOU MUST REMEMBER TO STOP THESE AFTER YOU GATHER YOUR DATA). In another window gather your data again, exactly as you did for your baseline with <code>sar</code> and <code>iostat</code> just for the time of the test.</p>"},{"location":"lac/u12lab/#system-tests-while-under-significant-load","title":"System Tests while under significant load","text":"<p>Put command you're using for load here:</p> Metric Server 1 SAR average load (during test) IOSTAT test (10 min) IOSTAT test (2s x 10 samples) Disk write - small files Disk write - small files (retry) Disk write - large files Processor benchmark"},{"location":"lac/u12lab/#system-tests-while-under-significant-load_1","title":"System Tests while under significant load","text":"<p>Put command you're using for load here:</p> Metric Server 1 SAR average load (during test) IOSTAT test (10 min) IOSTAT test (2s x 10 samples) Disk write - small files Disk write - small files (retry) Disk write - large files Processor benchmark <p>Continue copying and pasting tables as needed.</p>"},{"location":"lac/u12lab/#reflection-questions-optional","title":"Reflection Questions (optional)","text":"<ul> <li>How did the system perform under load compared to your baseline?</li> <li>What would you report to your management team regarding the new agent\u2019s impact?</li> <li>How would you adjust your test plan to capture additional performance metrics?</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u12ws/","title":"Worksheet","text":""},{"location":"lac/u12ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u12ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Kaggle - Python and Data Science Learning</li> </ul>"},{"location":"lac/u12ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u12_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u12_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u12ws/#unit-12-recording","title":"Unit 12 Recording","text":""},{"location":"lac/u12ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Scenario:</p>   Your manager has come to you with another emergency.  He has a meeting next week to discuss capacity planning and usage of the system with IT upper management. He doesn\u2019t want to lose his budget, but he has to prove that the system utilization warrants spending more.   <ol> <li> <p>What information can you show your manager from your systems?</p> </li> <li> <p>What type of data would prove system utilization? (Remember the big 4: compute,    memory, disk, networking)</p> </li> <li> <p>What would your report look like to your manager?</p> </li> </ol>"},{"location":"lac/u12ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   You are in a capacity planning meeting with a few of the architects. They have decided to add 2 more agents to your Linus sytems, Bacula Agent and an Avamar Agent. They expect these agents to run their work starting at 0400 every morning.   <p> </p> <ol> <li> <p>What do these agents do? (May have to look them up)</p> </li> <li> <p>Do you think there is a good reason not to use these agents at this timeframe?</p> </li> <li> <p>Is there anything else you might want to point out to these architects about these agents they are installing?</p> </li> </ol>"},{"location":"lac/u12ws/#discussion-post-3","title":"Discussion Post #3","text":"<p>Scenario:</p>   Your team has recently tested at proof of concept of a new storage system. The vendor has published the blazing fast speeds that are capable of being run through this storage system. You have a set of systems connected to both the old storage system and the new storage system.   <ol> <li> <p>Write up a test procedure of how you may test these two systems.</p> </li> <li> <p>How are you assuring these test are objective?</p> </li> <li>What is meant by the term Ceteris Paribus, in this context?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u12ws/#definitions","title":"Definitions","text":"<p>Baseline:</p> <p>Benchmark:</p> <p>High watermark:</p> <p>Scope:</p> <p>Methodology:</p> <p>Testing:</p> <p>Control:</p> <p>Experiment:</p> <p>Analytics:</p>"},{"location":"lac/u12ws/#digging-deeper-optional","title":"Digging Deeper (optional)","text":"<ol> <li> <p>Analyzing data may open up a new field of interest to you. Go through some of the    free lessons on Kaggle, here: https://www.kaggle.com/learn</p> </li> <li> <p>What did you learn?</p> </li> <li> <p>How will you apply these lessons to data and monitoring you have already      collected as a system administrator?</p> </li> <li> <p>Find a blog or article that discusses the 4 types of data analytics.</p> </li> <li> <p>What did you learn about past operations?</p> </li> <li> <p>What did you learn about predictive operations?</p> </li> <li> <p>Download Spyder IDE (Open source).</p> </li> <li>Find a blog post or otherwise try to evaluate some data.</li> <li>Perform some Linear regression. My block of code (but this requires some      additional libraries to be added. I can help with that if you need it.)      <pre><code>import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nsize = [[5.0], [5.5], [5.9], [6.3], [6.9], [7.5]]\nprice =[[165], [200], [223], [250], [278], [315]]\nplt.title('Pizza Price plotted against the size')\nplt.xlabel('Pizza Size in inches')\nplt.ylabel('Pizza Price in cents')\nplt.plot(size, price, 'k.')\nplt.axis([5.0, 9.0, 99, 355])\nplt.grid(True)\nmodel = LinearRegression()\nmodel.fit(X = size, y = price)\n#plot the regression line\nplt.plot(size, model.predict(size), color='r')\n</code></pre></li> </ol>"},{"location":"lac/u12ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How can you apply this now in your current role in IT?    If you\u2019re not in IT, how can you look to put something like this into your resume or    portfolio?</p> </li> </ol>"},{"location":"lac/u13b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p> <p>This bonus lab is designed to provide material and exercises in applying the skills and principles outlined by this course.</p> <p>Students will:</p> <ul> <li>Install necessary lab dependencies, <code>fail2ban</code>, <code>ssh</code>, <code>nginx</code></li> <li>Build troubleshooting, deductive reasoning, and investigative skills</li> <li>Edit configuration files, utilize many command line tools, <code>systemctl</code>, <code>vi</code></li> <li>Understand specific use case cyber security tools</li> <li>And more</li> </ul>"},{"location":"lac/u13b/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://github.com/fail2ban/fail2ban</li> <li>https://www.digitalocean.com/community/tutorials/how-fail2ban-works-to-protect-services-on-a-linux-server</li> <li>https://nginx.org/en/docs/beginners_guide.html</li> <li>https://www.openssh.com/features.html</li> <li>https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/getting-started-with-nftables_configuring-and-managing-networking#con_basics-of-nftables-tables_assembly_creating-and-managing-nftables-tables-chains-and-rules</li> <li>https://developers.cloudflare.com/waf/get-started/</li> </ul>"},{"location":"lac/u13b/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ host</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u13b/#bonus-pre-lab-warm-up","title":"Bonus Pre-Lab Warm-Up","text":"<p>First lets identify a couple dependencies for this lab. Since many of the labs in this course are predicated on Rocky we will provide commands like <code>dnf</code> and <code>rpm</code> to accomplish this task.</p> <pre><code>rpm -ql openssh-server\n</code></pre> <p>This command will list configuration files and underlying dependent libraries required to run an SSH server if <code>openssh-server</code> is installed locally. But be careful, sometimes this query will list lingering configuration files and directories even though it isn't installed.</p> <p>To corroborate our findings, let's query <code>dnf</code></p> <pre><code>dnf list --installed | grep openssh-server\n</code></pre> <p>If the piped grep command comes up empty <code>openssh-server</code> is not installed, install it. Hopefully these commands and strategies are familiar to you.</p> <pre><code>dnf install openssh-server\n</code></pre> <p>Now repeat this process for <code>nginx</code>, and <code>fail2ban</code>. What are nginx and fail2ban you ask? Well now is a great time to use the <code>man</code> pages.</p> <p>If a <code>man</code> command ever fails due to a lack of 'manual entry' that means you may need to install the package or you have a path issue. However if the shell returns that the man command is not found you may need to install <code>man-db</code>.</p> <p>Hopefully it's becoming clear why understanding our tools, troubleshooting, and deductive reasoning skills come in handy!</p> <pre><code>dnf install -y nginx fail2ban man-db\n\n# We should now be able to man nginx and fail2ban\n# if we couldn't before\n\nman nginx\nman fail2ban\n</code></pre> <p>Now that they're installed let's enable <code>sshd</code> and <code>nginx</code> from <code>systemctl</code>.</p> <pre><code>systemctl enable --now sshd # the --now flag along will also start the service\nsystemctl enable --now nginx\n</code></pre> <p></p> <p>We should now be able to see these services are running in a myriad of ways:</p> <pre><code>ss -ntulp | grep ssh\nss -ntulp | grep nginx\n\nsystemctl status sshd\nsystemctl status nginx\n</code></pre> <p>Ideally these services are hosted on a student owned device/host and not the ProLUG lab boxes. With these enabled it should be possible to <code>ssh</code> into the host or visit the nginx web page via http://(localhost or {IP address}) from a web browser.</p> <p>Technically you could <code>curl localhost</code> from the ProLUG Rocky box and capture the html nginx hosts and ssh into the box from a different box to verify they are enabled.</p>"},{"location":"lac/u13b/#bonus-lab","title":"Bonus Lab \ud83e\uddea","text":""},{"location":"lac/u13b/#ssh-nginx-and-implementing-fail2ban","title":"SSH, NGINX and implementing Fail2Ban","text":"<p>When services like SSH and NGINX (pronounced 'engine-x') are exposed to the public internet it will become exceedingly apparent (in seconds if not minutes) within their log files that they are under bombardment from web scrapers, bots, hackers, and more.</p> <p>The goals of these entities are either malicious, self serving, or helpful in the case of organizations like Palo Alto who build databases for cybersecurity purposes.</p> <p>An example of an nginx <code>access.log</code> file with Palo Alto's Expanse web scraping arm is shown below:</p> <p></p>"},{"location":"lac/u13b/#fail2ban","title":"Fail2Ban","text":"<p>Fail2Ban is a small part of a larger solution in mitigating and monitoring these threats and actors. While more robust solutions exist from providers like Cloudflare or Fortinet this lab hopes to introduce a small foray into implementing a more manageable solution for students.</p> <p>Plus, it's kinda cool and pretty fun.</p>"},{"location":"lac/u13b/#how-fail2ban-works","title":"How Fail2Ban Works","text":"<p>Fail2Ban is designed to analyze log files and manipulates the host's firewall to programmatically ban offending IP addresses based on various conditions predicated by specific configuration files.</p> <p>First let's briefly skim Fail2Ban's main configuration file:</p> <pre><code>vi /etc/fail2ban.conf\n</code></pre> <pre><code># Fail2Ban main configuration file\n#\n# Comments: use '#' for comment lines and ';' (following a space) for inline comments\n#\n# Changes:  in most of the cases you should not modify this\n#           file, but provide customizations in fail2ban.local file, e.g.:\n#\n# [DEFAULT]\n# loglevel = DEBUG\n#\n\n[DEFAULT]\n\n# Option: loglevel\n# Notes.: Set the log level output.\n#         CRITICAL\n#         ERROR\n#         WARNING\n#         NOTICE\n#         INFO\n#         DEBUG\n# Values: [ LEVEL ]  Default: INFO\n#\nloglevel = INFO\n\n# Option: logtarget\n# Notes.: Set the log target. This could be a file, SYSTEMD-JOURNAL, SYSLOG, STDERR or STDOUT.\n#         Only one log target can be specified.\n#         If you change logtarget from the default value and you are\n#         using logrotate -- also adjust or disable rotation in the\n#         corresponding configuration file\n#         (e.g. /etc/logrotate.d/fail2ban on Debian systems)\n# Values: [ STDOUT | STDERR | SYSLOG | SYSOUT | SYSTEMD-JOURNAL | FILE ]  Default: STDERR\n#\nlogtarget = /var/log/fail2ban.log\n\nRemaining output redacted...\n</code></pre> <p>Generally this file can remain in its default configuration. We are however interested in its log path of <code>/var/log/fail2ban.log</code>. If we ever need to investigate or debug Fail2Ban we now know where it logs its decisions when an actionable event arises.</p> <p>A further configuration file we are interested in is Fail2Ban's <code>jail.conf</code>. Let's look at Fail2Ban's <code>man jail.conf</code> entry first:</p> <pre><code>CONFIGURATION FILES FORMAT\n *.conf  files  are distributed by Fail2Ban.  It is recommended that *.conf files should\n  remain unchanged to ease upgrades.  If needed, customizations should be provided in *.local files.\n  For example, if you would like to enable the [ssh-iptables-ipset] jail specified in jail.conf,\n  create jail.local containing\n\n jail.local\n        [ssh-iptables-ipset]\n\n        enabled = true\n\n In .local files specify only the settings you would like to change and the rest of the configuration\n  will then come from the corresponding .conf file which is parsed first.\n\n jail.d/ and fail2ban.d/\n\n        In addition to .local, for jail.conf or fail2ban.conf file there can be a corresponding .d/\n        directory containing additional .conf  files.  The order e.g. for jail configuration would be:\n\n        jail.conf\n        jail.d/*.conf (in alphabetical order)\n        jail.local\n        jail.d/*.local (in alphabetical order).\n\n        i.e.  all  .local  files  are  parsed after .conf files in the original configuration file and files\n        under .d directory.  Settings in the file parsed later take precedence over identical entries in\n        previously parsed files.  Files are ordered alphabetically, e.g.\n\n        fail2ban.d/01_custom_log.conf - to use a different log path\n        jail.d/01_enable.conf - to enable a specific jail\n        jail.d/02_custom_port.conf - to change the port(s) of a jail.\n</code></pre> <p>This section is what we are most interested in. We see that Fail2Ban recommends utilizing <code>jail.local</code> files and drop-in directories to preserve initial configuration files and to facilitate updates down the road.</p> <p>Further, lets now take a brief look at the <code>jail.conf</code> file and get an understanding of the options available to us. While this is a lot of information to take in it should be embraced for this is the bread and butter of becoming a better administrator. Understanding the tools available to us.</p> <p>And for what it's worth, we don't need to know this tool down to its quantum level. \"Just enough to get the job done.\"</p> <pre><code>vi /etc/fail2ban/jail.conf\n</code></pre> <p>Understanding jail configuration options as shown below are some of the many configuration details that will go a long way to intelligently protecting our services and systems.</p> <pre><code>#\n# MISCELLANEOUS OPTIONS\n#\n\n# \"bantime.increment\" allows to use database for searching of previously banned ip's to increase a\n# default ban time using special formula, default it is banTime * 1, 2, 4, 8, 16, 32...\n#bantime.increment = true\n\n# \"bantime.maxtime\" is the max number of seconds using the ban time can reach (doesn't grow further)\n#bantime.maxtime =\n\n# \"bantime.factor\" is a coefficient to calculate exponent growing of the formula or common multiplier,\n# default value of factor is 1 and with default value of formula, the ban time\n# grows by 1, 2, 4, 8, 16 ...\n#bantime.factor = 1\n</code></pre>"},{"location":"lac/u13b/#implementing-fail2ban","title":"Implementing Fail2Ban","text":"<p>Let's keep these types of options in mind and now look at an example of a basic <code>jail.local</code> file to protect our SSH server.</p> <p>Based upon our observations earlier this command will make the necessary <code>jail.local</code> file we will need in its proper directory.</p> <pre><code>vi /etc/fail2ban/jail.local\n</code></pre> <p>And now let's define some necessary options to begin protecting SSH from broad attack.</p> <pre><code>[DEFAULT]\nbantime            =  1h\nmaxretry           =  2\nbantime.increment  =  true\nbantime.factor     =  12\nbantime.maxtime    =  5w\nignoreip           =  {IP_ADDRESS} # useful to prevent banning oneself\n\n[sshd]\nbackend            =  systemd # required for systemd based systems\nenabled            =  true\n</code></pre> <p>And this is it.</p> <p>It took a lot to get here but it's important to understand our firearms before we fire them. For something like Fail2Ban could potentially permanently lock us out of a system under the right circumstances and make us have a very bad day indeed.</p> <p>While there are more options available for a <code>jail.local</code> file, this should suffice to ban repeat offenders who attempt to use an incorrect password on the SSH service. Any other required definitions to properly implement this <code>jail.local</code> file for SSH will be parsed before hand as was stipulated in the man page and the <code>jail.conf</code> file.</p> <p>After that we must restart the Fail2Ban service to implement our changes.</p> <pre><code>systemctl restart fail2ban\n</code></pre>"},{"location":"lac/u13b/#monitoring-fail2ban","title":"Monitoring Fail2Ban","text":"<p>Now if everything is configured properly we should be able to input the following command to see a list of currently banned IP addresses:</p> <pre><code>fail2ban-client status sshd\n</code></pre> <p></p> <p>Typically SSH services are not exposed publicly to the internet. It is a far better solution to lock SSH behind a Virtual Private Network (VPN) where something like a \"slow brute-force\" attack will be mitigated almost entirely.</p> <p>However you still might institute Fail2Ban even behind the VPN in the event a threat actor does gain access to the VPN and attempts to brute force or slow brute force attack hosts with SSH services exposed.</p> <p>Given how easy it is to implement Fail2Ban, why wouldn't you? Well, there's always a bigger fish, but that is a different conversation.</p>"},{"location":"lac/u13b/#nginx","title":"NGINX","text":"<p>If you've made it this far I appreciate your tenacity or perhaps deep captivation of this subject.</p> <p>Now where Fail2Ban really shines is when integrated with an application like <code>nginx</code>. As we'll see Fail2Ban allows us to configure what they call \"filters\" that can further protect <code>nginx</code> and our website, if we had one. Since this lab has ran long I will keep it brief.</p> <p>Suffice it say for students this is theory, but as I will mention later these filters can be quite powerful.</p> <p>Let's look at what is available to us for nginx:</p> <pre><code>ls /etc/fail2ban/filter.d/ | grep nginx\n</code></pre> <pre><code>nginx-bad-request.conf\nnginx-botsearch.conf\nnginx-error-common.conf\nnginx-forbidden.conf\nnginx-http-auth.conf\nnginx-limit-req.conf\n</code></pre> <p>Well, what do we have here?</p> <p>I encourage you to explore all of these available filters however in my experience the <code>nginx-bad-request.conf</code> filter has been most useful in banning bad actors.</p> <pre><code>cat /etc/fail2ban2/filter.d/nginx-bad-request.conf\n</code></pre> <pre><code># Fail2Ban filter to match bad requests to nginx\n#\n\n[Definition]\n\n# The request often doesn't contain a method, only some encoded garbage\n# This will also match requests that are entirely empty\nfailregex = ^&lt;HOST&gt; - \\S+ \\[\\] \"[^\"]*\" 400\n\ndatepattern = {^LN-BEG}%%ExY(?P&lt;_sep&gt;[-/.])%%m(?P=_sep)%%d[T ]%%H:%%M:%%S(?:[.,]%%f)?(?:\\s*%%z)?\n              ^[^\\[]*\\[({DATE})\n              {^LN-BEG}\n\njournalmatch = _SYSTEMD_UNIT=nginx.service + _COMM=nginx\n\n# Author: Jan Przybylak\n</code></pre> <p>Whenever nginx receives a \"bad request\", think a request for a link, file, or directory that doesn't exist in the domain or shouldn't be accessible, Fail2Ban will recognize it from the <code>nginx</code> access.log by a 404 return made by <code>nginx</code> and act appropriately based upon our default action options.</p> <p>(After 2 bad requests, you get banned for an hour. After that timeout, if you send 2 more bad requests the timeout is extended for 24 hours, growing exponentially for each occurrence afterwards up to a 5 week ban. It is typically advised against implementing permanent bans as over time this will lead to potentially significant overhead for the host.)</p> <p>When running this filter on my own personal nginx web server over the course of 30 days I will have banned over 40,000 IP addresses with varying ban times.</p> <p>As of rebooting my publicly available website not minutes ago this is how many IP addresses are already banned.</p> <p></p> <p>And here is how Fail2Ban manipulates <code>iptables</code> by default, though ideally Fail2Ban is configured to utilize <code>nftables</code>, a modernized and significantly improved firewall solution, or <code>firewalld</code> which has access to firewall architectures like <code>iptables</code>, and <code>nftables</code>.</p> <p>Configuring Fail2Ban with <code>firewalld</code> or <code>nftables</code> will look like such:</p> <pre><code>[DEFAULT]\n..etc\nbanaction           =  firewallcmd-rich-rules[actiontype=&lt;multiport&gt;]\nbanaction_allports  =  firewallcmd-rich-rules[actiontype=&lt;allports&gt;]\n\n# Or\n\n[DEFAULT]\n..etc\nbanaction           =  nftables\nbanaction_allports  =  nftables[type=allports]\n</code></pre> <p>And here is how Fail2Ban modifies an <code>iptables</code> chain.</p> <p></p> <p>I highly, highly encourage students have a working understanding of Linux firewalls and their components like tables and chains.</p> <p>It's important to be stated that this should be understood as a mitigation, not a perfect solution. Primarily to minimize automated bots scraping a domain, usually for nefarious purposes.</p> <p>And I will iterate there are far better solutions for free (Cloudflare WAF) that protect more intelligently and robustly than Fail2Ban. Migrating your domain over to Cloudflare or equivalent service is probably the far smarter and less work intensive task than a comprehensive Fail2Ban setup. But I like to think we're building our muscles... you know, putting in reps.</p>"},{"location":"lac/u13b/#filter-implementation","title":"Filter Implementation","text":"<p>Remembering our previous configurations we know that if a user sends more than two malformed, either malicious or unintentional, requests to our website they will be temporarily banned.</p> <pre><code>vi /etc/fail2ban/jail.local\n</code></pre> <p>Here is what the configuration file should look like to implement this filter:</p> <pre><code>[nginx-bad-request]\nenabled  =  true\nport     =  http,https\nlogpath  =  %(nginx_access_log)s\n</code></pre> <p>Append these lines to the earlier file we implemented after our SSHD section and let the regex do the work for us.</p> <p>Then finally restart Fail2Ban again:</p> <pre><code>systemctl restart fail2ban\n</code></pre> <p>It's as simple as that.</p> <p>You can use <code>fail2ban-client status nginx-bad-request</code> to monitor any actions Fail2Ban has taken to ban bad actors or investigate the <code>/var/log/fail2ban.log</code> file.</p> <p>Well that about wraps it up. There is far more to consider when it comes to protecting web servers and SSH, but hopefully this was a good primer and helped exercise those Linux muscles.</p>"},{"location":"lac/u13intro/","title":"System Hardening","text":""},{"location":"lac/u13intro/#overview","title":"Overview","text":"<p>In this unit, we focus on system hardening \u2014 the process of configuring Linux systems to meet defined security standards. As threats evolve, system administrators play a key role in ensuring confidentiality, integrity, and availability by reducing attack surfaces and enforcing secure configurations.</p> <p>We will explore industry benchmarks like STIGs and CIS, implement hardening techniques for services like SSH, identify unneeded software, and analyze system security posture using tools like the SCC Tool. You\u2019ll also revisit baselining and documentation as part of security validation and compliance.</p>"},{"location":"lac/u13intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you will be able to:</p> <ul> <li>Define system hardening and understand its role in securing Linux servers</li> <li>Scan systems using the SCC Tool to assess security compliance</li> <li>Apply remediation steps based on STIG reports</li> <li>Harden services such as SSHD, remove unnecessary software, and lock down ports</li> <li>Rescan and verify improvements in your system\u2019s security posture</li> <li>Understand the importance of documentation and change management in security</li> </ul>"},{"location":"lac/u13intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Security hardening helps ensure that systems are not only functional but also resilient against misuse and attacks. Whether aligning with PCI DSS, CIS benchmarks, or STIGs, hardening turns general-purpose Linux installs into mission-ready infrastructure.</p> <p>This unit emphasizes security vs. accessibility, change management, and shared responsibility between security and operations. You\u2019ll experience real-world practices like scanning, remediating, and verifying \u2014 essential skills for any administrator tasked with system security.</p>"},{"location":"lac/u13intro/#prerequisites","title":"Prerequisites","text":"<p>Before starting Unit 13, you should have:</p> <ul> <li>A solid understanding of Linux system administration and services</li> <li>Comfort using the terminal and managing services with <code>systemctl</code></li> <li>Ability to inspect ports, services, and installed software</li> <li>Familiarity with tools like <code>ss</code>, <code>rpm</code>, <code>dnf</code>, and <code>ssh</code></li> <li>Access to a Rocky Linux system with root/sudo privileges</li> <li>(Optional but recommended): Experience from Unit 12 on baselining and benchmarking</li> </ul>"},{"location":"lac/u13intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Hardening</p> <p>Pipeline</p> <p>Change Management</p> <p>Security Standard</p> <p>Security Posture</p> <p>Acceptable Risk</p> <ul> <li>NIST 800-53</li> </ul> <p>STIG</p> <p>CIS Benchmark</p> <p>OpenSCAP</p> <p>SCC Tool</p> <p>HIDS</p> <p>HIPS</p>"},{"location":"lac/u13lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u13lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://killercoda.com/het-tanis/course/Linux-Labs/207-OS_STIG_Scan_with_SCC_Tool</li> <li>https://public.cyber.mil/stigs/srg-stig-tools/</li> <li>https://nvd.nist.gov/vuln/search</li> </ul>"},{"location":"lac/u13lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u13lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u13_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u13_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u13lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <ol> <li> <p><code>ss -ntulp</code></p> </li> <li> <p>What ports are open on this server?</p> </li> <li>What is open on port 9080?</li> <li> <p>What does this service do?</p> </li> <li> <p><code>systemctl --failed</code></p> </li> <li> <p>Are there any failed units?</p> </li> <li> <p><code>systemctl list-units --state=active</code></p> </li> <li> <p>About how many active units are there?</p> <ul> <li><code>systemctl list-units --state=active | wc -l</code></li> </ul> </li> <li> <p><code>rpm -qa | wc -l</code></p> </li> <li> <p>Approximately how many software packages do you have?</p> </li> <li> <p><code>rpm -qa | grep -i ssh</code></p> </li> <li> <p>How many ssh packages do you have?</p> </li> <li>What is the version of openssh?</li> <li>Do you know if there are any known vulnerabilities for that version?<ul> <li>https://nvd.nist.gov/vuln/search</li> </ul> </li> </ol>"},{"location":"lac/u13lab/#lab","title":"Lab \ud83e\uddea","text":"<p>There will be three basic tasks for today\u2019s labs:</p> <ol> <li>You will scan a server for a SCC Report and get a STIG Score</li> <li>You will remediate some of the items from the scan</li> <li>You will rescan and verify a better score.</li> </ol>"},{"location":"lac/u13lab/#scc-report","title":"SCC Report:","text":"<p>This lab portion can be done in the ProLUG Rocky servers, or in killercoda at this location: https://killercoda.com/het-tanis/course/Linux-Labs/207-OS_STIG_Scan_with_SCC_Tool</p> <p>Testing hardening on the ProLUG Lab may take over an hour. You are welcome to perform the test there, but make sure you have some time.</p> <p><code>ssh</code> into a Rocky sever</p> <pre><code>cd /opt/scc\ntime ./cscc\n\n# - Wait over an hour\n\ncd /root/SCC/sessions #find the most recent run\n</code></pre> <p>Look in the results to see output.</p>"},{"location":"lac/u13lab/#harden-the-system","title":"Harden the system","text":"<ol> <li>Harden sshd</li> </ol> <ul> <li>Is your system hardened in this capacity?</li> <li>How did you check?</li> <li>Did the fix check work for you?</li> <li> <p>How did you check?</p> </li> <li> <p>Remove unneeded Software</p> </li> <li> <p>Read about cowsay \u2013 <code>man cowsay</code></p> </li> <li>Remove cowsay \u2013 <code>dnf remove cowsay</code></li> </ul> <p></p>"},{"location":"lac/u13lab/#rescan-to-validate-change","title":"Rescan to validate change","text":"<p><code>ssh</code> into a Rocky sever</p> <pre><code>cd /opt/scc\ntime ./cscc\n\n# - Wait over an hour\n\ncd /root/SCC/sessions #find the most recent run\n</code></pre> <p>Look in the results to see output.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u13ws/","title":"Worksheet","text":""},{"location":"lac/u13ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u13ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Lab - Server Startup Process</li> <li>Killercoda Lab - Updating a Golden Image</li> </ul>"},{"location":"lac/u13ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u13_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u13_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u13ws/#unit-13-recording","title":"Unit 13 Recording","text":""},{"location":"lac/u13ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Scenario:</p>   Your security team comes to you with a discrepancy between the production security baseline and something that is running on one of your servers in production. There are 5 servers in a web cluster and only one of them is showing this behavior. They want you to account for why something is different.   <ol> <li> <p>How are you going to validate that the difference between the systems?</p> </li> <li> <p>What are you going to look at to explain this?</p> </li> <li> <p>What could be done to prevent this problem in the future?</p> </li> </ol>"},{"location":"lac/u13ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   Your team has been giving you more and more engineering responsibilities.   You are being asked to build out the next set of servers to integrate into the development environment. Your team is going from RHEL 8 to Rocky 9.4.   <ol> <li> <p>How might you start to plan out your migration?</p> </li> <li> <p>What are you going to check on the existing systems to baseline your build?</p> </li> <li> <p>What kind of validation plan might you use for your new Rocky 9.4 systems?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u13ws/#definitions","title":"Definitions","text":"<p>Hardening:</p> <p>Pipeline:</p> <p>Change management (IT):</p> <p>Security Standard:</p> <p>Security Posture:</p> <p>Acceptable Risk:</p> <p>NIST 800-53:</p> <p>STIG:</p> <p>CIS Benchmark:</p> <p>OpenSCAP:</p> <p>SCC Tool:</p> <p>HIDS:</p> <p>HIPS:</p>"},{"location":"lac/u13ws/#digging-deeper-optional","title":"Digging Deeper (Optional)","text":"<ol> <li> <p>Run through this lab: https://killercoda.com/het-tanis/course/Linux-Labs/107-server-startup-process</p> </li> <li> <p>How does this help you better understand the discussion 13-2 question?</p> </li> <li> <p>Run through this lab: https://killercoda.com/het-tanis/course/Linux-Labs/203-updating-golden-image</p> </li> <li>How does this help you better understand the process of hardening systems?</li> </ol>"},{"location":"lac/u13ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How can you apply this now in your current role in IT?    If you\u2019re not in IT, how can you look to put something like this into your resume or    portfolio?</p> </li> </ol>"},{"location":"lac/u14b/","title":"U14b","text":""},{"location":"lac/u14b/#objective","title":"Objective","text":"<p>Expand your Ansible skills by creating a self-documenting automation system that:</p> <ul> <li>Collects system information from multiple servers</li> <li>Stores the results in timestamped reports</li> <li>Sends the output via a webhook to simulate automation integration with external systems (like Slack, Discord, or CI/CD pipelines)</li> </ul>"},{"location":"lac/u14b/#part-1-system-info-playbook","title":"Part 1: System Info Playbook","text":"<p>Create a new file <code>collect_info.yaml</code> with the following content:</p> <pre><code>- name: Collect system info and log results\n  hosts: servers\n  gather_facts: yes\n  vars:\n    outdir: /tmp/ansible_reports\n  tasks:\n    - name: Ensure output directory exists\n      file:\n        path: \"{{ outdir }}\"\n        state: directory\n        mode: \"0755\"\n\n    - name: Create system report\n      copy:\n        content: |\n          Hostname: {{ ansible_hostname }}\n          IP: {{ ansible_default_ipv4.address }}\n          Uptime: {{ ansible_uptime_seconds }} seconds\n          Memory: {{ ansible_memtotal_mb }} MB\n        dest: \"{{ outdir }}/report_{{ inventory_hostname }}_{{ ansible_date_time.iso8601_basic_short }}.txt\"\n</code></pre> <p>Run the playbook with:</p> <pre><code>ansible-playbook -i hosts -k collect_info.yaml\n</code></pre>"},{"location":"lac/u14b/#part-2-webhook-integration","title":"Part 2: Webhook Integration","text":"<p>Send a short success message to a Discord webhook when the job completes.</p> <p>Append this task to the end of your <code>tasks:</code> list in <code>collect_info.yaml</code>:</p> <pre><code>- name: Notify via webhook\n  uri:\n    url: https://discord.com/api/webhooks/your_webhook_url\n    method: POST\n    headers:\n      Content-Type: \"application/json\"\n    body_format: json\n    body:\n      content: \"Ansible report job completed for {{ inventory_hostname }} at {{ ansible_date_time.iso8601 }}\"\n</code></pre> <p>Replace <code>your_webhook_url</code> with your actual Discord webhook.</p>"},{"location":"lac/u14b/#bonus-challenge","title":"Bonus Challenge","text":"<ul> <li>Modify the playbook to install a package (<code>htop</code>, <code>tree</code>, or <code>vim</code>) only if it\u2019s missing.</li> <li>Schedule the playbook to run nightly using <code>cron</code> or a <code>systemd</code> timer.</li> </ul>"},{"location":"lac/u14intro/","title":"Ansible Automation","text":""},{"location":"lac/u14intro/#overview","title":"Overview","text":"<p>This unit introduces Ansible Automation, a powerful open-source tool used for IT automation, configuration management, and application deployment. By the end of this unit, you will understand how to implement Ansible in enterprise environments to manage Linux infrastructure efficiently.</p> <ol> <li>Configuration Management: Automate system configurations across multiple hosts.</li> <li>Infrastructure as Code (IaC): Define infrastructure using Ansible playbooks.</li> <li>Automation: Execute tasks across multiple systems in an efficient, repeatable manner.</li> </ol>"},{"location":"lac/u14intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you should be able to:</p> <ul> <li>Set up and configure Ansible on a Linux system.</li> <li>Understand Ansible inventory and playbooks.</li> <li>Automate common administrative tasks.</li> <li>Use ad-hoc commands and Ansible modules effectively.</li> </ul>"},{"location":"lac/u14intro/#relevance-context","title":"Relevance &amp; Context","text":"<ol> <li>Consistency: Automate repetitive tasks to ensure uniform configurations.</li> <li>Scalability: Manage thousands of servers with minimal manual intervention.</li> <li>Security &amp; Compliance: Enforce policies and reduce misconfigurations.</li> </ol>"},{"location":"lac/u14intro/#prerequisites","title":"Prerequisites","text":"<p>Before beginning this unit, ensure you understand:</p> <ol> <li>Basic Linux command-line operations.</li> <li>SSH and remote system management.</li> <li>YAML syntax and basic scripting.</li> </ol>"},{"location":"lac/u14intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Playbook</p> <p>Task</p> <p>Inventory</p> <p>Ad-hoc Commands</p> <p>Roles</p>"},{"location":"lac/u14lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u14lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Ansible Documentation</li> <li>Killercoda - Ansible Labs</li> <li>HPC_Deploy Repo</li> </ul>"},{"location":"lac/u14lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u14lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u14_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u14_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u14lab/#warmup-exercises","title":"Warmup Exercises","text":"<p>Quickly run through your system and familiarize yourself:</p> <pre><code>mkdir /root/ansible_madness\ncd /root/ansible_madness\ndnf whatprovides ansible   # Where is Ansible installed from?\nansible --version          # What version of Ansible is installed?\nansible-&lt;TAB&gt;              # What other ansible-* tools are available?\nansible localhost -m shell -a uptime  # Compare with standalone `uptime`\nansible -vvv localhost -m shell -a uptime  # What extra info does -vvv show?\n</code></pre>"},{"location":"lac/u14lab/#lab-exercises","title":"Lab Exercises","text":""},{"location":"lac/u14lab/#create-an-inventory-file","title":"Create an Inventory File","text":"<p>While in <code>/root/ansible_madness</code>, create a file called <code>hosts</code>:</p> <pre><code>vi /root/ansible_madness/hosts\n</code></pre> <p>Add the following contents:</p> <pre><code>[servers]\n192.168.200.101\n192.168.200.102\n192.168.200.103\n</code></pre>"},{"location":"lac/u14lab/#run-ad-hoc-commands","title":"Run Ad Hoc Commands","text":""},{"location":"lac/u14lab/#test-connectivity-into-the-servers","title":"Test connectivity into the servers:","text":"<pre><code>ansible servers -i hosts -u inmate -k -m shell -a uptime\n</code></pre> <ul> <li>Use password: <code>LinuxR0cks1!</code></li> </ul> <p>Verbose version:</p> <pre><code>ansible -vvv servers -i hosts -u inmate -k -m shell -a uptime\n</code></pre>"},{"location":"lac/u14lab/#create-a-playbook-to-push-files","title":"Create a Playbook to Push Files","text":"<ol> <li>Create a test file:</li> </ol> <pre><code>echo \"This is my file &lt;yourname&gt;\" &gt; somefile\n</code></pre> <ol> <li>Create <code>deploy.yaml</code>:</li> </ol> <pre><code>hosts: servers\nvars:\ngather_facts: True\nbecome: False\ntasks:\n  - name: Copy somefile over at {{ ansible_date_time.iso8601_basic_short }}\n    copy:\n      src: /root/ansible_madness/somefile\n      dest: /tmp/somefile.txt\n</code></pre> <ol> <li>Run the playbook:</li> </ol> <pre><code>ansible-playbook -i hosts -k deploy.yaml\n</code></pre> <ol> <li>Verify the file was pushed everywhere:</li> </ol> <pre><code>ansible servers -i hosts -u inmate -k -m shell -a \"ls -l /tmp/somefile\"\n</code></pre>"},{"location":"lac/u14lab/#pull-down-a-github-repo","title":"Pull Down a GitHub Repo","text":"<pre><code>git clone https://github.com/het-tanis/HPC_Deploy.git\ncd HPC_Deploy\n</code></pre> <p>Then reflect:</p> <ul> <li>What do you see in here?</li> <li>What do you need to learn more about to deploy some of these tools?</li> <li>Can you execute some of these? Why or why not?</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u14ws/","title":"Worksheet","text":""},{"location":"lac/u14ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u14ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Official Ansible Documentation</li> <li>Ansible GitHub Repository</li> <li>YAML Syntax Guide</li> </ul>"},{"location":"lac/u14ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u14_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u14_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u14ws/#unit-14-recording","title":"Unit 14 Recording","text":""},{"location":"lac/u14ws/#discussion-post-1","title":"Discussion Post 1","text":"<p>Refer to your Unit 5 scan of the systems.</p>   You know that Ansible is a tool that you want to maintain in the environment. Review this online documentation:  <p></p> <ol> <li>Make an inventory of the servers, grouped any way you like.</li> <li>What format did you choose to use for your inventory?</li> <li>What other things might you include later in your inventory to make it more useful?</li> </ol>"},{"location":"lac/u14ws/#discussion-post-2","title":"Discussion Post 2","text":"You have been noticing drift on your server configurations, so you want a way to generate a report on them every day to validate the configurations are the same.   <p>Use any lab in here to find ideas: https://killercoda.com/het-tanis/course/Ansible-Labs</p>"},{"location":"lac/u14ws/#discussion-post-3","title":"Discussion Post 3","text":"<p>Using ansible module for git, pull down this repo: https://github.com/het-tanis/HPC_Deploy.git</p> <ol> <li>How is the repo setup?</li> <li>What is in the roles directory?</li> <li>How are these playbooks called, and how do roles differ from tasks?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u14ws/#definitions","title":"Definitions","text":"<p>Automation:</p> <p>Consistency:</p> <p>Dev/Ops:</p> <p>Timelines:</p> <p>Git:</p> <p>Repository:</p> <p>Ad-hoc:</p> <p>Playbook:</p> <p>Task:</p> <p>Role:</p> <p>SSH (Secure Shell):</p> <p>WinRM (Windows Remote Management):</p>"},{"location":"lac/u14ws/#digging-deeper-optional","title":"Digging Deeper (Optional)","text":"<ol> <li> <p>I have a large amount of labs to get you started on your Ansible Journey (all free):    https://killercoda.com/het-tanis/course/Ansible-Labs</p> </li> <li> <p>Find projects from our channel Ansible-Code, in Discord and find something that is interesting to you.</p> </li> <li> <p>Use Ansible to access secrets from Hashicorp Vault:    https://killercoda.com/het-tanis/course/Hashicorp-Labs/004-vault-read-secrets-ansible</p> </li> </ol>"},{"location":"lac/u14ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How can you apply this now in your current role in IT?</p> </li> <li> <p>If you\u2019re not in IT, how can you look to put something like this into your resume or portfolio?</p> </li> </ol>"},{"location":"lac/u15intro/","title":"Troubleshooting","text":""},{"location":"lac/u15intro/#overview","title":"Overview","text":"<p>In this unit, we focus on incident management, root cause analysis, and troubleshooting frameworks. These are foundational skills for Linux administrators who are responsible for maintaining system reliability and responding effectively to issues.</p> <p>You\u2019ll explore structured approaches like the Scientific Method, 5 Whys, FMEA, and PDCA, as well as methodologies like Six Sigma, TQM, and systems thinking. We\u2019ll also look at tools for visual problem solving, including the Fishbone Diagram and Fault Tree Analysis, and discuss how data types play a role in investigations.</p>"},{"location":"lac/u15intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you will be able to:</p> <ul> <li>Apply the Scientific Method to real-world troubleshooting scenarios</li> <li>Understand and use structured methods like FMEA, 5 Whys, and PDCA</li> <li>Differentiate between continuous and discrete data in diagnostics</li> <li>Use visual tools like Fishbone Diagrams and Fault Tree Analysis to trace causes</li> <li>Explain the OSI model as it applies to layered troubleshooting</li> <li>Leverage concepts from Six Sigma and 5S methodology to organize your workflows</li> <li>Document and communicate incidents effectively with post-mortem writeups</li> </ul>"},{"location":"lac/u15intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Troubleshooting is not guesswork \u2014 it\u2019s a discipline. Whether you\u2019re debugging a failed deployment or analyzing a high watermark in system performance, incident management requires both technical skill and structured reasoning.</p> <p>This unit bridges engineering troubleshooting and administrative troubleshooting, providing multiple models to approach problems methodically. These frameworks are used by professionals across industries to maintain uptime, solve complex problems, and continuously improve system reliability.</p>"},{"location":"lac/u15intro/#prerequisites","title":"Prerequisites","text":"<p>Before starting Unit 15, you should have:</p> <ul> <li>A working knowledge of Linux system administration</li> <li>Familiarity with logs, alerts, and system metrics</li> <li>Understanding of basic monitoring and baseline performance concepts</li> <li>Comfort using Linux command-line tools and interpreting output</li> </ul>"},{"location":"lac/u15intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Incident</p> <p>Problem</p> <p>FMEA</p> <p>Six Sigma</p> <p>TQM</p> <p>Post Mortem</p> <p>Scientific Method</p> <p>Iterative</p> <p>Discrete data</p> <ul> <li>Ordinal</li> <li>Nominal (binary - attribute)</li> </ul> <p>Continuous data</p> <p>Risk Priority Number (RPN)</p> <p>5 Whys</p> <p>Fishbone Diagram (Ishikawa)</p> <p>Fault Tree Analysis (FTA)</p> <p>PDCA</p> <p>SIPOC</p>"},{"location":"lac/u15lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u15lab/#under-construction","title":"Under Construction","text":""},{"location":"lac/u15lab/#resources-important-links","title":"Resources / Important Links","text":""},{"location":"lac/u15lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u15lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u15_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u15_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u15ws/","title":"Worksheet","text":""},{"location":"lac/u15ws/#under-construction","title":"Under Construction","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u15ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Six Sigma Intro</li> </ul>"},{"location":"lac/u15ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u15_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u15_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u15ws/#unit-2-recording","title":"Unit 2 Recording","text":""},{"location":"lac/u15ws/#unit-2-discussion-post-1","title":"Unit 2 Discussion Post #1","text":"<p>Scenario:</p>   Your management is all fired up about implementing some Six Sigma processes around the company. You decide to familiarize yourself and get some basic understanding to pass along to your team [Six Sigma Intro](https://www.sixsigmacouncil.org/wp-content/uploads/2018/08/Six-Sigma-A-Complete-Step-by-Step-Guide.pdf)   <ol> <li>Page 56 \u2013 What about the \u201c5S\u201d methodology might help us as a team of system administrators? (Think of your virtual or software workspaces)</li> <li>Page 94 - What are the four layers of process definition? How would you explain them to your junior engineers?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Post 1</li> </ul>"},{"location":"lac/u15ws/#unit-2-discussion-post-2","title":"Unit 2 Discussion Post #2","text":"<p>Your team looks at a lot of visual data. You decide to write up an explanation for them to explain what they look at.</p> <ol> <li>What is a high water mark? Why might it be good to know in utilization of systems?</li> <li>What is an upper and lower control limit in a system output? While this isn\u2019t exactly    what we\u2019re looking at, why might it be good to explain to your junior engineers</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Post 2</li> </ul>"},{"location":"lac/u15ws/#definitions","title":"Definitions","text":"<p>Incident:</p> <p>Problem:</p> <p>FMEA:</p> <p>Six Sigma:</p> <p>TQM:</p> <p>Post Mortem:</p> <p>Scientific Method:</p> <p>Iterative:</p> <p>Discrete data:</p> <p>Ordinal:</p> <p>Nominal (binary \u2013 attribute):</p> <p>Continuous data:</p> <p>Risk Priority Number (RPN):</p> <p>5 Whys:</p> <p>Fishbone Diagram (Ishikawa):</p> <p>Fault Tree Analysis (FTA):</p> <p>PDCA:</p> <p>SIPOC:</p>"},{"location":"lac/u15ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>Spend more time in Six Sigma Intro    a. Page 243 \u2013 Starts looking at visual data analysis.</li> <li>Get your White belt (Free) Six Sigma Certification.</li> </ol>"},{"location":"lac/u15ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li>What questions do you still have about this week?</li> <li>How can you apply this now in your current role in IT? If you\u2019re not in IT, how can you look to put something like this into your resume or portfolio?</li> </ol>"},{"location":"lac/u16intro/","title":"Incident Response","text":""},{"location":"lac/u16intro/#under-construction","title":"Under Construction","text":""},{"location":"lac/u16lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u16lab/#under-construction","title":"Under Construction","text":""},{"location":"lac/u16lab/#resources-important-links","title":"Resources / Important Links","text":""},{"location":"lac/u16lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u16lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u16_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u16_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u16ws/","title":"Worksheet","text":""},{"location":"lac/u16ws/#under-construction","title":"Under Construction","text":""},{"location":"lac/u1b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p>"},{"location":"lac/u1b/#module-1-getting-started-days-1-2","title":"Module 1: Getting Started (Days 1-2)","text":""},{"location":"lac/u1b/#day-1-first-contact-with-vim","title":"Day 1: First Contact with VIM","text":"<p>Segment 1: The Basics</p> <ol> <li>Complete first section of <code>vimtutor</code></li> <li>Learn essential commands:</li> <li><code>vim filename</code> - Open/create file</li> <li><code>i</code> - Enter insert mode</li> <li><code>Esc</code> - Return to normal mode</li> <li><code>:w</code> - Save changes</li> <li><code>:q</code> - Quit</li> <li><code>:wq</code> or <code>ZZ</code> - Save and quit</li> <li><code>:q!</code> - Quit without saving</li> </ol> <p>Segment 2: Building Muscle Memory</p> <ol> <li>Create five different files</li> <li>Practice mode switching 50 times</li> <li>Write and save content in each file</li> <li>Practice recovering from common mistakes:</li> <li>Accidentally pressed keys in normal mode</li> <li>Forgot to enter insert mode</li> <li>Trying to quit without saving</li> </ol> <p>Segment 3: First Real Task</p> <ol> <li>Create a simple bash script template</li> <li>Add standard sections:</li> <li>Shebang line</li> <li>Comments</li> <li>Basic variables</li> <li>Simple functions</li> <li>Save and reopen multiple times</li> </ol>"},{"location":"lac/u1b/#day-2-comfort-zone","title":"Day 2: Comfort Zone","text":"<p>Segment 1: More Basic Operations</p> <ol> <li>Complete second section of <code>vimtutor</code></li> <li>Practice quick save and exit combinations</li> <li>Learn to read VIM messages and errors</li> <li>Understand modes in depth:</li> <li>Normal mode</li> <li>Insert mode</li> <li>Visual mode (introduction)</li> </ol> <p>Segment 2: Error Recovery</p> <ol> <li>Create deliberate errors and fix them:</li> <li>Write without insert mode</li> <li>Exit without saving needed changes</li> <li>Get stuck in different modes</li> <li>Practice until you can recover without thinking</li> </ol> <p>Segment 3: Real Config Practice</p> <ol> <li>Copy <code>/etc/hosts</code> file</li> <li>Make various modifications:</li> <li>Add new host entries</li> <li>Modify existing entries</li> <li>Add comments</li> <li>Save different versions</li> </ol>"},{"location":"lac/u1b/#module-2-navigation-days-3-4","title":"Module 2: Navigation (Days 3-4)","text":""},{"location":"lac/u1b/#day-3-basic-movement","title":"Day 3: Basic Movement","text":"<p>Segment 1: Core Movement Commands</p> <ul> <li>Master the basics:</li> <li><code>h</code> - Left</li> <li><code>j</code> - Down</li> <li><code>k</code> - Up</li> <li><code>l</code> - Right</li> <li><code>w</code> - Next word</li> <li><code>b</code> - Previous word</li> <li><code>0</code> - Line start</li> <li><code>$</code> - Line end</li> </ul> <p>Segment 2: Movement Drills</p> <ol> <li>Create a \"movement course\" file</li> <li>Practice moving between marked points</li> <li>Time your navigation speed</li> <li>Compete against your previous times</li> </ol> <p>Segment 3: Applied Navigation</p> <ol> <li>Navigate through <code>/etc/ssh/sshd_config</code>:</li> <li>Find specific settings</li> <li>Move between sections</li> <li>Locate comments</li> <li>Jump to line numbers</li> </ol>"},{"location":"lac/u1b/#day-4-advanced-movement","title":"Day 4: Advanced Movement","text":"<p>Segment 1: Extended Movement</p> <ul> <li>Learn efficient jumps:</li> <li><code>gg</code> - File start</li> <li><code>G</code> - File end</li> <li><code>{</code> - Previous paragraph</li> <li><code>}</code> - Next paragraph</li> <li><code>Ctrl+f</code> - Page down</li> <li><code>Ctrl+b</code> - Page up</li> </ul> <p>Segment 2: Speed Training</p> <ol> <li>Work with a large configuration file</li> <li>Practice jumping between sections</li> <li>Find specific lines quickly</li> <li>Navigate through code blocks</li> </ol> <p>Segment 3: Real-world Navigation</p> <ol> <li>Work with system logs</li> <li>Jump between error messages</li> <li>Navigate through long configuration files</li> <li>Practice quick file browsing</li> </ol>"},{"location":"lac/u1b/#module-3-essential-editing-days-5-7","title":"Module 3: Essential Editing (Days 5-7)","text":""},{"location":"lac/u1b/#day-5-basic-editing","title":"Day 5: Basic Editing","text":"<p>Segment 1: Edit Commands</p> <ul> <li>Master core editing:</li> <li><code>x</code> - Delete character</li> <li><code>dd</code> - Delete line</li> <li><code>yy</code> - Copy line</li> <li><code>p</code> - Paste after</li> <li><code>P</code> - Paste before</li> <li><code>u</code> - Undo</li> <li><code>Ctrl + r</code> - Redo</li> </ul> <p>Segment 2: Editing Drills</p> <ol> <li>Create practice documents</li> <li>Delete and replace text</li> <li>Copy and paste sections</li> <li>Practice undo/redo chains</li> </ol> <p>Segment 3: System File Editing</p> <ol> <li>Work with <code>/etc/fstab</code> copy:</li> <li>Add mount points</li> <li>Remove entries</li> <li>Comment lines</li> <li>Fix formatting</li> </ol>"},{"location":"lac/u1b/#day-6-intermediate-editing","title":"Day 6: Intermediate Editing","text":"<p>Segment 1: Combined Commands</p> <ul> <li>Learn efficient combinations:</li> <li><code>dw</code> - Delete word</li> <li><code>d$</code> - Delete to line end</li> <li><code>d0</code> - Delete to line start</li> <li><code>cc</code> - Change whole line</li> <li><code>cw</code> - Change word</li> </ul> <p>Segment 2: Practical Application</p> <ol> <li>Edit service configuration files</li> <li>Modify system settings</li> <li>Update network configurations</li> <li>Clean up log files</li> </ol> <p>Segment 3: Speed Challenges</p> <ol> <li>Timed editing tasks</li> <li>Configuration file cleanup</li> <li>Quick text transformation</li> <li>Error correction sprints</li> </ol>"},{"location":"lac/u1b/#day-7-editing-mastery","title":"Day 7: Editing Mastery","text":"<p>Segment 1: Advanced Operations</p> <ul> <li>Master text objects:</li> <li><code>ciw</code> - Change inner word</li> <li><code>ci\"</code> - Change inside quotes</li> <li><code>di(</code> - Delete inside parentheses</li> <li><code>yi{</code> - Yank inside braces</li> </ul> <p>Segment 2: Integration Practice</p> <ol> <li>Combine all learned commands</li> <li>Work with multiple files</li> <li>Practice common scenarios</li> <li>Time your operations</li> </ol>"},{"location":"lac/u1b/#daily-success-metrics","title":"Daily Success Metrics","text":"<p>By end of each day, you should be able to:</p> <ul> <li>Day 1: Open, edit, save, and exit files confidently</li> <li>Day 2: Understand and recover from common errors</li> <li>Day 3: Navigate small files without arrow keys</li> <li>Day 4: Move through large files efficiently</li> <li>Day 5: Perform basic edits without hesitation</li> <li>Day 6: Combine movement and editing commands</li> <li>Day 7: Edit configuration files with confidence</li> </ul>"},{"location":"lac/u1b/#practice-tips","title":"Practice Tips","text":"<ol> <li>Use <code>vimtutor</code> during breaks</li> <li>Disable arrow keys completely</li> <li>Keep a command log of new discoveries</li> <li>Time your editing operations</li> <li>Practice with real system files (copies)</li> </ol> <p>Remember: Focus on accuracy first, then build speed.</p>"},{"location":"lac/u1b/#downloads","title":"Downloads","text":""},{"location":"lac/u1intro/","title":"Linux File Operations","text":""},{"location":"lac/u1intro/#overview","title":"Overview","text":"<p>This unit introduces the foundational skills needed for effective Linux system administration with an emphasis on Red Hat Enterprise Linux (RHEL). It covers:</p> <ul> <li> <p>Command-Line Proficiency: Mastery of the shell environment is essential for routine tasks such as navigating the file system, managing processes, and automating scripts.</p> </li> <li> <p>Text Editing with VI/Vim: Given that many RHEL systems use VI/Vim as the default editor for configuration and scripting, learners are introduced to these tools through practical exercises like using vimtutor and exploring interactive resources (e.g., VIM Adventures).</p> </li> <li> <p>Understanding the Linux File System: The worksheet emphasizes the standard Linux file hierarchy\u2014critical for managing files, permissions, and services in a Red Hat environment.</p> </li> <li> <p>Basic Utilities and System Management: Along with the command-line and text editors, the unit touches on fundamental utilities that are pivotal for system configuration, troubleshooting, and maintenance on enterprise systems.</p> </li> </ul>"},{"location":"lac/u1intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Master Command-Line Fundamentals:</p> </li> <li> <p>Develop proficiency in navigating the Linux command-line interface (CLI) for everyday system management tasks.</p> </li> <li> <p>Learn how to execute commands to manipulate files, directories, and system processes efficiently.</p> </li> <li> <p>Understand the Linux File System:</p> </li> <li> <p>Grasp the structure and organization of the Linux file hierarchy.</p> </li> <li> <p>Comprehend how the file system affects system configuration, security, and troubleshooting on Red Hat platforms.</p> </li> <li> <p>Gain Proficiency in Text Editing with VI/Vim:</p> </li> <li> <p>Acquire hands-on experience with vi/vim through guided exercises (e.g., vimtutor, VIM Adventures).</p> </li> <li> <p>Learn to edit configuration files and scripts accurately, which is critical for system administration.</p> </li> <li> <p>Engage with Practical System Administration Tasks:</p> </li> <li> <p>Explore foundational utilities and commands essential for managing a Linux system.</p> </li> <li>Apply theoretical knowledge through real-world examples, discussion posts, and interactive resources to reinforce learning.</li> </ol> <p>These objectives are designed to ensure that learners not only acquire technical competencies but also understand how these skills integrate into broader system administration practices in a Red Hat environment.</p>"},{"location":"lac/u1intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>The skills taught in this unit are indispensable for several reasons:</p> <ul> <li> <p>Efficient System Management:   The RHEL environment is typically managed via the command line. Proficiency in the CLI, along with an in-depth understanding of the file system, is crucial for daily tasks like system configuration, package management (using tools such as YUM or DNF), and remote troubleshooting.</p> </li> <li> <p>Security and Stability:   Editing configuration files, managing system services, and monitoring logs are all critical tasks that ensure the secure and stable operation of RHEL systems. A robust understanding of these basics is necessary to mitigate risks and ensure compliance with enterprise security standards.</p> </li> <li> <p>Professional Certification &amp; Career Growth:   For those pursuing certifications like the Red Hat Certified System Administrator (RHCSA) or Red Hat Certified Engineer (RHCE), these foundational skills are not only testable requirements but also a stepping stone for more advanced topics such as automation (using Ansible), container management (with Podman or OpenShift), and performance tuning.</p> </li> <li> <p>Operational Excellence:   In enterprise settings where uptime and rapid incident response are paramount, having a solid grasp of these fundamentals enables administrators to quickly diagnose issues, apply fixes, and optimize system performance\u2014thereby directly impacting business continuity and service quality.</p> </li> </ul>"},{"location":"lac/u1intro/#prerequisites","title":"Prerequisites","text":"<p>The unit assumes a basic level of computer literacy, meaning the learner is comfortable with fundamental computer operations. However, before achieving that level, one must have digital literacy. This involves:</p> <ul> <li> <p>Familiarity with Computer Hardware:   Understanding what a computer is, how to power it on/off, and how to use basic peripherals (keyboard, mouse, monitor). This foundational comfort enables users to interact with a computer effectively.</p> </li> <li> <p>Basic Software Navigation:   Knowing how to use common applications like web browsers, file managers, or simple text editors. This prior exposure helps learners transition into more specialized areas (like command-line interfaces) without being overwhelmed.</p> </li> <li> <p>Understanding Core Concepts:   Grasping the basic idea of files, directories, and simple interactions with the operating system lays the groundwork for later learning. Without this, even basic computer literacy may be hard to achieve.</p> </li> </ul>"},{"location":"lac/u1intro/#key-terms-and-definitions","title":"Key terms and Definitions","text":"<p>Linux Kernel</p> <p>Command-Line Interface (CLI)</p> <p>Shell</p> <p>Terminal</p> <p>Filesystem Hierarchy</p> <p>Package Manager (e.g., YUM/DNF)</p> <p>Text Editors (VI/Vim)</p> <p>Sudo</p> <p>File Permissions and Ownership</p> <p>Processes and Daemons</p> <p>System Logs</p> <p>Networking Basics</p> <p>Bash Scripting</p>"},{"location":"lac/u1lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u1lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Top 50+ Linux CLI Commands</li> </ul>"},{"location":"lac/u1lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u1lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u1_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u1_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u1lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <pre><code>mkdir lab_essentials\ncd lab_essentials\nls\ntouch testfile1\nls\ntouch testfile{2..10}\nls\n\n# What does this do differently?\n# Can you figure out what the size of those files are in bytes? What command did you use?\n\ntouch file.`hostname`\ntouch file.`hostname`.`date +%F`\ntouch file.`hostname`.`date +%F`.`date +%s`\nls\n\n# What do each of these values mean? `man date` to figure those values out.\n\n# Try to set the following values in the file\n\n# year, just two digits\n# today's day of the month\n# Just the century\n\ndate +%y\ndate +%e\ndate +%C\n</code></pre>"},{"location":"lac/u1lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to help you get familiar with the basics of the systems you will be working on. Some of you will find that you know the basic material but the techniques here allow you to put it together in a more complex fashion.</p> <p>It is recommended that you type these commands and do not copy and paste them. Word sometimes likes to format characters and they don\u2019t always play nice with Linux.</p>"},{"location":"lac/u1lab/#working-with-files","title":"Working with files:","text":"<pre><code># Creating empty files with touch\ntouch fruits.txt\n\nls -l fruits.txt\n# You will see that fruits.txt exists and is a 0 length (bytes) file\n\n-rw-r--r--. 1 root root 0 Jun 22 07:59 fruits.txt\n# Take a look at those values and see if you can figure out what they mean.\n# man touch and see if it has any other useful features you might use. If\n# you\u2019ve ever used tiered storage think about access times and how to keep data\n# hot/warm/cold. If you haven\u2019t just look around for a bit.\n\nrm -rf fruits.txt\n\nls -l fruits.txt\n# You will see that fruits.txt is gone.\n</code></pre>"},{"location":"lac/u1lab/#creating-files-just-by-stuffing-data-in-them","title":"Creating files just by stuffing data in them:","text":"<pre><code>echo \u201cgrapes 5\u201d &gt; fruits.txt\ncat fruits.txt\necho \u201capples 3\u201d &gt; fruits.txt\ncat fruits.txt\n\necho \u201c \u201c &gt; fruits.txt\n\necho \u201cgrapes 5\u201d &gt;&gt; fruits.txt\ncat fruits.txt\necho \u201capples 3\u201d &gt;&gt; fruits.txt\ncat fruits.txt\n</code></pre> <p>What is the difference between these two? Appending a file &gt;&gt; adds to the file whereas &gt; just overwrites the file each write. Log files almost always are written with &gt;&gt;, we never &gt; over those types of files.</p>"},{"location":"lac/u1lab/#creating-file-with-vi-or-vim","title":"Creating file with vi or vim:","text":"<pre><code># It is highly recommended the user read vimtutor. To get vimtutor follow\n# these steps:\nsudo -i\nyum -y install vim\nvimtutor\n\n# There are about 36 short labs to show a user how to get around inside of vi.\n# There are also cheat sheets around to help.\n\nvi somefile.txt\n# type \u201ci\u201d to enter insert mode\n\n# Enter the following lines\ngrapes 5\napples 7\noranges 3\nbananas 2\npears 6\npineapples 9\n\n# hit the \u201cesc\u201d key at the top left of your keyboard\n# Type \u201c:wq\u201d\n# Hit enter\n\ncat somefile.txt\n</code></pre>"},{"location":"lac/u1lab/#copying-and-moving-files","title":"Copying and moving files:","text":"<pre><code>cp somefile.txt backupfile.txt\nls\ncat backupfile.txt\nmv somefile.txt fruits.txt\nls\ncat fruits.txt\n</code></pre> <p>Look at what happened in each of these scenarios. Can you explain the difference between cp and mv? Read the manuals for cp and mv to see if there\u2019s anything that may be useful to you. For most of us -r is tremendously useful option for moving directories.</p>"},{"location":"lac/u1lab/#searchingfiltering-through-files","title":"Searching/filtering through files:","text":"<pre><code># So maybe we only want to see certain values from a file, we can filter\n# with a tool called grep\n\ncat fruits.txt\ncat fruits.txt | grep apple\ncat fruits.txt | grep APPLE\n\n# read the manual for grep and see if you can cause it to ignore case.\n\n# See if you can figure out how to both ignore case and only find the\n# word apple at the beginning of the line.\n\n# If you can\u2019t, here\u2019s the the answer. Try it:\ncat fruits.txt | grep -i \"^apple\"\n</code></pre> <p>Can you figure out why that worked? What do you think the ^ does? Anchoring is a common term for this. See if you can find what anchors to the end of a string.</p>"},{"location":"lac/u1lab/#sorting-files-with-sort","title":"Sorting files with sort:","text":"<pre><code># Let\u2019s sort our file fruits.txt and look at what happens to the output\n# and the original file\n\nsort fruits.txt\ncat fruits.txt\n\n# Did the sort output come out different than the cat output? Did sorting\n# your file do anything to your original data? So let\u2019s sort our data again\n# and figure out what this command does differently\n\nsort -k 2 fruits.txt\n\n# You can of course man sort to figure it out, but -k refers to the \u201ckey\u201d and\n# can be useful for sorting by a specific column\n\n# But, if we cat fruits.txt we see we didn\u2019t save anything we did. What if we\n# wanted to save these outputs into a file. Could you do it? If you couldn\u2019t,\n# here\u2019s an answer:\n\nsort fruits.txt &gt; sort_by_alphabetical.txt\nsort -k 2 fruits.txt &gt; sort_by_price.txt\n\n# Cat both of those files out and verify their output\n</code></pre>"},{"location":"lac/u1lab/#advanced-sort-practice","title":"Advanced sort practice:","text":"<pre><code># Consider the command\nps -aux\n\n# But that\u2019s too long to probably see everything, so let\u2019s use a command\n# to filter just the top few lines\nps -aux | head\n\n# So now you can see the actual fields (keys) across the top that we could sort by\n\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND\n\n# So let\u2019s say we wanted to sort by %MEM\nps -aux | sort -k 4 -n -r | head -10\n</code></pre> <p>Read man to see why that works. Why do you suppose that it needs to be reversed to have the highest numbers at the top? What is the difference, if you can see any, between using the -n or not using it? You may have to use head -40 to figure that out, depending on your processes running.</p> <p>Read man ps to figure out what other things you can see or sort by from the ps command. We will examine that command in detail in another lab.</p>"},{"location":"lac/u1lab/#working-with-redirection","title":"Working with redirection:","text":"<p>The good thing is that you\u2019ve already been redirecting information into files. The &gt; and &gt;&gt; are useful for moving data into files. We have other functionality within redirects that can prove useful for putting data where we want it, or even not seeing the data.</p> <p>Catching the input of one command and feeding that into the input of another command We\u2019ve actually been doing this the entire time. \u201c|\u201d is the pipe operator and causes the output of one command to become the input of the second command.</p> <pre><code>cat fruits.txt | grep apple\n# This cats out the file, all of it, but then only shows the things that\n# pass through the filter of grep. We could continually add to these and make\n# them longer and longer\n\ncat fruits.txt | grep apple | sort | nl | awk \u2018{print $2}\u2019 | sort -r\npineapples\napples\ncat fruits.txt | grep apple | sort | nl | awk '{print $3}' | sort -r\n9\n7\ncat fruits.txt | grep apple | sort | nl | awk '{print $1}' | sort -r\n2\n1\n\n# Take these apart by pulling the end pipe and command off to see what is\n# actually happening:\n\ncat fruits.txt | grep apple | sort | nl | awk '{print $1}' | sort -r\n2\n1\ncat fruits.txt | grep apple | sort | nl | awk '{print $1}'\n1\n2\ncat fruits.txt | grep apple | sort | nl\n1 apples 7\n2 pineapples 9\ncat fruits.txt | grep apple | sort\napples 7\npineapples 9\ncat fruits.txt | grep apple\napples 7\npineapples 9\n</code></pre> <p>See if you can figure out what each of those commands do. Read the manual <code>man command</code> for any command you don\u2019t recognize. Use something you learned to affect the output.</p>"},{"location":"lac/u1lab/#throwing-the-output-into-a-file","title":"Throwing the output into a file:","text":"<p>We\u2019ve already used &gt; and &gt;&gt; to throw data into a file but when we redirect like that we are catching it before it comes to the screen. There is another tool that is useful for catching data and also showing it to us, that is tee.</p> <pre><code>date\n# comes to the screen\n\ndate &gt; datefile\n# redirects and creates a file datefile with the value\n\ndate | tee -a datefile\n# will come to screen, redirect to the file.\n</code></pre> <p>Do a quick man on tee to see what the -a does. Try it without that value. Can you see any other useful options in there for tee?</p>"},{"location":"lac/u1lab/#ignoring-pesky-errors-or-tossing-out-unwanted-output","title":"Ignoring pesky errors or tossing out unwanted output:","text":"<p>Sometimes we don\u2019t care when something errs out. We just want to see that it\u2019s working or not. If you\u2019re wanting to filter out errors (2) in the standarderr, you can do this</p> <pre><code>ls fruits.txt\n# You should see normal output\n\nls fruity.txt\n# You should see an error unless you made this file\n\nls fruity.txt 2&gt; /dev/null\n# You should no longer see the error.\n\n# But, sometimes you do care how well your script runs against 100 servers,\n# or you\u2019re testing and want to see those errors. You can redirect that to a file, just as easy\n\nls fruity.txt 2&gt; error.log\ncat error.log\n# You\u2019ll see the error. If you want it see it a few times do the error line to see it happen.\n</code></pre> <p>In one of our later labs we\u2019re going to look at stressing our systems out. For this, we\u2019ll use a command that basically just causes the system to burn cpu cycles creating random numbers, zipping up the output and then throwing it all away. Here\u2019s a preview of that command so you can play with it.</p> <p>May have to yum -y install bzip2 for this next one to work.</p> <pre><code>time dd if=/dev/urandom bs=1024k count=20 | bzip2 -9 &gt;&gt; /dev/null\n</code></pre> <p>Use \u201ccrtl + c\u201d to break if you use that and it becomes too long or your system is under too much load. The only numbers you can play with there are the 1024k and the count. Other numbers should be only changed if you use man to read about them first.</p> <p>This is the \u201cpoor man\u2019s\u201d answer file. Something we used to do when we needed to answer some values into a script or installer. This is still very accurate and still works, but might be a bit advanced with a lot of advanced topics in here. Try it if you\u2019d like but don\u2019t worry if you don\u2019t get this on the first lab.</p> <pre><code>vi testscript.sh\nhit \u201ci\u201d to enter insert mode\nadd the following lines:\n\n#!/bin/bash\n\nread value\necho \"The first value is $value\"\nread value\necho \"The second value is $value\"\nread value\necho \"The third value is $value\"\nread value\necho \"The fourth value is $value\"\n\n# hit \u201cesc\u201d key\ntype in :wq\n# hit enter\n\nchmod 755 testscript.sh\n\n# Now type in this (don\u2019t type in the &gt; those will just be there in your shell):\n\n[xgqa6cha@N01APL4244 ~]$ echo \"yes\n\n&gt; no\n&gt; 10\n&gt; why\" | ./testscript.sh\n&gt; yes\n&gt; no\n&gt; 10\n&gt; why\n</code></pre> <p>What happened here is that we read the input from command line and gave it, in order to the script to read and then output. This is something we do if we know an installer wants certain values throughout it, but we don\u2019t want to sit there and type them in, or we\u2019re doing it across 100 servers quickly, or all kinds of reasons. It\u2019s just a quick and dirty input \u201chack\u201d that counts as a redirect.</p>"},{"location":"lac/u1lab/#working-with-permissions","title":"Working with permissions:","text":"<p>Permissions have to do with who can or cannot access (read), edit (write), or execute (xecute)files.</p> <p>Permissions look like this.</p> <pre><code>ls -l\n</code></pre> Permission # of Links UID Owner Group Owner Size (b) Creation Month Creation Day Creation Time File Name -rw-r--r--. 1 Root root 58 Jun 22 08:52 datefile <p>The primary permissions commands we\u2019re going to use are going to be chmod (access) and chown (ownership).</p> <p>A quick rundown of how permissions break out:</p> <p></p> <p>Let\u2019s examine some permissions and see if we can\u2019t figure out what permissions are allowed.</p> <pre><code>ls -ld /root/\n# drwx. 5 root root 4096 Jun 22 09:11 /root/\n</code></pre> <p>The first character lets you know if the file is a directory, file, or link. In this case we are looking at my home directory.</p> <p><code>rwx</code>: For UID (me).</p> <ul> <li>What permissions do I have?</li> </ul> <p><code>---</code>: For group.</p> <ul> <li>Who are they?</li> <li>What can my group do?</li> </ul> <p><code>---</code>: For everyone else.</p> <ul> <li>What can everyone else do?</li> </ul> <p>Go find some other interesting files or directories and see what you see there. Can you identify their characteristics and permissions?</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u1ws/","title":"Worksheet","text":""},{"location":"lac/u1ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u1ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>What is Vim?</li> <li>The Linux Foundation</li> <li>Linux CLI Cheatsheets</li> </ul>"},{"location":"lac/u1ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u1_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u1_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u1ws/#unit-1-recording","title":"Unit 1 Recording","text":""},{"location":"lac/u1ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Using a 0-10 system, rate yourself on how well you think you know each topic in the table below. (You do not have to post this rating).</p> Skill High 8-10 Mid 4-7 Low 0-3 Total Linux Storage Security Networking Git Automation Monitoring Database Cloud Kubernetes Total <p>Next, answer these questions here:</p> <ol> <li> <p>What do you hope to learn in this course?</p> </li> <li> <p>What type of career path are you shooting for?</p> </li> </ol>"},{"location":"lac/u1ws/#discussion-post-2","title":"Discussion Post #2","text":"<ol> <li> <p>Post a job that you are interested in from a local job website. (link or image)</p> </li> <li> <p>What do you know how to do in the posting?</p> </li> <li> <p>What don't you know how to do in the posting?</p> </li> <li> <p>What are you doing to close the gap? What can you do to remedy the difference?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u1ws/#start-thinking-about-your-project-ideas-more-to-come-in-future-weeks","title":"Start thinking about your project ideas (more to come in future weeks):","text":"<p>Topics:</p> <ol> <li>System Stability</li> <li>System Performance</li> <li>System Security</li> <li>System monitoring</li> <li>Kubernetes</li> <li>Programming/Automation</li> </ol> <p>You will research, design, deploy, and document a system that improves your administration of Linux systems in some way.</p>"},{"location":"lac/u1ws/#definitions","title":"Definitions","text":"<p>Kernel:</p> <p>Kernel Args:</p> <p>OS Version:</p> <p>Modules:</p> <p>Mount Points:</p> <p>Text Editor:</p>"},{"location":"lac/u1ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Use vimtutor and see how far you get. What did you learn that you did not know about vi/vim?</p> </li> <li> <p>Go to https://vim-adventures.com/ and see how far you get. What did you learn that you did not already know about vi/vim?</p> </li> <li> <p>Go to https://www.youtube.com/watch?v=d8XtNXutVto and see how far you get with vim. What did you learn that you did not already know about vi/vim?</p> </li> </ol>"},{"location":"lac/u1ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you\u2019ve learned in your current role?</p> </li> </ol>"},{"location":"lac/u2intro/","title":"Essential Tools","text":""},{"location":"lac/u2intro/#overview","title":"Overview","text":"<p>This unit centers on a focus on security and troubleshooting.</p> <ul> <li>The use of SELinux for implementing mandatory access controls, managing file permissions with ACLs (Access Control Lists),</li> <li>Understanding operational methodologies for incident triage.</li> </ul>"},{"location":"lac/u2intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Understand and Configure SELinux:</p> </li> <li> <p>Grasp the core concepts of SELinux, including security contexts, labels, and its role in enforcing mandatory access control.</p> </li> <li> <p>Learn how to configure and troubleshoot SELinux settings to ensure system security and compliance.</p> </li> <li> <p>Master Access Control Lists (ACLs):</p> </li> <li> <p>Recognize the limitations of traditional Unix permissions and how ACLs provide granular control over file and directory access.</p> </li> <li> <p>Develop skills in applying and managing ACLs in a complex Linux environment.</p> </li> <li> <p>Develop Effective Troubleshooting Methodologies:</p> </li> <li> <p>Acquire techniques to diagnose and resolve system access issues, particularly those arising from SELinux policies and ACL misconfigurations.</p> </li> <li> <p>Apply structured troubleshooting strategies to ensure minimal downtime and maintain high availability.</p> </li> <li> <p>Integrate Theoretical Knowledge with Practical Application:</p> </li> <li> <p>Engage with interactive exercises, discussion prompts, and real-world scenarios to reinforce learning.</p> </li> <li> <p>Utilize external resources, such as technical documentation and instructional videos, to supplement hands-on practice.</p> </li> <li> <p>Enhance Collaborative Problem-Solving Skills:</p> </li> <li> <p>Participate in peer discussions and reflective exercises to compare different approaches to system administration challenges.</p> </li> <li> <p>Learn to articulate and document troubleshooting processes and system configurations for continuous improvement.</p> </li> <li> <p>Build a Foundation for Advanced Security Practices:</p> </li> <li>Understand how SELinux and ACLs fit into the broader context of system security and operational stability.</li> <li>Prepare for more advanced topics by reinforcing the fundamental skills needed to manage and secure Red\u00a0Hat Enterprise Linux environments.</li> </ol> <p>These objectives aim to ensure that learners not only acquire specific technical skills but also develop a holistic understanding of how to secure and manage Linux systems in enterprise settings.</p>"},{"location":"lac/u2intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>For Linux administrators and engineers, mastering SELinux and ACLs is essential because these tools add critical layers of security and control over system resources. By understanding how to use security contexts and labels, professionals can:</p> <ul> <li> <p>Enhance System Security: Implementing SELinux helps mitigate vulnerabilities by enforcing strict access controls.</p> </li> <li> <p>Troubleshoot Access Issues: Knowledge of ACLs and SELinux enables the identification and resolution of permission-related issues, which are common in complex, multi-user environments.</p> </li> <li> <p>Improve System Reliability: Understanding these concepts supports the broader goal of maintaining high availability and operational stability, especially when systems must operate under varying security configurations.</p> </li> </ul>"},{"location":"lac/u2intro/#prerequisites","title":"Prerequisites","text":"<p>Before engaging with this unit, readers should have a foundational understanding of:</p> <ul> <li> <p>Basic Linux Commands and File System Structure: Familiarity with navigating Linux directories, managing files, and using the terminal.</p> </li> <li> <p>Traditional Unix Permissions: A solid grasp of the standard user/group/other permission model.</p> </li> <li> <p>Fundamental Security Principles: An introductory knowledge of concepts like Discretionary Access Control (DAC) and Mandatory Access Control (MAC), which provide the groundwork for understanding SELinux.</p> </li> <li> <p>Basic Troubleshooting Techniques: Experience with diagnosing and resolving common system issues will be beneficial when applying the methodologies discussed in the unit.</p> </li> </ul>"},{"location":"lac/u2intro/#key-terms-and-definitions","title":"Key terms and Definitions","text":"<p>SELinux (Security-Enhanced Linux)</p> <p>Access Control Lists (ACLs)</p> <p>Security Contexts</p> <p>Mandatory Access Control (MAC)</p> <p>Discretionary Access Control (DAC)</p> <p>Uptime</p> <p>Standard Streams (stdin, stdout, stderr)</p> <p>High Availability (HA)</p> <p>Service Level Objectives (SLOs)</p> <p>Troubleshooting Methodologies</p>"},{"location":"lac/u2lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u2lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Top 50+ Linux CLI Commands</li> </ul>"},{"location":"lac/u2lab/#required-materials","title":"Required Materials","text":"<ul> <li>Putty or other connection tool</li> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u2lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u2_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u2_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u2lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <pre><code>cd ~\nls\nmkdir evaluation\nmkdir evaluation/test/round6\n# This fails, can you find out why?\n\nmkdir -p evaluation/test/round6\n# This works, think about why?\n\ncd evaluation\npwd\n# What is the path you are in?\n\ntouch testfile1\nls\n# What did this do?\n\ntouch testfile{2..10}\nls\n# What did this do differently than earlier?\n# touch .hfile .hfile2 .hfile3\n\nls\n# Can you see your newest files? Why or why not? (man ls)\n# What was the command to let you see those hidden files?\n\nls -l\n# What do you know about this long listing? Think about 10 things this can show you.\n# Did it show you all the files or are some missing?\n</code></pre>"},{"location":"lac/u2lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to help you get familiar with the basics of the systems you will be working on. Some of you will find that you know the basic material but the techniques here allow you to put it together in a more complex fashion.</p> <p>It is recommended that you type these commands and do not copy and paste them. Word sometimes likes to format characters and they don\u2019t always play nice with Linux.</p>"},{"location":"lac/u2lab/#gathering-system-information","title":"Gathering system information:","text":"<pre><code>hostname\ncat /etc/*release\n# What do you recognize about this output? What version of RHEL (CENTOS) are we on?\n\nuname\nuname -a\nuname -r\n\n# man uname to see what those options mean if you don\u2019t recognize the values\n</code></pre>"},{"location":"lac/u2lab/#check-the-amount-of-ram","title":"Check the amount of RAM:","text":"<pre><code>cat /proc/meminfo\nfree\nfree -m\n\n# What do each of these commands show you? How are they useful?\n</code></pre>"},{"location":"lac/u2lab/#check-the-number-of-processors-and-processor-info","title":"Check the number of processors and processor info:","text":"<pre><code>cat /proc/cpuinfo\n# What type of processors do you have? How many are there? (counting starts at 0)\n\ncat /proc/cpuinfo | grep proc | wc -l\n# Does this command accurately count the processors?\n</code></pre>"},{"location":"lac/u2lab/#check-storage-usage-and-mounted-filesystems","title":"Check Storage usage and mounted filesystems:","text":"<pre><code>df\n# But df is barely readable, so find the option that makes it more readable `man df`\n\ndf -h\ndf -h | grep -i var\n# What does this show, or search for? Can you invert this search? (hint `man grep`\n# look for invert or google \u201cinverting grep\u2019s output\u201d)\n\ndf -h | grep -i sd\n# This one is a little harder, what does this one show? Not just the line, what are\n# we checking for? (hint if you need it, google \u201cwhat is /dev/sda in linux\u201d)\n\nmount\n# Mount by itself gives a huge amount of information. But, let\u2019s say someone is asking\n# you to verify that the mount is there for /home on a system. Can you check that\n# quickly with one command?\n\nmount | grep -i home\n#This works, but there is a slight note to add here. Just because something isn\u2019t\n# individually mounted doesn\u2019t mean it doesn\u2019t exist. It just means it\u2019s not part of\n# it\u2019s own mounted filesystem.\n\nmount | grep -i /home/xgqa6cha\n# will produce no output\n\ndf -h /home/xgqa6cha\n# will show you that my home filesystem falls under /home.\n\ncd ~; pwd; df -h .\n# This command moves you to your home directory, prints out that directory,\n# and then shows you what partition your home directory is on.\n\ndu -sh .\n# will show you space usage of just your directory\n\ntry `du -h .` as well to see how that ouput differs\n# read `man du` to learn more about your options.\n</code></pre>"},{"location":"lac/u2lab/#check-the-system-uptime","title":"Check the system uptime:","text":"<pre><code>uptime\n\nman uptime\n# Read the man for uptime and figure out what those 3 numbers represent.\n# Referencing this server, do you think it is under high load? Why or why not?\n</code></pre>"},{"location":"lac/u2lab/#check-who-has-recently-logged-into-the-server-and-who-is-currently-in","title":"Check who has recently logged into the server and who is currently in:","text":"<pre><code>last\n# Last is a command that outputs backwards. (Top of the output is most recent).\n# So it is less than useful without using the more command.\n\nlast | more\n# Were you the last person to log in? Who else has logged in today?\n\nw\nwho\nwhoami\n# how many other users are on this system? What does the pts/0 mean on google?\n</code></pre>"},{"location":"lac/u2lab/#check-who-you-are-and-what-is-going-on-in-your-environment","title":"Check who you are and what is going on in your environment:","text":"<pre><code>printenv\n# This scrolls by way too fast, how would you search for your home?\n\nprintenv | grep -i home\nwhoami\nid\necho $SHELL\n</code></pre>"},{"location":"lac/u2lab/#check-running-processes-and-services","title":"Check running processes and services:","text":"<pre><code>ps -aux | more\nps -ef | more\nps -ef | wc -l\n</code></pre>"},{"location":"lac/u2lab/#check-memory-usage-and-what-is-using-the-memory","title":"Check memory usage and what is using the memory:","text":"<pre><code># Run each of these individually for understanding before we look at part b.\nfree -m\nfree -m | egrep \u201cMem|Swap\u201d\nfree -m| egrep \u201cMem|Swap\u201d | awk \u2018{print $1, $2, $3}\u2019\nfree -t | egrep \"Mem|Swap\" | awk '{print $1 \" Used Space = \" ($3 / $2) * 100\"%\"}'\n\n# Taking this apart a bit:\n# You\u2019re just using free and searching for the lines that are for memory and swap\n# You then print out the values $1 = Mem or Swap\n# You then take $3 used divided by $2 total and multiply by 100 to get the percentage\n</code></pre> <p>Have you ever written a basic check script or touched on conditional statements or loops? (Use ctrl + c to break out of these):</p> <pre><code>while true; do free -m; sleep 3; done\n\n# Watch this output for a few and then break with ctrl + c\n# Try to edit this to wait for 5 seconds\n# Try to add a check for uptime and date each loop with a blank line between\n# each and 10 second wait:\n\nwhile true; do date; uptime; free -m; echo \u201c \u201c; sleep 10; done\n# Since we can wrap anything inside of our while statements, let\u2019s try adding\n# something from earlier:\nwhile true; do free -t | egrep \"Mem|Swap\" | awk '{print $1 \" Used Space = \" ($3 / $2) * 100\"%\"}'; sleep 3; done\n</code></pre> <pre><code>seq 1 10\n# What did this do?\n# Can you man seq to modify that to count from 2 to 20 by 2\u2019s?\n# Let\u2019s make a counting for loop from that sequence\n\nfor i in `seq 1 20`; do echo \"I am counting i and am on $i times through the loop\"; done\n</code></pre> <p>Can you tell me what is the difference or significance of the $ in the command above? What does that denote to the system?</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u2ws/","title":"Worksheet","text":""},{"location":"lac/u2ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u2ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Bash Reference Manual</li> <li>Security Enhanced Linux</li> </ul>"},{"location":"lac/u2ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u2_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u2_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u2ws/#unit-2-recording","title":"Unit 2 Recording","text":""},{"location":"lac/u2ws/#unit-2-discussion-post-1","title":"Unit 2 Discussion Post #1","text":"<p>Think about how week 1 went for you.</p> <ol> <li> <p>Do you understand everything that needs to be done?</p> </li> <li> <p>Do you need to allocate more time to the course, and if so, how do you plan to do it?</p> </li> <li> <p>How well did you take notes during the lecture? Do you need to improve this?</p> </li> </ol>"},{"location":"lac/u2ws/#unit-2-discussion-post-2","title":"Unit 2 Discussion Post #2","text":"<p>Read a blog, check a search engine, or ask an AI about SELinux. What is the significance of contexts? What are the significance of labels?</p> <p>Scenario:</p>   You follow your company instructions to add a new user to a set of 10 Linux servers. They cannot access just one of the servers.  When you review the differences in the servers you see that the server they cannot access is running SELINUX. On checking other users have no problem getting into the system.  You find nothing in the documentation (typical) about this different system or how these users are accessing it.   <p>What do you do? Where do you check?</p> <p>You may use any online resources to help you answer this. This is not a trick and it is not a \u201cone answer solution\u201d. This is for you to think through.</p>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u2ws/#start-thinking-about-your-project-ideas-more-to-come-in-future-weeks","title":"Start thinking about your project ideas (more to come in future weeks):","text":"<p>Topics:</p> <ol> <li>System Stability</li> <li>System Performance</li> <li>System Security</li> <li>System monitoring</li> <li>Kubernetes</li> <li>Programming/Automation</li> </ol> <p>You will research, design, deploy, and document a system that improves your administration of Linux systems in some way.</p>"},{"location":"lac/u2ws/#definitions","title":"Definitions","text":"<p>Uptime:</p> <p>Standard input (stdin):</p> <p>Standard output (stdout):</p> <p>Standard error (stderr):</p> <p>Mandatory Access Control (MAC):</p> <p>Discretionary Access Control (DAC):</p> <p>Security contexts (SELinux):</p> <p>SELinux operating modes:</p>"},{"location":"lac/u2ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>How does troubleshooting differ between system administration and system    engineering? To clarify, how might you troubleshoot differently if you know a    system was previously running correctly. If you\u2019re building a new system out?</p> </li> <li> <p>Investigate a troubleshooting methodology, by either Google or AI search.    Does the methodology fit for you in an IT sense, why or why not?</p> </li> </ol>"},{"location":"lac/u2ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you\u2019ve learned in your current role?</p> </li> </ol>"},{"location":"lac/u3b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p> <p>When storage issues arise, troubleshooting step by step ensures a quick resolution. This guide flows logically, covering the most common issues you might face, from slow performance to filesystem corruption.</p>"},{"location":"lac/u3b/#step-1-is-storage-performance-slow","title":"\ud83d\udd0d Step 1: Is Storage Performance Slow?","text":"<p>If everything feels sluggish, your disk might be the bottleneck.</p>"},{"location":"lac/u3b/#check","title":"Check:","text":"<pre><code># Monitor disk I/O, latency, and throughput\niostat -xz 1\n\n# Identify processes consuming high I/O\npidstat -d 1\n\n# Real-time disk activity monitoring\niostat -dx 1\n</code></pre> <ul> <li>If I/O wait is high, it means the CPU is waiting on slow disk operations.</li> <li>If certain processes are consuming all disk bandwidth, they might be the cause.</li> </ul>"},{"location":"lac/u3b/#fix","title":"Fix:","text":"<ol> <li>Identify and stop unnecessary high I/O processes:</li> </ol> <pre><code># Forcefully terminate a process (use with caution)\nkill -9 &lt;PID&gt;\n</code></pre> <ol> <li>Optimize filesystem writes (for ext4):</li> </ol> <pre><code># Enable writeback mode for better performance\ntune2fs -o journal_data_writeback /dev/sdX\n</code></pre> <ol> <li>Reduce excessive metadata writes:</li> </ol> <pre><code># Disable access time updates and set commit interval\nmount -o noatime,commit=60 /mnt/data\n</code></pre> <ol> <li>If using LVM, extend the volume to reduce fragmentation:    <pre><code># Add 5GB to volume\nlvextend -L +5G /dev/examplegroup/lv_data\n</code></pre></li> </ol>"},{"location":"lac/u3b/#step-2-is-the-filesystem-full-no-space-left-on-device","title":"\ud83d\udd0d Step 2: Is the Filesystem Full? (\"No Space Left on Device\")","text":"<p>\ud83d\udc49 Disk space exhaustion is one of the most common causes of storage failures.</p>"},{"location":"lac/u3b/#check_1","title":"Check:","text":"<pre><code># Show disk usage per filesystem\ndf -hT\n\n# Find the biggest files\ndu -ahx / | sort -rh | head -20\n</code></pre> <ul> <li>If a filesystem is 100% full, it prevents writes and can cause application crashes.</li> <li>If there's space but files still won't write, check Step 4 (Corrupted Filesystem).</li> </ul>"},{"location":"lac/u3b/#fix_1","title":"Fix:","text":"<ol> <li>Find and remove large unnecessary files:</li> </ol> <pre><code># Remove specific log file\nrm -f /var/log/large_old_log.log\n</code></pre> <ol> <li>Truncate logs safely without deleting them:</li> </ol> <pre><code># Clear log contents while preserving file\ntruncate -s 0 /var/log/syslog\n\n# Limit journal size\njournalctl --vacuum-size=100M\n</code></pre> <ol> <li>Expand disk space if using LVM:</li> </ol> <pre><code># Extend logical volume\nlvextend -L +10G /dev/examplegroup/lv_data\n\n# Resize filesystem\nresize2fs /dev/examplegroup/lv_data  # for ext4\nxfs_growfs /mnt/data                 # for XFS\n</code></pre>"},{"location":"lac/u3b/#step-3-are-mounts-failing-lvm-fstab-nfs-smb","title":"\ud83d\udd0d Step 3: Are Mounts Failing? (LVM, fstab, NFS, SMB)","text":"<p>If files suddenly disappear or applications complain about missing storage, a mount issue may be the cause.</p>"},{"location":"lac/u3b/#check_2","title":"Check:","text":"<pre><code># View current mounts\nmount | grep /mnt/data\n\n# Check block devices\nlsblk\n\n# Verify permanent mount configuration\ncat /etc/fstab\n</code></pre>"},{"location":"lac/u3b/#fix_2","title":"Fix:","text":"<ol> <li>Manually remount the filesystem (if missing):</li> </ol> <pre><code># Remount all fstab entries\nmount -a\n</code></pre> <ol> <li>Ensure correct fstab entry for persistence:</li> </ol> <pre><code># Add to /etc/fstab (replace UUID with actual value)\nUUID=xxx-yyy-zzz /mnt/data ext4 defaults 0 2\n</code></pre> <ol> <li>If an LVM mount is missing after reboot, reactivate it:</li> </ol> <pre><code># Activate volume groups\nvgchange -ay\n\n# Mount the logical volume\nmount /dev/examplegroup/lv_data /mnt/data\n</code></pre> <ol> <li>For NFS issues, check connectivity and restart services:</li> </ol> <pre><code># Check NFS exports\nshowmount -e &lt;NFS_SERVER_IP&gt;\n\n# Restart NFS service\nsystemctl restart nfs-server\n</code></pre>"},{"location":"lac/u3b/#step-4-is-the-filesystem-corrupted","title":"\ud83d\udd0d Step 4: Is the Filesystem Corrupted?","text":"<p>\ud83d\udc49 Power losses, unexpected shutdowns, and failing drives can cause corruption.</p>"},{"location":"lac/u3b/#check_3","title":"Check:","text":"<pre><code># Check kernel error messages\ndmesg | grep -i \"error\"\n\n# Check filesystem integrity (non-destructive)\nfsck.ext4 -n /dev/sdX  # for ext4\nxfs_repair -n /dev/sdX  # for XFS\n</code></pre>"},{"location":"lac/u3b/#fix_3","title":"Fix:","text":"<ol> <li>Repair the filesystem (if unmounted):</li> </ol> <pre><code># Unmount first\numount /dev/sdX\n\n# Run filesystem repair\nfsck -y /dev/sdX    # for ext4\nxfs_repair /dev/sdX  # for XFS\n</code></pre> <ol> <li>If corruption is severe, restore from backup:    <pre><code># Restore using rsync\nrsync -av /backup/mnt_data /mnt/data/\n</code></pre></li> </ol>"},{"location":"lac/u3b/#step-5-are-you-out-of-inodes","title":"\ud83d\udd0d Step 5: Are You Out of Inodes?","text":"<p>You might have disk space but still can't create files? Check your inodes!</p>"},{"location":"lac/u3b/#check_4","title":"Check:","text":"<pre><code># Check inode usage\ndf -i\n\n# Count files in current directory\nfind . -type f | wc -l\n</code></pre> <ul> <li>If inode usage shows 100%, you can't create new files even with free space.</li> <li>This happens when you have too many small files.</li> </ul>"},{"location":"lac/u3b/#fix_4","title":"Fix:","text":"<ol> <li>Clean up temporary files:</li> </ol> <pre><code># Remove old files in /tmp\nrm -rf /tmp/*\n\n# Clean package cache (Debian/Ubuntu)\napt-get clean\n</code></pre> <ol> <li>Find and remove unnecessary files:    <pre><code># List directories with most files\ndu -a | sort -n -r | head -n 10\n</code></pre></li> </ol>"},{"location":"lac/u3intro/","title":"Storage","text":""},{"location":"lac/u3intro/#overview","title":"Overview","text":"<p>The unit focuses on understanding and implementing techniques to ensure systems remain operational with minimal downtime.</p> <ul> <li> <p>The process of quickly assessing, prioritizing, and addressing system incidents.</p> </li> <li> <p>Leveraging performance indicators (KPIs, SLIs) and setting clear operational targets (SLOs, SLAs) to guide troubleshooting and recovery efforts.</p> </li> </ul>"},{"location":"lac/u3intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Understand Fundamental Concepts of System Reliability and High Availability:</p> </li> <li> <p>Explain the importance of uptime and the implications of \u201cFive 9\u2019s\u201d availability in mission-critical environments.</p> </li> <li> <p>Define key terms such as Single Point of Failure (SPOF), Mean Time to Detect (MTTD), Mean Time to Recover (MTTR), and Mean Time Between Failures (MTBF).</p> </li> <li> <p>Identify and Apply High Availability Architectures:</p> </li> <li> <p>Differentiate between Active-Active and Active-Standby configurations and describe their advantages and trade-offs.</p> </li> <li> <p>Evaluate real-world scenarios to determine where redundancy and clustering (using tools like Pacemaker and Corosync) can improve system resilience.</p> </li> <li> <p>Develop Incident Triage and Response Skills:</p> </li> <li> <p>Outline a structured approach to incident detection, prioritization, and resolution.</p> </li> <li> <p>Use performance metrics (KPIs, SLIs, SLOs, and SLAs) to guide decision-making during operational incidents.</p> </li> <li> <p>Integrate Theoretical Knowledge with Practical Application:</p> </li> <li> <p>Leverage external resources (such as AWS whitepapers, Google SRE documentation, and Red\u00a0Hat guidelines) to deepen understanding of system reliability best practices.</p> </li> <li> <p>Participate in interactive discussion posts and collaborative problem-solving exercises to reinforce learning.</p> </li> <li> <p>Cultivate Analytical and Troubleshooting Abilities:</p> </li> <li> <p>Apply systematic troubleshooting techniques to diagnose and resolve system issues.</p> </li> <li> <p>Reflect on incident case studies and simulated exercises to improve proactive prevention strategies.</p> </li> </ol> <p>These learning objectives are designed to ensure that participants not only grasp the theoretical underpinnings of system reliability and high availability but also build the practical skills needed for effective incident management and system optimization in a professional Linux environment.</p>"},{"location":"lac/u3intro/#relevance-context","title":"Relevance &amp; Context","text":"<ul> <li> <p>Ensuring Mission-Critical Uptime:   Minimizing downtime is critical, and high availability strategies help ensure continuous service\u2014even in the face of hardware or software failures.</p> </li> <li> <p>Optimized Incident Management:   A well-practiced incident triage process enables administrators to quickly diagnose issues, reduce system downtime, and mitigate potential service interruptions.</p> </li> <li>Designing Resilient Architectures:   For a Red\u00a0Hat Systems Administrator, understanding how to build redundancy (using techniques like Active-Active or Active-Standby clustering) and eliminate Single Points of Failure (SPOFs) is key to creating robust systems.</li> <li>Data-Driven Decision Making:   Leveraging metrics such as KPIs, SLIs, SLOs, and SLAs allows administrators to set measurable goals, monitor performance, and make informed decisions about system improvements.</li> <li>Integration with Enterprise Tools:   Red\u00a0Hat environments often utilize specific tools (such as Pacemaker and Corosync for clustering, and Ansible for configuration management) that align with the concepts taught in this unit. Mastery of these principles helps engineers integrate and optimize these tools effectively within their infrastructure.</li> </ul>"},{"location":"lac/u3intro/#prerequisites","title":"Prerequisites","text":"<p>Before engaging with this unit, readers should have a foundational understanding of:</p> <ul> <li> <p>Basic Networking Concepts: Familiarity with the principles of networking (such as IP addressing, DNS, and basic network troubleshooting) is crucial because many Linux administration tasks involve network configuration and monitoring.</p> </li> <li> <p>Text Editing and Scripting Basics: An introductory exposure to editing text (using simple editors) and the idea of writing or running small scripts helps prepare learners for more complex shell operations.</p> </li> <li> <p>Version Control (Git): Since the learning material and collaborative discussions use GitHub, understanding Git and markdown is beneficial.</p> </li> <li> <p>Problem-Solving: A general troubleshooting mindset, including the ability to search documentation, diagnose issues systematically, and apply corrective measures.</p> </li> </ul>"},{"location":"lac/u3intro/#key-terms-and-definitions","title":"Key terms and Definitions","text":"<p>Resilience Engineering</p> <p>Fault Tolerance</p> <p>Proactive Monitoring</p> <p>Observability</p> <p>Incident Response</p> <p>Root Cause Analysis (RCA)</p> <p>Disaster Recovery (DR)</p> <p>Error Budgeting</p> <p>Capacity Planning</p> <p>Load Balancing Service Continuity</p> <p>Infrastructure as Code (IaC)</p> <p>Configuration Management</p> <p>Preventive Maintenance</p> <p>DevOps Culture</p>"},{"location":"lac/u3lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u3lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Ubuntu Documentation on LVM</li> </ul>"},{"location":"lac/u3lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u3lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u3_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u3_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u3lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <pre><code>cd ~\nmkdir lvm_lab\n\ncd lvm_lab\ntouch somefile\necho \u201cthis is a string of text\u201d &gt; somefile\ncat somefile\necho \u201cthis is a string of text\u201d &gt; somefile\n# Repeat 3 times\n\ncat somefile\n# How many lines are there?\n\nEcho \u201cthis is a string of text\u201d &gt;&gt; somefile\n# Repeat 3 times\n\ncat somefile\n# How many lines are there?\n\n# cheat with `cat somefile | wc -l`\necho \u201cthis is our other test text\u201d &gt;&gt; somefile\n# Repeat 3 times\n\ncat somefile | nl\n# How many lines are there?\n\ncat somefile | nl | grep test\n# compare that with 14\n\ncat somefile | grep test | nl\n</code></pre> <p>If you want to preserve positional lines in file (know how much you\u2019ve cut out when you grep something, or generally be able to find it in the unfiltered file for context, always | nl | before your grep</p>"},{"location":"lac/u3lab/#pre-lab-disk-speed-tests","title":"Pre Lab - Disk Speed tests:","text":"<p>When using the ProLUG lab environment, you should always check that there are no other users on the system <code>w</code> or <code>who</code>.</p> <p>After this, you may want to check the current state of the disks, as they retain their information even after a reboot resets the rest of the machine. <code>lsblk /dev/xvda</code>.</p> <pre><code># If you need to wipe the disks, you should use fdisk or a similar partition utility.\nfdisk /dev/xvda\n\np #print to see partitions\nd #delete partitions or information\nw #Write out the changes to the disk.\n</code></pre> <p>This is an aside, before the lab. This is a way to test different read or writes into or out of your filesystems as you create them. Different types of raid and different disk setups will give different speed of read and write. This is a simple way to test them. Use these throughout the lab in each mount for fun and understanding.</p>"},{"location":"lac/u3lab/#write-tests-saving-off-write-data-rename-tmpfile-each-time","title":"Write tests (saving off write data - rename /tmp/file each time):","text":"<pre><code># Check /dev/xvda for a filesystem\nblkid /dev/xvda\n\n# If it does not have one, make one\nmkfs.ext4 /dev/xvda\nmkdir /space # (If you don\u2019t have it. Lab will tell you to later as well)\n\nmount /dev/xvda /space\n</code></pre>"},{"location":"lac/u3lab/#write-test","title":"Write Test:","text":"<pre><code>for i in `seq 1 10`; do time dd if=/dev/zero of=/space/testfile$i bs=1024k count=1000 | tee -a /tmp/speedtest1.basiclvm; done\n</code></pre>"},{"location":"lac/u3lab/#read-tests","title":"Read tests:","text":"<pre><code>for i in `seq 1 10`; do time dd if=/space/testfile$i of=/dev/null; done\n</code></pre>"},{"location":"lac/u3lab/#cleanup","title":"Cleanup:","text":"<pre><code>for i in `seq 1 10`; do rm -rf /space/testfile$i; done\n</code></pre> <p>If you are re-creating a test without blowing away the filesystem, change the name or counting numbers of testfile because that\u2019s the only way to be sure there is not some type of filesystem caching going on to optimize. This is especially true in SAN write tests.</p>"},{"location":"lac/u3lab/#lab","title":"Lab \ud83e\uddea","text":"<p>start in root (#); cd /root</p>"},{"location":"lac/u3lab/#lvm-explanation-and-use-within-the-system","title":"LVM explanation and use within the system:","text":"<pre><code># Check physical volumes on your server (my output may vary)\nfdisk -l | grep -i xvd\n\n# Disk /dev/xvda: 15 GiB, 16106127360 bytes, 31457280 sectors\n# Disk /dev/xvdb: 3 GiB, 3221225472 bytes, 6291456 sectors\n# Disk /dev/xvdc: 3 GiB, 3221225472 bytes, 6291456 sectors\n# Disk /dev/xvde: 3 GiB, 3221225472 bytes, 6291456 sectors\n</code></pre>"},{"location":"lac/u3lab/#looking-at-logical-volume-management","title":"Looking at Logical Volume Management:","text":"<p>Logical Volume Management is an abstraction layer that looks a lot like how we carve up SAN disks for storage management. We have Physical Volumes that get grouped up into Volume Groups. We carve Volume Groups up to be presented as Logical Volumes.</p> <p>Here at the Logical Volume layer we can assign RAID functionality from our Physical Volumes attached to a Volume Group or do all kinds of different things that are \u201cunder the hood\u201d. Logical Volumes get filesystems formatting and are mounted to the OS.</p> <p>There are many important commands for showing your physical volumes, volume groups, and logical volumes.</p> <p>The three simplest and easiest are:</p> <pre><code>pvs\nvgs\nlvs\n</code></pre> <p>With these you can see basic information that allows you to see how the disks are allocated. Why do you think there is no output from these commands the first time you run them? Try these next commands to see if you can figure out what is happening? To see more in depth information try pvdisplay, vgdisplay, and lvdisplay.</p> <p>If there is still no output, it\u2019s because this system is not configured for LVM. You will notice that none of the disk you verified are attached are allocated to LVM yet. We\u2019ll do that next.</p>"},{"location":"lac/u3lab/#creating-and-carving-up-your-lvm-resources","title":"Creating and Carving up your LVM resources:","text":"<p>Disks for this lab are /dev/xvdb, /dev/xvdc, and /dev/xvdd. (but verify before continuing and adjust accordingly.)</p> <p>We can do individual pvcreates for each disk <code>pvcreate /dev/xvdb</code> but we can also loop over them with a simple loop as below. Use your drive letters.</p> <pre><code>for disk in b c d; do pvcreate /dev/xvd$disk; done\n\n# Physical volume \"/dev/xvdb\" successfully created.\n# Creating devices file /etc/lvm/devices/system.devices\n# Physical volume \"/dev/xvdc\" successfully created.\n# Physical volume \"/dev/xvde\" successfully created.\n\n# To see what we made:\n\npvs\n\n# PV VG Fmt Attr PSize PFree\n# /dev/xvdb lvm2  3.00g 3.00g\n# /dev/xvdc lvm2  3.00g 3.00g\n# /dev/xvde lvm2  3.00g 3.00g\n\nvgcreate VolGroupTest /dev/xvdb /dev/xvdc /dev/xvde\n\n# Volume group \"VolGroupTest\" successfully created\n\nvgs\n# VG #PV #LV #SN Attr VSize VFree\n# VolGroupTest 3 0 0 wz--n- &lt;8.99g &lt;8.99g\n\nlvcreate -l +100%FREE -n lv_test VolGroupTest\n\n# Logical volume \"lv_test\" created.\n\nlvs\n\n# LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert\n# lv_test VolGroupTest -wi-a-- &lt;8.99g\n# Formatting and mounting the filesystem\n\nmkfs.ext4 /dev/mapper/VolGroupTest-lv_test\n\n# mke2fs 1.42.9 (28-Dec-2013)\n# Filesystem label=\n# OS type: Linux\n# Block size=4096 (log=2)\n# Fragment size=4096 (log=2)\n# Stride=0 blocks, Stripe width=0 blocks\n# 983040 inodes, 3929088 blocks\n# 196454 blocks (5.00%) reserved for the super user\n# First data block=0\n# Maximum filesystem blocks=2151677952\n# 120 block groups\n# 32768 blocks per group, 32768 fragments per group\n# 8192 inodes per group\n# Superblock backups stored on blocks:\n# 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208\n#\n# Allocating group tables: done\n# Writing inode tables: done\n# Creating journal (32768 blocks): done\n# Writing superblocks and filesystem accounting information: done\n\nmkdir /space #Created earlier\nvi /etc/fstab\n\n# Add the following line\n# /dev/mapper/VolGroupTest-lv_test /space ext4 defaults 0 0\n\n# reload fstab\nsystemctl daemon-reload\n</code></pre> <p>If this command works, there will be no output. We use the df -h in the next command to verify the new filesystem exists. The use of mount -a and not manually mounting the filesystem from the command line is an old administration trick I picked up over the years.</p> <p>By setting our mount in /etc/fstab and then telling the system to mount everything we verify that this will come back up properly during a reboot. We have mounted and verified we have a persistent mount in one step.</p> <pre><code>df -h\n\n# Filesystem Size Used Avail Use% Mounted on\n# devtmpfs 4.0M 0 4.0M 0% /dev\n# tmpfs 2.0G 0 2.0G 0% /dev/shm\n# tmpfs 2.0G 8.5M 1.9G 1% /run\n# tmpfs 2.0G 1.4G 557M 72% /\n# tmpfs 2.0G 0 2.0G 0% /run/shm\n# 192.168.200.25:/home 44G 15G 30G 34% /home\n# 192.168.200.25:/opt 44G 15G 30G 34% /opt\n# tmpfs 390M 0 390M 0% /run/user/0\n# /dev/mapper/VolGroupTest-lv*test 8.8G 24K 8.3G 1% /space\n</code></pre> <p>Good place to speed test and save off your data.</p>"},{"location":"lac/u3lab/#removing-and-breaking-down-the-lvm-to-raw-disks","title":"Removing and breaking down the LVM to raw disks:","text":"<p>The following command is one way to comment out the line in /etc/fstab. If you had to do this across multiple servers this could be useful. (Or you can just use vi for simplicity).</p> <pre><code>grep lv_test /etc/fstab; perl -pi -e \"s/\\/dev\\/mapper\\/VolGroupTest/#removed \\/dev\\/mapper\\/VolGroupTest/\" /etc/fstab; grep removed /etc/fstab\n# /dev/mapper/VolGroupTest-lv_test /space ext4 defaults 0 0\n#removed dev/mapper/VolGroupTest-lv_test /space ext4 defaults 0 0\n\numount /space\nlvremove /dev/mapper/VolGroupTest-lv_test\n\n# Do you really want to remove active logical volume VolGroupTest/lv_test? [y/n]: y\n# Logical volume \"lv_test\" successfully removed\n\nvgremove VolGroupTest\n\n# Volume group \"VolGroupTest\" successfully removed\n\n\nfor disk in c e f; do pvremove /dev/sd$disk; done\n\n# Labels on physical volume \"/dev/sdc\" successfully wiped.\n# Labels on physical volume \"/dev/sde\" successfully wiped.\n# Labels on physical volume \"/dev/sdf\" successfully wiped.\n</code></pre> <p>Use your <code>pvs;vgs;lvs</code> commands to verify those volumes no longer exist.</p> <pre><code>pvs;vgs;lvs\n\n# PV VG Fmt Attr PSize PFree\n# /dev/sda2 VolGroup00 lvm2 a-- 17.48g 4.00m\n# /dev/sdb VolGroup01 lvm2 a-- 20.00g 96.00m\n# VG #PV #LV #SN Attr VSize VFree\n# VolGroup00 1 9 0 wz--n- 17.48g 4.00m\n# VolGroup01 1 1 0 wz--n- 20.00g 96.00m\n# LV VG Attr LSize Pool Origin Data% Meta% Move Log\n# LogVol00 VolGroup00 -wi-ao- 2.50g\n# LogVol01 VolGroup00 -wi-ao- 1000.00m\n# LogVol02 VolGroup00 -wi-ao- 5.00g\n# LogVol03 VolGroup00 -wi-ao- 1.00g\n# LogVol04 VolGroup00 -wi-ao- 5.00g\n# LogVol05 VolGroup00 -wi-ao- 1.00g\n# LogVol06 VolGroup00 -wi-ao- 1.00g\n# LogVol07 VolGroup00 -wi-ao- 512.00m\n# LogVol08 VolGroup00 -wi-ao- 512.00m\n# lv_app VolGroup01 -wi-ao- 19.90g\n</code></pre>"},{"location":"lac/u3lab/#more-complex-types-of-lvm","title":"More complex types of LVM:","text":"<p>LVM can also be used to raid disks</p> <p>Create a RAID 5 filesystem and mount it to the OS (For brevity\u2019s sake we will be limiting show commands from here on out, please use pvs,vgs,lvs often for your own understanding)</p> <pre><code>for disk in c e f; do pvcreate /dev/sd$disk; done\n\n# Physical volume \"/dev/sdc\" successfully created.\n# Physical volume \"/dev/sde\" successfully created.\n# Physical volume \"/dev/sdf\" successfully created.\n\nvgcreate VolGroupTest /dev/sdc /dev/sde /dev/sdf\n\nlvcreate -l +100%FREE --type raid5 -n lv_test VolGroupTest\nmkfs.xfs /dev/mapper/VolGroupTest-lv_test\n\nvi /etc/fstab\n\n# fix the /space directory to have these parameters (change ext4 to xfs)\n/dev/mapper/VolGroupTest-lv_test /space xfs defaults 0 0\n\ndf -h\n# Filesystem Size Used Avail Use% Mounted on\n# /dev/mapper/VolGroup00-LogVol08 488M 34M 419M 8% /var/log/audit\n# /dev/mapper/VolGroupTest-lv_test 10G 33M 10G 1% /space\n</code></pre> <p>Since we\u2019re now using RAID 5 we would expect to see the size no longer match the full 15GB, 10GB is much more of a RAID 5 value 66% of raw disk space.</p> <p>To verify our raid levels we use lvs</p> <pre><code>lvs\n# LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync\n# LogVol00 VolGroup00 -wi-ao- 2.50g\n# LogVol01 VolGroup00 -wi-ao- 1000.00m\n# LogVol02 VolGroup00 -wi-ao- 5.00g\n# LogVol03 VolGroup00 -wi-ao- 1.00g\n# LogVol04 VolGroup00 -wi-ao- 5.00g\n# LogVol05 VolGroup00 -wi-ao- 1.00g\n# LogVol06 VolGroup00 -wi-ao- 1.00g\n# LogVol07 VolGroup00 -wi-ao- 512.00m\n# LogVol08 VolGroup00 -wi-ao- 512.00m\n# lv*app VolGroup01 -wi-ao- 19.90g\n# lv_test VolGroupTest rwi-aor 9.98g 100.00\n</code></pre> <p>Spend 5 min reading the <code>man lvs</code> page to read up on raid levels and what they can accomplish. To run RAID 5 3 disks are needed. To run RAID 6 at least 4 disks are needed.</p> <p>Good place to speed test and save off your data</p>"},{"location":"lac/u3lab/#set-the-system-back-to-raw-disks","title":"Set the system back to raw disks:","text":"<p>Unmount /space and remove entry from /etc/fstab</p> <pre><code>lvremove /dev/mapper/VolGroupTest-lv_test\n# Do you really want to remove active logical volume VolGroupTest/lv_test? [y/n]: y\n# Logical volume \"lv_test\" successfully removed\n\nvgremove VolGroupTest\n# Volume group \"VolGroupTest\" successfully removed\n\nfor disk in c e f; do pvremove /dev/sd$disk; done\n# Labels on physical volume \"/dev/sdc\" successfully wiped.\n# Labels on physical volume \"/dev/sde\" successfully wiped.\n# Labels on physical volume \"/dev/sdf\" successfully wiped.\n</code></pre>"},{"location":"lac/u3lab/#working-with-mdadm-as-another-raid-option","title":"Working with MDADM as another RAID option:","text":"<p>There could be a reason to use MDADM on the system. For example you want raid handled outside of your LVM so that you can bring in sets of new disks already raided and treat them as their own Physical Volumes. Think, \u201cI want to add another layer of abstraction so that even my LVM is unaware of the RAID levels.\u201d This has special use case, but is still useful to understand.</p> <p>May have to install mdadm yum: yum install mdadm</p>"},{"location":"lac/u3lab/#create-a-raid5-with-mdadm","title":"Create a raid5 with MDADM:","text":"<pre><code>mdadm --create -l raid5 /dev/md0 -n 3 /dev/sdc /dev/sde /dev/sdf\n\n# mdadm: Defaulting to version 1.2 metadata\n# mdadm: array /dev/md0 started.\n</code></pre>"},{"location":"lac/u3lab/#add-newly-created-devmd0-raid-to-lvm","title":"Add newly created /dev/md0 raid to LVM:","text":"<p>This is same as any other add. The only difference here is that LVM is unaware of the lower level RAID that is happening.</p> <pre><code>pvcreate /dev/md0\n# Physical volume \"/dev/md0\" successfully created.\n\nvgcreate VolGroupTest /dev/md0\n# Volume group \"VolGroupTest\" successfully created\n\nlvcreate -l +100%Free -n lv_test VolGroupTest\n# Logical volume \"lv_test\" created.\n\nlvs\n# LV VG Attr LSize Pool Origin Data% Meta% Move Log\n# LogVol00 VolGroup00 -wi-ao- 2.50g\n# LogVol01 VolGroup00 -wi-ao- 1000.00m\n# LogVol02 VolGroup00 -wi-ao- 5.00g\n# LogVol03 VolGroup00 -wi-ao- 1.00g\n# LogVol04 VolGroup00 -wi-ao- 5.00g\n# LogVol05 VolGroup00 -wi-ao- 1.00g\n# LogVol06 VolGroup00 -wi-ao- 1.00g\n# LogVol07 VolGroup00 -wi-ao- 512.00m\n# LogVol08 VolGroup00 -wi-ao- 512.00m\n# lv_app VolGroup01 -wi-ao- 19.90g\n# lv_test VolGroupTest -wi-a-- 9.99g\n</code></pre> <p>Note that LVM does not see that it is dealing with a raid system, but the size is still 10g instead of 15g.</p> <p>Fix your /etc/fstab to read</p> <p>/dev/mapper/VolGroupTest-lv_test /space xfs defaults 0 0</p> <pre><code>mkfs.xfs /dev/mapper/VolGroupTest-lv_test\n\n# meta-data=/dev/mapper/VolGroupTest-lv_test isize=512 agcount=16, agsize=163712 blks\n# = sectsz=512 attr=2, projid32bit=1\n# = crc=1 finobt=0, sparse=0\n# data = bsize=4096 blocks=2618368, imaxpct=25\n# = sunit=128 swidth=256 blks\n# naming =version 2 bsize=4096 ascii-ci=0 ftype=1\n# log =internal log bsize=4096 blocks=2560, version=2\n# = sectsz=512 sunit=8 blks, lazy-count=1\n# realtime =none extsz=4096 blocks=0, rtextents=0\n\nmount -a\n</code></pre> <p>Good place to speed test and save off your data</p>"},{"location":"lac/u3lab/#setting-the-mdadm-to-persist-through-reboots","title":"Setting the MDADM to persist through reboots:","text":"<p>(not in our lab environment though)</p> <pre><code>mdadm --detail --scan &gt;&gt; /etc/mdadm.conf\ncat /etc/mdadm.conf\n# ARRAY /dev/md0 metadata=1.2 name=ROCKY1:0 UUID=03583924:533e5338:8d363715:09a8b834\n</code></pre> <p>Verify with <code>df -h</code> ensure that your /space is mounted.</p> <p>There is no procedure in this lab for breaking down this MDADM RAID.</p> <p>You are root/administrator on your machine, and you do not care about the data on this RAID. Can you use the internet/man pages/or other documentation to take this raid down safely and clear those disks?</p> <p>Can you document your steps so that you or others could come back and do this process again?</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u3ws/","title":"Worksheet","text":""},{"location":"lac/u3ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u3ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Google SRE Book - Implementing SLOs</li> <li>AWS High Availability Architecture Guide</li> <li>Red Hat High Availability Cluster Configuration</li> </ul>"},{"location":"lac/u3ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u3_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u3_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u3ws/#unit-3-recording","title":"Unit 3 Recording","text":""},{"location":"lac/u3ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Scan the chapter here for keywords and pull out what you think will help you to better understand how to triage an incident.</p> <p>Read the section called \"Operation Security\" in this same chapter: Building Secure and Reliable Systems</p> <ol> <li>What important concepts do you learn about how we behave during an    operational response to an incident?</li> </ol>"},{"location":"lac/u3ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Ask Google, find a blog, or ask an AI about high availability. (Here's one if you need it: AWS Real-Time Communication Whitepaper</p> <ol> <li>What are some important terms you read about? Why do you think understanding    HA will help you better in the context of triaging incidents?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u3ws/#definitions","title":"Definitions","text":"<p>Five 9's:</p> <p>Single Point of Failure (SPOF):</p> <p>Key Performance Indicators (KPIs):</p> <p>Service Level Indicator (SLI):</p> <p>Service Level Objective (SLO):</p> <p>Service Level Agreement (SLA):</p> <p>Active-Standby:</p> <p>Active-Active:</p> <p>Mean Time to Detect (MTTD):</p> <p>Mean Time to Recover/Restore (MTTR):</p> <p>Mean Time Between Failures (MTBF):</p>"},{"location":"lac/u3ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>If uptime is so important to us, why is it so important to us to also understand how our systems can fail? Why would we focus on the thing that does not drive uptime?</p> </li> <li> <p>Start reading about SLOs: Implementing SLOs    How does this help you operationally?    Does it make sense that keeping systems within defined parameters will help keep    them operating longer?</p> </li> </ol>"},{"location":"lac/u3ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you've learned in your current role?</p> </li> </ol>"},{"location":"lac/u4intro/","title":"Operating Running Systems","text":""},{"location":"lac/u4intro/#overview","title":"Overview","text":"<p>This unit concentrates on the core tasks involved in operating running systems in a Linux environment, particularly with Red Hat Enterprise Linux (RHEL). It covers:</p> <ul> <li> <p>Understanding resource usage CPU, memory, disk I/O.</p> </li> <li> <p>Become familiar with service management frameworks.</p> </li> </ul>"},{"location":"lac/u4intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Monitor and Manage System Resources:</p> </li> <li> <p>Learn to track CPU, memory, disk, and network usage.</p> </li> <li> <p>Understand how to troubleshoot performance bottlenecks.</p> </li> <li> <p>Master Service and Process Control:</p> </li> <li> <p>Gain proficiency with systemd for managing services and understanding dependency trees.</p> </li> <li> <p>Acquire the ability to identify, start, stop, and restart services and processes as needed.</p> </li> <li> <p>Configure and Interpret System Logs:</p> </li> <li> <p>Explore journald and syslog-based logging to collect and store vital system events.</p> </li> <li> <p>Develop techniques to analyze log files for troubleshooting and security assessments.</p> </li> <li> <p>Implement Scheduling and Automation:    Use <code>cron</code>, <code>at</code>, and <code>systemd</code> timers to automate recurring tasks.    Understand how automated job scheduling improves reliability and reduces manual intervention.</p> </li> </ol> <p>These objectives ensure learners can sustain, troubleshoot, and improve actively running Linux systems within enterprise environments, reducing downtime and increasing system reliability.</p>"},{"location":"lac/u4intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Operating running systems is central to any Linux administrator\u2019s responsibilities for several reasons:</p> <p>System Stability and Performance:</p> <ul> <li>Continuous monitoring and immediate remediation of issues ensure critical services remain available and performant.</li> </ul> <p>Proactive Problem Resolution:</p> <ul> <li>Effective log management and automation allow administrators to detect anomalies early, schedule essential maintenance, and minimize disruptions.</li> </ul> <p>Security and Compliance:</p> <ul> <li>Logs are often the first line of evidence in security auditing and breach investigations.</li> <li>Regularly reviewing and correlating logs is crucial to maintaining a secure environment.</li> </ul> <p>Enterprise Uptime and Reliability:</p> <ul> <li>In production environments, even brief outages can lead to significant operational and financial impacts.</li> <li>Proper management of running systems ensures high availability and robust service delivery.</li> </ul>"},{"location":"lac/u4intro/#prerequisites","title":"Prerequisites","text":"<p>Before tackling the tasks of operating running systems, learners should possess:</p> <ul> <li> <p>Command-Line Proficiency:    Familiarity with fundamental shell commands, directory structures, and file management is critical to executing system operations efficiently.</p> </li> <li> <p>Basic text editing skills:   Ability to utilize <code>vi</code>, <code>vim</code>, or comparable text editing tool. Understanding of vi, vim, or comparable editing tool shortcuts and commands.</p> </li> <li> <p>Aware of system components:   Familiarity with computer hardware concepts such as computer processors, memory, and storage.</p> </li> </ul>"},{"location":"lac/u4intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Systemd</p> <p>Journalctl</p> <p>Cron / At / Systemd Timers</p> <p>Daemon</p>"},{"location":"lac/u4lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u4lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Cron Wiki page</li> <li>tldp.org's cron guide</li> </ul>"},{"location":"lac/u4lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u4lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u4_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u4_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u4lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<ol> <li><code>cd ~</code></li> <li><code>ls</code></li> <li><code>mkdir unit4</code></li> <li><code>mkdir unit4/test/round6</code></li> <li>This fails.</li> <li><code>mkdir -p unit4/test/round6</code></li> <li>This works, think about why. (<code>man mkdir</code>)</li> <li><code>cd unit4</code></li> <li><code>ps</code></li> <li>Read <code>man ps</code></li> <li><code>ps -ef</code></li> <li>What does this show differently?</li> <li><code>ps -ef | grep -i root</code></li> <li>What is the PID of the 4th line?</li> <li><code>ps -ef | grep -i root | wc -l</code><ul> <li>What does this show you and why might it be useful?</li> </ul> </li> <li><code>top</code><ul> <li>Use <code>q</code> to exit.</li> <li>Inside top, use <code>h</code> to find commands you can use to toggle system info.</li> </ul> </li> </ol>"},{"location":"lac/u4lab/#pre-lab-disk-speed-tests","title":"Pre-Lab - Disk Speed tests:","text":"<ol> <li>Real quick check for a package that is useful.</li> </ol> <pre><code>rpm -qa | grep -i iostat #should find nothing\n</code></pre> <ol> <li>Let's find what provides iostat by looking in the YUM (we'll explore more in later lab)</li> </ol> <pre><code>dnf whatprovides iostat\n</code></pre> <ul> <li> <p>This should tell you that <code>sysstat</code> provides <code>iostat</code>.</p> </li> <li> <p>Let's check to see if we have it</p> </li> </ul> <pre><code>rpm -qa | grep -i sysstat\n</code></pre> <ol> <li>If you don't, lets install it</li> </ol> <pre><code>dnf install sysstat\n</code></pre> <ol> <li>Re-check to verify we have it now    <pre><code>rpm -qa | grep -I sysstat\nrpm -qi sysstat&lt;version&gt;\niostat # We'll look at this more in a bit\n</code></pre>    While we're working with packages, make sure that Vim is on your system.    This is the same procedure as above.    <pre><code>rpm -qa | grep -i vim  # Check if vim is installed\n# If it's there, good.\ndnf install vim\n# If it's not, install it so you can use vimtutor later (if you need help with vi commands)\n</code></pre></li> </ol>"},{"location":"lac/u4lab/#lab","title":"Lab \ud83e\uddea","text":"<ol> <li>Gathering system information release and kernel information</li> </ol> <pre><code>cat /etc/*release\nuname\nuname -a\nuname -r\n</code></pre> <p>Run <code>man uname</code> to see what those options mean if you don't recognize the values</p> <pre><code>rpm -qa | grep -i kernel\n</code></pre> <p>What is your kernel number? Highlight it (copy in putty)</p> <pre><code>rpm -qi &lt;kernel from earlier&gt;\n</code></pre> <p>What does this tell you about your kernel?    When was the kernel last updated?    What license is your kernel released under?</p> <ol> <li>Check the number of disks    <pre><code>fdisk -l\nls /dev/sd*\n</code></pre></li> <li>When might this command be useful?</li> <li>What are we assuming about the disks for this to work?</li> <li>How many disks are there on this system?</li> <li>How do you know if it's a partition or a disk?</li> </ol> <pre><code>pvs # What system are we running if we have physical volumes?\n    # What other things can we tell with vgs and lvs?\n</code></pre> <ul> <li>Use <code>pvdisply</code>, <code>vgdisplay</code>, and <code>lvdisplay</code> to look at your carved up volumes.   Thinking back to last week's lab, what might be interesting from each of those?</li> <li> <p>Try a command like <code>lvdisplay | egrep \"Path|Size\"</code> and see what it shows.</p> </li> <li> <p>Does that output look useful?</p> </li> <li> <p>Try to <code>egrep</code> on some other values. Separate with <code>|</code> between search items.</p> </li> <li> <p>Check some quick disk statistics   <pre><code>iostat -d\niostat -d 2   # Wait for a while, then use crtl + c to break. What did this do? Try changing this to a different number.\niostat -d 2 5 # Don't break this, just wait. What did this do differently? Why might this be useful?\n</code></pre></p> </li> <li> <p>Check the amount of RAM</p> </li> </ul> <pre><code>cat /proc/meminfo\nfree\nfree -m\n</code></pre> <ul> <li> <p>What do each of these commands show you? How are they useful?</p> </li> <li> <p>Check the number of processors and processor info    <pre><code>cat /proc/cpuinfo\n</code></pre>    What type of processors do you have? Google to try to see when they were released.    Look at the flags. Sometimes when compiling these are important to know. This is how    you check what execution flags your processor works with.    <pre><code>cat /proc/cpuinfo | grep proc | wc -l\n</code></pre></p> </li> <li>Does this command accurately count the processors?</li> <li>Check some quick processor statistics</li> </ul> <pre><code>iostat -c\niostat -c 2 # Wait for a while, then use Ctrl+C to break. What did this do? Try changing this to a different number.\niostat -c 2 5 # Don't break this, just wait. What did this do differently? Why might this be useful?\n</code></pre> <p>Does this look familiar to what we did earlier with <code>iostat</code>?</p> <ol> <li>Check the system uptime</li> </ol> <pre><code>uptime\nman uptime\n</code></pre> <p>Read <code>man uptime</code> and figure out what those 3 numbers represent.    Referencing this server, do you think it is under high load? Why or why not?</p> <ol> <li>Check who has recently logged into the server and who is currently in</li> </ol> <pre><code>last\n</code></pre> <p>Last is a command that outputs backwards. (Top is most recent).    So it is less than useful without using the more command.</p> <pre><code>last | more\n</code></pre> <ul> <li> <p>Were you the last person to log in? Who else has logged in today?      <pre><code>w\nwho\nwhoami\n</code></pre>      How many other users are on this system? What does the <code>pts/0</code> mean on Google?</p> </li> <li> <p>Check running processes and services</p> </li> </ul> <pre><code>ps -aux | more\nps -ef | more\nps -ef | wc -l\n</code></pre> <ul> <li>Try to use what you've learned to see all the processes owned by your user</li> <li> <p>Try to use what you've learned to count up all of those processes owned by your user</p> </li> <li> <p>Looking at system usage (historical)</p> </li> <li>Check processing for last day      <pre><code>sar | more\n</code></pre></li> <li>Check memory for the last day      <pre><code>sar -r | more\n</code></pre></li> </ul> <p>Sar is a tool that shows the 10 minute weighted average of the system for the last day.</p> <p>Sar is tremendously useful for showing long periods of activity and system load. It is exactly the opposite in it's usefulness of spikes or high traffic loads. In a 20 minute period of 100% usage a system may just show to averages times of 50% and 50%, never actually giving accurate info.</p> <p>Problems typically need to be proactively tracked by other means, or with scripts, as we will see below. Sar can also be run interactively. Run the command <code>yum whatprovides sar</code> and you will see that it is the <code>sysstat</code> package. You may have guessed that sar runs almost exactly like <code>iostat</code>.</p> <ul> <li>Try the same commands from earlier, but with their interactive information:</li> </ul> <pre><code>sar 2  # Ctrl+C to break\nsar 2 5\n# or\nsar -r 2\nsar -r 2 5\n</code></pre> <ul> <li>Check sar logs for previous daily usage   <pre><code>cd /var/log/sa/\nls\n# Sar logfiles will look like: sa01 sa02 sa03 sa04 sa05 sar01 sar02 sar03 sar04\nsar -f sa03 | head\nsar -r -f sa03 | head #should output just the beginning of 3 July (whatever month you're in).\n</code></pre>   Most Sar data is kept for just one month but is very configurable.   Read <code>man sar</code> for more info.</li> </ul> <p>Sar logs are not kept in a readable format, they are binary. So if you needed to dump all the sar logs from a server, you'd have to output it to a file that is readable.</p> <p>You could do something like this:</p> <ul> <li>Gather information and move to the right location</li> </ul> <pre><code>cd /var/log/sa\npwd\nls\n</code></pre> <p>We know the files we want are in this directory and all look like this <code>sa*</code></p> <ul> <li>Build a loop against that list of files</li> </ul> <pre><code>for file in `ls /var/log/sa/sa??`; do echo \"reading this file $file\"; done\n</code></pre> <ul> <li>Execute that loop with the output command of sar instead of just saying the filename</li> </ul> <pre><code>for file in `ls /var/log/sa/sa?? | sort -n`; do sar -f $file ; done\n</code></pre> <ul> <li>But that is too much scroll, so let's also send it to a file for later viewing</li> </ul> <pre><code>for file in `ls /var/log/sa/sa?? | sort -n`; do sar -f $file | tee -a /tmp/sar_data_`hostname`; done\n</code></pre> <ul> <li>Let's verify that file is as long as we expect it to be:</li> </ul> <pre><code>ls -l /tmp/sar_data*\ncat /tmp/sar_data_&lt;yourhostname&gt; | wc -l\n</code></pre> <ul> <li>Is it what you expected? You can also visually check it a number of ways   <pre><code>cat /tmp/&lt;filename&gt;\nmore /tmp/&lt;filename&gt;\n</code></pre></li> </ul>"},{"location":"lac/u4lab/#exploring-cron","title":"Exploring Cron:","text":"<p>Your system is running the cron daemon. You can check with:</p> <pre><code>ps -ef | grep -i cron\nsystemctl status crond\n</code></pre> <p>This is a tool that wakes up between the 1st and 5th second of every minute and checks to see if it has any tasks it needs to run. It checks in a few places in the system for these tasks. It can either read from a crontab or it can execute tasks from files found in the following locations.</p> <p><code>/var/spool/cron</code> is one location you can <code>ls</code> to check if there are any crontabs on your system.</p> <p>The other locations are directories found under:</p> <pre><code>ls -ld /etc/cron*\n</code></pre> <p>These should be self-explanatory in their use. If you want to see if the user you are running has a crontab, use the command <code>crontab -l</code>. If you want to edit (using your default editor, probably <code>vi</code>), use <code>crontab -e</code>.</p> <p>We'll make a quick crontab entry and I'll point you here if you're interested in learning more.</p> <p>Crontab format looks like this picture:</p> <pre><code># .- Minute (0 - 59)\n# | .- Hour (0 - 23)\n# | | .- Day of month (1 - 31)\n# | | | .- Month (1 - 12)\n# | | | | .- Day of week (0 - 6) (Sunday to Saturday - Sunday is also 7 on some systems)\n# | | | | |\n# | | | | |\n  * * * * *  command to be executed\n</code></pre> <p>Let's do these steps.</p> <ol> <li><code>crontab -e</code></li> <li>Add this line (using vi commands - Revisit <code>vimtutor</code> if you need help with them)</li> </ol> <pre><code>* * * * * echo 'this is my cronjob running at' `date` | wall\n</code></pre> <ol> <li>Verify with <code>crontab -l</code>.</li> <li>Wait to see if it runs and echos out to wall.</li> <li><code>cat /var/spool/cron/root</code> to see that it is actually stored where I said it was.</li> <li>This will quickly become very annoying, so I recommend removing that line, or commenting it    out (<code>#</code>) from that file.</li> </ol> <p>We can change all kinds of things about this to execute at different times. The one above, we executed every minute through all hours, of every day, of every month.</p> <p>We could also have done some other things:</p> <ul> <li>Every 2 minutes (divisible by any number you need):</li> </ul> <pre><code>*/2 * * * *\n</code></pre> <ul> <li>The first and 31st minute of each hour:</li> </ul> <pre><code>1,31 * * * *\n</code></pre> <ul> <li>The first minute of every 4th hour:</li> </ul> <pre><code>1 */4 * * *\n</code></pre> <ul> <li>NOTE: If you're adding system-wide cron jobs (<code>/etc/crontab</code>), you can also specify   the user to run the command as.   <pre><code>* * * * * &lt;user&gt; &lt;command&gt;\n</code></pre></li> </ul> <p>There's a lot there to explore, I recommend looking into the Cron wiki or tldp.org's cron guide for more information.</p> <p>That's all for this week's lab. There are a lot of uses for all of these tools above. Most of what I've shown here, I'd liken to showing you around a tool box. Nothing here is terribly useful in itself, the value comes from knowing the tool exists and then being able to properly apply it to the problem at hand.</p> <p>I hope you enjoyed this lab.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u4ws/","title":"Worksheet","text":""},{"location":"lac/u4ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u4ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Operations Bridge</li> <li>Security Incident Cheatsheet</li> <li>Battle Drills</li> </ul>"},{"location":"lac/u4ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u4_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u4_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u4ws/#unit-4-recording","title":"Unit 4 Recording","text":""},{"location":"lac/u4ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Read this article: https://cio-wiki.org/wiki/Operations_Bridge</p> <ol> <li> <p>What terms and concepts are new to you?</p> </li> <li> <p>Which pro seems the most important to you? Why?</p> </li> <li> <p>Which con seems the most costly, or difficult to overcome to you? Why?</p> </li> </ol>"},{"location":"lac/u4ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   Your team has no documentation around how to check out a server during an incident. Write out a procedure of what you think an operations person should be doing on the system they suspect is not working properly.   <p>This may help, to get you started https://zeltser.com/media/docs/security-incident-survey-cheat-sheet.pdf?msc=Cheat+Sheet+Blog You may use AI for this, but let us know if you do.</p>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u4ws/#definitions","title":"Definitions","text":"<p>Detection:</p> <p>Response:</p> <p>Mitigation:</p> <p>Reporting:</p> <p>Recovery:</p> <p>Remediation:</p> <p>Lessons Learned:</p> <p>After action review:</p> <p>Operations Bridge:</p>"},{"location":"lac/u4ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Read about battle drills here https://en.wikipedia.org/wiki/Battle_drill</p> </li> <li> <p>Why might it be important to practice incident handling before an incident occurs?</p> </li> <li> <p>Why might it be important to understand your tools before an incident occurs?</p> </li> </ol>"},{"location":"lac/u4ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How much better has your note taken gotten since you started?    What do you still need to work on? Have you started using a different tool?    Have you taken more notes?</p> </li> </ol>"},{"location":"lac/u5intro/","title":"Managing Users and Groups","text":""},{"location":"lac/u5intro/#overview","title":"Overview","text":"<p>This unit focuses on managing user's environments and scanning and enumerating Systems.</p> <ul> <li>Become familiar with networking scanning tools</li> <li>Understand the functionality systems files and customized .(dot) files.</li> </ul>"},{"location":"lac/u5intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Become familiar with Networking mapping:</p> </li> <li> <p>Learn how to find your network inventory by using nmap.</p> </li> <li> <p>Grasp the basics of targeted scans by scanning virtual boxes and creating a report.</p> </li> <li> <p>Explore the system files:</p> </li> <li> <p>Understand the structure of the /etc/passwd file by using the cat command.</p> </li> <li>Customize the /etc/skel file to create a default shell environment for the users.</li> </ol>"},{"location":"lac/u5intro/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of networking.</li> <li>Familiarity with nmap.</li> <li>Intermediate understanding of file manipulation commands.</li> <li>General idea of bash scripting.</li> </ul>"},{"location":"lac/u5intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Footprinting</p> <p>Scanning</p> <p>Enumeration</p> <p>System Hacking</p> <p>Escalation of Privilege</p> <p>Rule of Least Privilege</p> <p>Covering Tracks</p> <p>Planting Backdoors</p>"},{"location":"lac/u5lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u5lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>RedHat: User and Group Management</li> <li>Rocky Linux User Admin Guide</li> <li>Killercoda lab by FishermanGuyBro</li> </ul>"},{"location":"lac/u5lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u5lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u5_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u5_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u5lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>Exercises (Warmup to quickly run through your system and practice commands)</p> <ol> <li><code>mkdir lab_users</code></li> <li><code>cd /lab_users</code></li> <li><code>cat /etc/passwd</code></li> <li>We'll be examining the contents of this file later</li> <li><code>cat /etc/passwd | tail -5</code></li> <li>What did this do to the output of the file?</li> <li><code>cat /etc/passwd | tail -5 | nl</code></li> <li><code>cat /etc/passwd | tail -5 | awk -F : \u2018{print $1, $3, $7}'</code></li> <li>What did that do and what do each of the <code>$#</code> represent?</li> <li>Can you give the 2nd, 5th, and 6th fields?</li> <li><code>cat /etc/passwd | tail -5 | awk -F : \u2018{print $NF}'</code></li> <li>What does this <code>$NF</code> mean? Why might this be useful to us as administrators?</li> <li><code>alias</code></li> <li>Look at the things you have aliased.</li> <li>These come from defaults in your <code>.bashrc</code> file. We'll configure these later</li> <li><code>cd /root</code></li> <li><code>ls -l</code></li> <li><code>ll</code><ul> <li>Output should be similar.</li> </ul> </li> <li><code>unalias ll</code></li> <li><code>ll</code><ul> <li>You shouldn't have this command available anymore.</li> </ul> </li> <li><code>ls</code></li> <li><code>unalias ls</code><ul> <li>How did <code>ls</code> change on your screen?</li> </ul> </li> </ol> <p>No worries, there are two ways to fix the mess you've made. Nothing you've done is permanent, so logging out and reloading a shell (logging back in) would fix this. We just put the aliases back.</p> <ol> <li><code>alias ll='ls -l --color=auto'</code></li> <li><code>alias ls='ls --color=auto'</code><ul> <li>Test with <code>alias</code> to see them added and also use <code>ll</code> and <code>ls</code> to see them work properly.</li> </ul> </li> </ol>"},{"location":"lac/u5lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to help you get familiar with the basics of the systems you will be working on.</p> <p>Some of you will find that you know the basic material but the techniques here allow you to put it together in a more complex fashion.</p> <p>It is recommended that you type these commands and do not copy and paste them. Browsers sometimes like to format characters in a way that doesn't always play nice with Linux.</p>"},{"location":"lac/u5lab/#the-shadow-password-suite","title":"The Shadow password suite:","text":"<p>There are 4 files that comprise of the shadow password suite. We'll investigate them a bit and look at how they secure the system. The four files are <code>/etc/passwd</code>, <code>/etc/group</code>, <code>/etc/shadow</code>, and <code>/etc/gshadow</code>.</p> <ol> <li>Look at each of the files and see if you can determine some basic information about them</li> </ol> <pre><code>more /etc/passwd\nmore /etc/group\nmore /etc/shadow\nmore /etc/gshadow\n</code></pre> <p>There is one other file you may want to become familiar with:</p> <pre><code>more /etc/login.defs\n</code></pre> <p>Check the file permissions:</p> <pre><code>ls -l /etc/passwd\n</code></pre> <p>Do this for each file to see how their permissions are set.</p> <p>You may note that <code>/etc/passwd</code> and <code>/etc/group</code> are readable by everyone on the system    but <code>/etc/shadow</code> and <code>/etc/gshadow</code> are not readable by anyone on the system.</p> <ol> <li>Anatomy of the <code>/etc/passwd</code> file    <code>/etc/passwd</code> is broken down like this, a <code>:</code> (colon) delimited file:</li> </ol> Username Password User ID (UID) Group ID (GID) User Info Home Directory Login Shell <code>puppet</code> <code>x</code> <code>994</code> <code>991</code> <code>Puppet server daemon</code> <code>/opt/puppetlabs/server/data/puppetserver</code> <code>/sbin/nologin</code> <p><code>cat</code> or <code>more</code> the file to verify these are values you see.</p> <p>Are there always 7 fields?</p> <ol> <li>Anatomy of the <code>/etc/group</code> file    <code>/etc/group</code> is broken down like this, a <code>:</code> (colon) delimited file:</li> </ol> Groupname Password Group ID Group Members <code>puppet</code> <code>x</code> <code>991</code> <code>foreman, foreman-proxy</code> <ul> <li> <p><code>cat</code> or <code>more</code> the file to verify these are the values you see. Are there always 4 fields?</p> </li> <li> <p>We're not going to break down the <code>g</code> files, but there are a lot of resources online that    can show you this same information.    Suffice it to say, the passwords, if they exist, are stored in    an md5 digest format up to RHEL 5. RHEL 6,7,8 and 9 use SHA-512 hash.    We cannot allow these to be read by just anyone because then they could brute force    and try to figure out our passwords.</p> </li> </ul>"},{"location":"lac/u5lab/#creating-and-modifying-local-users","title":"Creating and modifying local users:","text":"<p>We should take a second to note that the systems you're using are tied into our active directory with Kerberos. You will not be seeing your account in <code>/etc/passwd</code>, as that authentication is occurring remotely. You can, however, run <code>id &lt;username&gt;</code> to see user information about yourself that you have according to active directory. Your <code>/etc/login.defs</code> file is default and contains a lot of the values that control how our next commands work</p> <ol> <li>Creating users</li> </ol> <pre><code>useradd user1\nuseradd user2\nuseradd user3\n</code></pre> <p>Do a quick check on our main files:</p> <pre><code>tail -5 /etc/passwd\ntail -5 /etc/shadow\n</code></pre> <p>What <code>UID</code> and <code>GID</code> were each of these given? Do they match up?    Verify your users all have home directories. Where would you check this?</p> <pre><code>ls /home\n</code></pre> <p>Your users <code>/home/&lt;username&gt;</code> directories have hidden files that were all pulled from a    directory called <code>/etc/skel</code>. If you wanted to test this and verify you might do something like    this:</p> <pre><code>cd /etc/skel\nvi .bashrc\n</code></pre> <p>Use <code>vi</code> commands to add the line:</p> <pre><code>alias dinosaur='echo \"Rarw\"'\n</code></pre> <p>Your file should now look like this:</p> <pre><code># .bashrc\n# Source global definitions\nif [ -f /etc/bashrc ]; then\n. /etc/bashrc\nfi\nalias dinosaur='echo \"Rarw\"'\n# Uncomment the following line if you don't like systemctl's auto-paging feature:\n# export SYSTEMD_PAGER=\n# User specific aliases and functions\n</code></pre> <p>Save the file with <code>:wq</code>.</p> <pre><code>useradd user4\nsu - user4\ndinosaur # Should roar out to the screen\n</code></pre> <p>Doing that changed the <code>.bashrc</code> file for all new users that have home directories created on the server.    An old trick, when users mess up their login files (all the <code>.</code> files), is to move them all to a    directory and pull them from <code>/etc/skel</code> again.    If the user can log in with no problems, you know the problem was something they created.</p> <p>We can test this with the same steps on an existing user.    Pick an existing user and verify they don't have that command</p> <pre><code>su - user1\ndinosaur # Command not found\nexit\n</code></pre> <p>Then, as root:</p> <pre><code>cd /home/user1\nmkdir old_dot_files\nmv .* old_dot_files          # Ignore the errors, those are directories\ncp /etc/skel/.* /home/user1  # Ignore the errors, those are directories\nsu - user1\ndinosaur # Should 'roar' now because the .bashrc file is new from /etc/skel\n</code></pre> <ol> <li>Creating groups    From our <code>/etc/login.defs</code> we can see that the default range for UIDs on this system, when created by    <code>useradd</code> are:</li> </ol> <pre><code>UID_MIN 1000\nUID_MAX 60000\n</code></pre> <p>So an easy way to make sure that we don't get confused on our group numbering is to ensure we create    groups outside of that range.    This isn't required, but can save you headache in the future.</p> <pre><code>groupadd -g 60001 project\ntail -5 /etc/group\n</code></pre> <p>You can also make groups the old fashioned way by putting a line right into the <code>/etc/group</code> file.    Try this:</p> <pre><code>vi /etc/group\n</code></pre> <ul> <li>Shift+G to go to the bottom of the file.</li> <li>Hit <code>o</code> to create a new line and go to insert mode.</li> <li>Add <code>project2:x:60002:user4</code></li> <li>Hit <code>Esc</code></li> <li><code>:wq!</code> to write quit the file explicit force because it's a read only file.</li> </ul> <pre><code>id user 4 # Should now see the project2 in the user's groups\n</code></pre> <ol> <li>Modifying or deleting users    So maybe now we need to move our users into that group.</li> </ol> <pre><code>usermod -G project user4\ntail -f /etc/group # Should see user4 in the group\n</code></pre> <p>But, maybe we want to add more users and we want to just put them in there:</p> <pre><code>vi /etc/group\n</code></pre> <ul> <li><code>Shift+G</code> Will take you to the bottom.</li> <li>Hit <code>i</code> (will put you into insert mode).</li> <li>Add <code>,user1,user2</code> after <code>user4</code>.</li> <li>Hit <code>Esc</code>.</li> <li><code>:wq</code> to save and exit.      Verify your users are in the group now</li> </ul> <pre><code>id user4\nid user1\nid user2\n</code></pre> <ol> <li>Test group permissions    I included the permissions discussion from an earlier lab because it's important to see how    permissions affect what user can see what information.</li> </ol> <p>Currently we have <code>user1,2,4</code> belonging to group <code>project</code> but not <code>user3</code>. So we will verify these    permissions are enforced by the filesystem.</p> <pre><code>mkdir /project\nls -ld /project\nchown root:project /project\ncmod 775 /project\nls -ld /project\n</code></pre> <p>If you do this, you now have a directory <code>/project</code> and you've changed the group ownership to <code>/project</code>.    You've also given group <code>project</code> users the ability to write into your directory.    Everyone can still read from your directory.    Check permissions with users:</p> <pre><code>su - user1\ncd /project\ntouch user1\nexit\nsu - user3\ncd /project\ntouch user3\nexit\n</code></pre> <p>Anyone not in the <code>project</code> group doesn't have permissions to write a file into that directory.    Now, as the root user:</p> <pre><code>chmod 770 /project\n</code></pre> <p>Check permissions with users:</p> <pre><code>su - user1\ncd /project\ntouch user1.1\nexit\nsu - user3\ncd /project # Should break right about here\ntouch user3\nexit\n</code></pre> <p>You can play with these permissions a bit, but there's a lot of information online to help you    understand permissions better if you need more resources.</p>"},{"location":"lac/u5lab/#working-with-permissions","title":"Working with permissions:","text":"<p>Permissions have to do with who can or cannot access (read), edit (write), or execute (xecute)files. Permissions look like this:</p> <pre><code>ls -l\n</code></pre> Permission # of Links UID Owner Group Owner Size (b) Creation Month Creation Day Creation Time Name of File <code>-rw-r--r--.</code> <code>1</code> <code>scott</code> <code>domain_users</code> <code>58</code> <code>Jun</code> <code>22</code> <code>08:52</code> <code>datefile</code> <p>The primary permissions commands we're going to use are going to be <code>chmod</code> (access) and <code>chown</code> (ownership).</p> <p>A quick rundown of how permissions break out:</p> <p></p> <p>Let's examine some permissions and see if we can't figure out what permissions are allowed:</p> <pre><code>ls -ld /home/scott/\ndrwx. 5 scott domain_users 4096 Jun 22 09:11 /home/scott/\n</code></pre> <p>The first character lets you know if the file is a directory, file, or link. In this case we are looking at my home directory.</p> <p><code>rwx</code>: For UID (me).</p> <ul> <li>What permissions do I have?</li> </ul> <p>``: For group.</p> <ul> <li>Who are they?</li> <li>What can my group do?</li> </ul> <p>``: For everyone else.</p> <ul> <li>What can everyone else do?</li> </ul> <p>Go find some other interesting files or directories and see what you see there. Can you identify their characteristics and permissions?</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u5ws/","title":"Worksheet","text":""},{"location":"lac/u5ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u5ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>OWASP Top Ten</li> <li>attack.mitre.org</li> <li>Attack Vectors</li> </ul>"},{"location":"lac/u5ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u5_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u5_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u5ws/#unit-5-recording","title":"Unit 5 Recording","text":""},{"location":"lac/u5ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Review the page: https://attack.mitre.org/</p> <ol> <li> <p>What terms and concepts are new to you?</p> </li> <li> <p>Why, as a system administrator and not directly in security, do you think it\u2019s so important to understand how your systems can be attacked? Isn\u2019t it someone else\u2019s problem to think about that?</p> </li> <li> <p>What impact to the organization is data exfiltration? Even if you\u2019re not a data owner or data custodian, why is it so important to understand the data on your systems?</p> </li> </ol>"},{"location":"lac/u5ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Find a blog or article on the web that discusses the user environment in Linux. You may want to search for .bashrc or (dot) environment files in Linux.</p> <ol> <li> <p>What types of customizations might you setup for your environment? Why?</p> </li> <li> <p>What problems can you anticipate around helping users with their dot files?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <p>Link to Discussion Posts</p>"},{"location":"lac/u5ws/#definitions","title":"Definitions","text":"<p>Footprinting:</p> <p>Scanning:</p> <p>Enumeration:</p> <p>System Hacking:</p> <p>Escalation of Privilege:</p> <p>Rule of least privilege:</p> <p>Covering Tracks:</p> <p>Planting Backdoors:</p>"},{"location":"lac/u5ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Read this page: https://owasp.org/www-project-top-ten/</p> </li> <li> <p>What is the OWASP Top Ten?</p> </li> <li> <p>Why is this important to know as a system administrator?</p> </li> <li> <p>Read this article: https://www.cobalt.io/blog/defending-against-23-common-attack-vectors</p> </li> <li>What is an attack vector?</li> <li>Why might it be a good idea to keep up to date with these?</li> </ol>"},{"location":"lac/u5ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li>What questions do you still have about this week?</li> <li>How are you going to use what you\u2019ve learned in your current role?</li> </ol>"},{"location":"lac/u6b/","title":"U6b","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p> <p>Enhance productivity by enabling the management of multiple sessions and windows from a single remote session.</p>"},{"location":"lac/u6b/#key-features-of-terminal-multiplexors","title":"Key Features of Terminal Multiplexors","text":""},{"location":"lac/u6b/#create-multiple-windowspanes","title":"Create Multiple Windows/Panes \ud83e\ude9f","text":"<p>Split your terminal into panes (or windows) so you can run different commands or tasks simultaneously.</p>"},{"location":"lac/u6b/#detach-and-reattach-sessions","title":"Detach and Reattach Sessions \ud83e\ude9d","text":"<p>You can detach from a session (e.g., when you log out of a remote server), and later reattach to it exactly as you left it.</p>"},{"location":"lac/u6b/#persistence-of-long-running-tasks","title":"Persistence of Long-Running Tasks","text":"<p>If your network connection drops, the tasks keep running on the server, and you can reattach to them later.</p>"},{"location":"lac/u6b/#collaborate","title":"Collaborate","text":"<p>Some terminal multiplexers allow multiple users to connect to the same session, enabling collaborative work on a single system.</p>"},{"location":"lac/u6b/#popular-terminal-multiplexors","title":"Popular Terminal Multiplexors","text":""},{"location":"lac/u6b/#tmux","title":"Tmux","text":"<ul> <li>Is widely used by developers and system administrators for its flexible configuration and vibrant community support.</li> <li>Its popularity also stems from its straightforward scripting capabilities, making it highly useful for automation.</li> </ul>"},{"location":"lac/u6b/#tmux-resources","title":"Tmux Resources","text":"<p>Tmux, a terminal multiplexer written in C, emerged around 2007, noted for its customizable configuration and scripting. Despite its popularity and flexibility, users occasionally report stability issues and complex scripting. Tmux, crafted in 2007 by Nicholas Marriott in C, marked an evolution from GNU Screen. Its flexible configuration appeals to system admins, despite some users finding the setup syntax intricate. Tmux, created by Nicholas Marriott in 2007, is a C-based terminal multiplexer famous for its configuration flexibility and scripting prowess, but newcomers often find its syntax intricate.</p> <ul> <li>Tmux Wiki</li> <li>Tmux Cheatsheet</li> </ul>"},{"location":"lac/u6b/#gnu-screen","title":"GNU Screen","text":"<p>GNU Screen, created by Oliver Laumann in 1987 and written in C, became one of the first mainstream terminal multiplexers, remaining a staple in many Linux distributions. Praised for its stability and included by default in numerous systems, it can still be considered less intuitive in configuration compared to newer options like tmux.</p> <ul> <li>is one of the original terminal multiplexers and remains popular due to its reliable, time-tested features.</li> <li>It continues to be bundled with many Linux distributions by default, contributing to its enduring user base.</li> </ul>"},{"location":"lac/u6b/#gnu-screen-resources","title":"GNU Screen Resources","text":"<ul> <li>GNU Screen Site</li> <li>GNU Screen Manual</li> </ul>"},{"location":"lac/u6b/#zellij","title":"Zellij","text":"<p>Zellij, first released in 2020 and written in Rust, is a newcomer to the terminal multiplexer space that focuses on an intuitive UI and easy collaboration. While its modern approach and built-in layout management offer clear advantages over older tools, its relatively small community and limited ecosystem may pose challenges for widespread adoption.</p> <ul> <li>Although not yet included in the default repositories of all distributions, Zellij is rapidly gaining visibility because of its modern design and user-friendly layout management.</li> <li>Its growing ecosystem of plugins and emphasis on collaboration make it an attractive choice for developers seeking a more advanced terminal multiplexer.</li> </ul>"},{"location":"lac/u6b/#zellij-resources","title":"Zellij Resources","text":"<ul> <li>Zellij Site</li> </ul>"},{"location":"lac/u6b/#downloads","title":"Downloads","text":""},{"location":"lac/u6intro/","title":"Firewalls","text":""},{"location":"lac/u6intro/#overview","title":"Overview","text":"<p>This unit focuses on Nohup environments and firewalls.</p> <ul> <li>We will cover Nohup tools and how to properly use Nohup environments.</li> <li>We will explore different types of firewalls and learn the use cases for each firewall type.</li> </ul>"},{"location":"lac/u6intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Become familiar with the <code>nohup</code> command:</p> </li> <li> <p>Learn real-life use cases of the <code>nohup</code> command.</p> </li> <li> <p>Understand the correlation between jump boxes and Nohup environments, including <code>screen</code> and <code>tmux</code>.</p> </li> <li> <p>Implement and manage Nohup environments:</p> </li> <li> <p>Learn how <code>nohup</code> allows processes to continue running after a user logs out, ensuring that long-running tasks are not interrupted.</p> </li> <li> <p>Develop skills in managing background processes effectively using <code>nohup</code>, <code>screen</code>, and <code>tmux</code>.</p> </li> <li> <p>Develop effective troubleshooting methodologies:</p> </li> <li>Acquire systematic approaches to diagnosing firewall misconfigurations, network connectivity issues, and unauthorized access attempts.</li> <li>Apply structured troubleshooting strategies to minimize downtime and maintain high availability.</li> </ol>"},{"location":"lac/u6intro/#prerequisites","title":"Prerequisites","text":"<ul> <li>A basic understanding of how processes work.</li> <li>Familiarity with the <code>firewalld</code> service.</li> <li>The ability to understand <code>.xml</code> files.</li> </ul>"},{"location":"lac/u6intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Firewall</p> <p>Zone</p> <p>Service</p> <p>DMZ (Demilitarized Zone)</p> <p>Proxy</p> <p>Stateful Packet Filtering</p> <p>Stateless Packet Filtering</p> <p>WAF (Web Application Firewall)</p> <p>NGFW (Next-Generation Firewall):</p>"},{"location":"lac/u6lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u6lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Firewalld Official Documentation</li> <li>RedHat Firewalld Documentation</li> </ul>"},{"location":"lac/u6lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u6lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u6_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u6_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u6lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>Exercises (Warmup to quickly run through your system and practice commands)</p> <ol> <li><code>cd~</code></li> <li><code>pwd (should be /home/&lt;yourusername&gt;)</code></li> <li><code>cd /tmp</code></li> <li><code>pwd (should be /tmp)</code></li> <li><code>cd</code></li> <li><code>pwd (should be /home/&lt;yourusername&gt;)</code></li> <li><code>mkdir lab_firewalld</code></li> <li><code>cd lab_firewalld</code></li> <li><code>touch testfile1</code></li> <li><code>ls</code></li> <li><code>touch testfile{2..10}</code></li> <li><code>ls</code></li> <li><code>seq 10</code></li> <li><code>seq 1 10</code></li> <li><code>seq 1 2 10</code><ul> <li>man seq and see what each of those values mean. It\u2019s important to know the behavior if you intend to ever use the command, as we often do with counting (for) loops.</li> </ul> </li> </ol> <p>No worries, there are two ways to fix the mess you've made. Nothing you've done is permanent, so logging out and reloading a shell (logging back in) would fix this. We just put the aliases back.</p> <ol> <li><code>for i in</code>seq 1 10<code>; do touch file$i; done;</code></li> <li><code>ls</code><ul> <li>Think about some of those commands and when you might use them. Try to change command #15 to remove all of those files (rm -rf file$i)</li> </ul> </li> </ol>"},{"location":"lac/u6lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to help you get familiar with the basics of the systems you will be working on.</p> <p>Some of you will find that you know the basic material but the techniques here allow you to put it together in a more complex fashion.</p> <p>It is recommended that you type these commands and do not copy and paste them. Browsers sometimes like to format characters in a way that doesn't always play nice with Linux.</p>"},{"location":"lac/u6lab/#check-firewall-status-and-settings","title":"Check Firewall Status and settings:","text":"<p>A very important thing to note before starting this lab. You\u2019re connected into that server on ssh via port 22. If you do anything to lockout port 22 in this lab, you will be blocked from that connection and we\u2019ll have to reset it.</p> <ol> <li>Check firewall status</li> </ol> <pre><code>[root@schampine ~]# systemctl status firewalld\n</code></pre> <p>Example Output:</p> <pre><code>firewalld.service - firewalld - dynamic firewall daemon\nLoaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)\nActive: inactive (dead) since Sat 2017-01-21 19:27:10 MST; 2 weeks 6 days ago\n Main PID: 722 (code=exited, status=0/SUCCESS)\n\nJan 21 19:18:11 schampine firewalld[722]: 2017-01-21 19:18:11 ERROR: COMMAND....\nJan 21 19:18:13 schampine firewalld[722]: 2017-01-21 19:18:13 ERROR: COMMAND....\nJan 21 19:18:13 schampine firewalld[722]: 2017-01-21 19:18:13 ERROR: COMMAND....\nJan 21 19:18:13 schampine firewalld[722]: 2017-01-21 19:18:13 ERROR: COMMAND....\nJan 21 19:18:13 schampine firewalld[722]: 2017-01-21 19:18:13 ERROR: COMMAND....\nJan 21 19:18:14 schampine firewalld[722]: 2017-01-21 19:18:14 ERROR: COMMAND....\nJan 21 19:18:14 schampine firewalld[722]: 2017-01-21 19:18:14 ERROR: COMMAND....\nJan 21 19:18:14 schampine firewalld[722]: 2017-01-21 19:18:14 ERROR: COMMAND....\nJan 21 19:27:08 schampine systemd[1]: Stopping firewalld - dynamic firewall.....\nJan 21 19:27:10 schampine systemd[1]: Stopped firewalld - dynamic firewall ...n.\n</code></pre> <p>Hint: Some lines were ellipsized, use -l to show in full.</p>"},{"location":"lac/u6lab/#if-necessary-start-the-firewalld-daemon","title":"If necessary start the firewalld daemon:","text":"<pre><code>systemctl start firewalld\n</code></pre>"},{"location":"lac/u6lab/#set-the-firewalld-daemon-to-be-persistent-through-reboots","title":"Set the firewalld daemon to be persistent through reboots:","text":"<pre><code>systemctl enable firewalld\n</code></pre> <p>Verify with systemctl status firewalld again from step 1</p>"},{"location":"lac/u6lab/#check-which-zones-exist","title":"Check which zones exist:","text":"<pre><code>firewall-cmd --get-zones\n</code></pre>"},{"location":"lac/u6lab/#checking-the-values-within-each-zone","title":"Checking the values within each zone:","text":"<pre><code>firewall-cmd --list-all --zone=public\n</code></pre> <p>General Output</p> <pre><code>public (default, active)\ninterfaces: wlp4s0\nsources:\nservices: dhcpv6-client ssh\nports:\nmasquerade: no\nforward-ports:\nicmp-blocks:\nrich rules:\n</code></pre>"},{"location":"lac/u6lab/#checking-the-active-and-default-zones","title":"Checking the active and default zones:","text":"<pre><code>firewall-cmd --get-default\n</code></pre> <p>Example Output:</p> <pre><code>public\n</code></pre> <p>Next Command</p> <pre><code>firewall-cmd --get-active\n</code></pre> <p>Example Output:</p> <pre><code>public\ninterfaces: wlp4s0\n</code></pre> <p>Note: this also shows which interface the zone is applied to. Multiple interfaces and zones can be applied</p> <p>So now you know how to see the values in your firewall. Use steps 4 and 5 to check all the values of the different zones to see how they differ.</p>"},{"location":"lac/u6lab/#set-the-firewall-active-and-default-zones","title":"Set the firewall active and default zones:","text":"<p>We know the zones from above, set your firewall to the different active or default zones. Default zones are the ones that will come up when the firewall is restarted.</p> <p>Note: It may be useful to perform an <code>ifconfig -a</code> and note your interfaces for the next part</p> <pre><code>ifconfig -a | grep -i flags\n</code></pre> <p>Example Output:</p> <pre><code>[root@rocky ~]# ifconfig -a | grep -i flags\ndocker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\nens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500\nlo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536\n</code></pre> <ol> <li>Changing the default zones (This is permanent over a reboot, other commands require --permanent switch)</li> </ol> <pre><code>firewall-cmd --set-default-zone=work\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Next Command:</p> <pre><code>firewall-cmd --get-active-zones\n</code></pre> <p>Example Output:</p> <pre><code>work\n    interfaces: wlp4s0\n</code></pre> <p>Attempt to set it back to the original public zone and verify. Set it to one other zone, verify, then set it back to public.</p> <p>Changing interfaces and assigning different zones (use another interface from your earlier <code>ifconfig -a</code></p> <pre><code>firewall-cmd --change-interface=virbr0 --zone dmz\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Next Command:</p> <pre><code>firewall-cmd --add-source 192.168.11.0/24 --zone=public\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Next Command:</p> <pre><code>firewall-cmd --get-active-zones\n</code></pre> <p>Example Output:</p> <pre><code>dmz\n   interfaces: virbr0\nwork\n   interfaces: wlp4s0\npublic\n   sources: 192.168.200.0/24\n</code></pre>"},{"location":"lac/u6lab/#working-with-ports-and-services","title":"Working with ports and services:","text":"<p>We can be even more granular with our ports and services. We can block or allow services by port number, or we can assign port numbers to a service name and then block or allow those service names.</p> <ol> <li>List all services assigned in firewalld</li> </ol> <pre><code>firewall-cmd --get-services\n</code></pre> <p>Example Output:</p> <pre><code>RH-Satellite-6 amanda-client bacula bacula-client dhcp dhcpv6 dhcpv6-client dns freeipa-ldap freeipa-ldaps freeipa-replication ftp high-availability http https imaps ipp ipp-client ipsec iscsi-target kerberos kpasswd ldap ldaps libvirt libvirt-tls mdns mountd ms-wbt mysql nfs ntp openvpn pmcd pmproxy pmwebapi pmwebapis pop3s postgresql proxy-dhcp radius rpc-bind rsyncd samba samba-client smtp ssh telnet tftp tftp-client transmission-client vdsm vnc-server wbem-https\n</code></pre> <p>This next part is just to show you where the service definitions exist. They are simple xml format and can easily be manipulated or changed to make new services. This would require a restart of the firewalld service to re-read this directory.</p> <p>Next Command:</p> <pre><code>ls /usr/lib/firewalld/services/\n</code></pre> <p>Example Output:</p> <pre><code>amanda-client.xml        iscsi-target.xml  pop3s.xml\nbacula-client.xml        kerberos.xml      postgresql.xml\nbacula.xml               kpasswd.xml       proxy-dhcp.xml\ndhcpv6-client.xml        ldaps.xml         radius.xml\ndhcpv6.xml               ldap.xml          RH-Satellite-6.xml\ndhcp.xml                 libvirt-tls.xml   rpc-bind.xml\ndns.xml                  libvirt.xml       rsyncd.xml\nfreeipa-ldaps.xml        mdns.xml          samba-client.xml\nfreeipa-ldap.xml         mountd.xml        samba.xml\nfreeipa-replication.xml  ms-wbt.xml        smtp.xml\nftp.xml                  mysql.xml         ssh.xml\nhigh-availability.xml    nfs.xml           telnet.xml\nhttps.xml                ntp.xml           tftp-client.xml\nhttp.xml                 openvpn.xml       tftp.xml\nimaps.xml                pmcd.xml          transmission-client.xml\nipp-client.xml           pmproxy.xml       vdsm.xml\nipp.xml                  pmwebapis.xml     vnc-server.xml\nipsec.xml                pmwebapi.xml      wbem-https.xml\n</code></pre> <p>Next Command:</p> <pre><code>cat /usr/lib/firewalld/services/http.xml\n</code></pre> <p>Example Output:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;service&gt;\n  &lt;short&gt;WWW (HTTP)&lt;/short&gt;\n  &lt;description&gt;HTTP is the protocol used to serve Web pages. If you plan to make your Web       server publicly available, enable this option. This option is not required for viewing pages locally or developing Web pages.&lt;/description&gt;\n  &lt;port protocol=\"tcp\" port=\"80\"/&gt;\n&lt;/service&gt;\n</code></pre> <ol> <li>Adding a service or port to a zone</li> </ol> <p>Ensuring we are working on a public zone</p> <pre><code>firewall-cmd --set-default-zone=public\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Listing Services</p> <pre><code>firewall-cmd --list-services\n</code></pre> <p>Example Ouput:</p> <pre><code>dhcpv6-client ssh\n</code></pre> <p>Note: We have 2 services</p> <p>Permanently adding a service with the <code>--permanent</code> switch</p> <pre><code>firewall-cmd --permanent --add-service ftp\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Reloading</p> <pre><code>firewall-cmd --reload\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Verifying we are in the correct Zone</p> <pre><code>firewall-cmd --get-default-zone\n</code></pre> <p>Example Output:</p> <pre><code>public\n</code></pre> <p>Verifying that we have successfully added the FTP service</p> <pre><code>firewall-cmd --list-services\n</code></pre> <p>Example Output:</p> <pre><code>dhcpv6-client ftp ssh\n</code></pre> <p>Alternatively, we can do almost the same thing but not use a defined service name. If I just want to allow port 1147 through for TCP traffic, it is very simple as well.</p> <pre><code>firewall-cmd --permanent --add-port=1147/tcp\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Reloading once again</p> <pre><code>firewall-cmd --reload\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Listing open ports now</p> <pre><code>[root@schampine services]# firewall-cmd --list-ports\n</code></pre> <p>Example Output:</p> <pre><code>1147/tcp\n</code></pre> <ol> <li>Removing unwanted services or ports</li> </ol> <p>To remove those values and permanently fix the configuration back we simply use remove.</p> <p>Firstly, we will permanently remove ftp service</p> <pre><code>firewall-cmd --permanent --remove-service=ftp\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Then we will permanently remove the ports</p> <pre><code>firewall-cmd --permanent --remove-port=1147/tcp\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Now lets do a reload</p> <pre><code>firewall-cmd --reload\n</code></pre> <p>Example Output:</p> <pre><code>success\n</code></pre> <p>Now we can list services again to confirm our work</p> <pre><code>firewall-cmd --list-services\n</code></pre> <p>Example Output:</p> <pre><code>dhcpv6-client ssh\n</code></pre> <p>Now we can list ports</p> <pre><code>firewall-cmd --list-ports\n</code></pre> <p>Example Output:</p> <p><code>Nothing</code></p> <p>Before making any more changes I recommend running the <code>list</code> commands above with <code>&gt;&gt; /tmp/firewall.orig</code> on them so you have all your original values saved somewhere in case you need them.</p> <p>So now take this and set up some firewalls on the interfaces of your system. Change the default ports and services assigned to your different zones (at least 3 zones) Read the <code>man firewall-cmd</code> command or <code>firewall-cmd -help</code> to see if there are any other userful things you should know.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u6ws/","title":"Worksheet","text":""},{"location":"lac/u6ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u6ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Official Firewalld Documentation</li> <li>RedHat Firewalld Documentation</li> <li>Official UFW Documentation</li> <li>Wikipedia entry for Next-Gen Firewalls</li> </ul>"},{"location":"lac/u6ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u6_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u6_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u6ws/#unit-6-recording","title":"Unit 6 Recording","text":""},{"location":"lac/u6ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Scenario:</p>   A ticket has come in from an application team. Some of the servers your team built for them last week have not been reporting up to enterprise monitoring and they need it to be able to troubleshoot a current issue, but they have no data. You jump on the new servers and find that your engineer built everything correctly and the agents for node_exporter, ceph_exporter and logstash exporter that your teams use. But, they also have adhered to the new company standard of firewalld must be running. No one has documented the ports that need to be open, so you\u2019re stuck between the new standards and fixing this problem on live systems.   <p>Next, answer these questions here:</p> <ol> <li> <p>As you\u2019re looking this up, what terms and concepts are new to you?</p> </li> <li> <p>What are the ports that you need to expose? How did you find the answer?</p> </li> <li> <p>What are you going to do to fix this on your firewall?</p> </li> </ol>"},{"location":"lac/u6ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   A manager heard you were the one that saved the new application by fixing the firewall. They get your manager to approach you with a request to review some documentation from a vendor that is pushing them hard to run a WAF in front of their web application. You are \u201cthe firewall\u201d guy now, and they\u2019re asking you to give them a review of the differences between the firewalls you set up (which they think should be enough to protect them) and what a WAF is doing.   <ol> <li> <p>What do you know about the differences now?</p> </li> <li> <p>What are you going to do to figure out more?</p> </li> <li> <p>Prepare a report for them comparing it to the firewall you did in the first discussion.</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u6ws/#definitions","title":"Definitions","text":"<p>Firewall:</p> <p>Zone:</p> <p>Service:</p> <p>DMZ:</p> <p>Proxy:</p> <p>Stateful packet filtering:</p> <p>Stateless packet filtering:</p> <p>WAF:</p> <p>NGFW:</p>"},{"location":"lac/u6ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>Read https://docs.rockylinux.org/zh/guides/security/firewalld-beginners/    What new things did you learn that you didn\u2019t learn in the lab?    What functionality of firewalld are you likely to use in your professional work?</li> </ol>"},{"location":"lac/u6ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li>What questions do you still have about this week?</li> <li>How are you going to use what you\u2019ve learned in your current role?</li> </ol>"},{"location":"lac/u7b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p> <p>This bonus explores how you can audit and verify software integrity on your system using package tools, hashes, and file validation -- going deeper into real-world sysadmin practice.</p> <p>This is more of a bonus lab. We're going beyond just installing packages. We're going to audit, validate, and verify that the software on our system is trustworthy and unmodified. We'll explore how to detect unexpected changes using built-in tools, dig into package metadata, and get a taste of real-world security practices like intrusion detection and system baselining through package auditing.</p> <p>In modern enterprise environments, packages may be tampered with, misconfigured, or out-of-date.</p> <p>A responsible sysadmin needs tools and methods to answer questions like:</p> <ul> <li>Was this package installed from a trusted source?</li> <li>Have any of the installed files been modified?</li> <li>Which files belong to which packages?</li> <li>Can I detect and recover from unexpected changes?</li> </ul> <p>Let's get into it.</p>"},{"location":"lac/u7b/#verifying-package-integrity","title":"Verifying Package Integrity","text":"<p>Start by finding a package you know is installed and used in your environment -- for example, <code>sshd</code>:</p> <pre><code>rpm -qi openssh-server\n</code></pre> <p>Now, check the integrity of the package's files:</p> <pre><code>rpm -V openssh-server\n</code></pre> <ul> <li><code>-V</code>: Stands for verify.</li> <li>This option checks timestamps, permissions, ownership, and hashes of installed files.</li> </ul> <p>If you don't see any output, that's a good thing.</p> <p><code>rpm -V</code> only reports files that have been altered in some way from what the package database expects. If there is no output, it means all files match the expected checksums, sizes, permissions, etc..</p> <p>If this command does have output, being able to interpret the output is important. Each character in the output has its own meaning:</p> <ul> <li><code>S</code> - Size differs.</li> <li><code>M</code> - Mode differs (permissions).</li> <li><code>5</code> - MD5 checksum mismatch.</li> <li><code>T</code> - Modification time differs.</li> </ul> <p>This is a great way to verify the integrity of installed packages. It's also helpful in troubleshooting when a package isn't working as expected.</p>"},{"location":"lac/u7b/#auditing-a-file-in-a-package","title":"Auditing a File in a Package","text":"<p>Let's say you suspect something has been changed or tampered with. Let's get all files from a package.</p> <ul> <li>Run <code>rpm -ql</code> to list the files that were installed with a package:</li> </ul> <pre><code>rpm -ql openssh-server\n</code></pre> <ul> <li>Now pick one file and manually generate its sha256 hash:</li> </ul> <pre><code>sha256sum /usr/sbin/sshd\n</code></pre> <ul> <li>Download the original <code>.rpm</code> package to compare its hash.</li> </ul> <pre><code>dnf download openssh-server\n</code></pre> <ul> <li>This will download the <code>openssh-server-&lt;version&gt;.rpm</code> package in the current directory.</li> <li> <p>These <code>.rpm</code> packages are not stored on the system by default.</p> </li> <li> <p>You can inspect the file of your choice with <code>rpm -qp --dump</code>:</p> </li> </ul> <pre><code>rpm -qp --dump openssh-server*.rpm | grep ^/usr/sbin/sshd\n</code></pre> <p>This will output a bunch of information about the file.   The <code>sha256</code> hash will be in the fourth column, so we can use <code>awk</code> to extract that:</p> <pre><code>rpm -qp --dump openssh-server*.rpm | grep ^/usr/sbin/sshd | awk '{print $4}'\n</code></pre> <ul> <li>Compare your version's hash to the original RPM file's hash:</li> </ul> <pre><code>sha256sum /usr/sbin/sshd\n</code></pre> <p>If the hashes are different, the file has been modified.</p>"},{"location":"lac/u7b/#bonus-challenge","title":"Bonus Challenge \ud83d\udca1","text":"<ol> <li>Run this one-liner to verify all installed packages:    <pre><code>rpm -Va\n</code></pre></li> <li>This will verify every file from every package and report anything suspicious.</li> <li>Narrow the scope. Only show actual modified files:</li> </ol> <pre><code>rpm -Va | grep -v '^..5'\n</code></pre> <ul> <li>This removes lines where only the MD5 checksum differs (which could be expected in some config files).</li> <li> <p>You\u2019ll now see files where size, mode, owner, or timestamp changed \u2014 higher confidence indicators of real change.</p> </li> <li> <p>Investigate a suspicious result. If you see something like:</p> </li> </ul> <pre><code>.M....... c /etc/ssh/sshd_config\n</code></pre> <p>That means:</p> <ul> <li>The permissions (<code>M</code>) have changed.</li> <li> <p>It's a config file (<code>c</code>).</p> </li> <li> <p>Check the file in question:</p> </li> </ul> <pre><code>ls -l /etc/ssh/sshd_config\n</code></pre> <ol> <li>Compare that to what you expected:    <pre><code>rpm -q --qf '%{NAME} %{VERSION}-%{RELEASE}\\n' -f /etc/ssh/sshd_config\n</code></pre></li> </ol> <p>Then you can reinstall the package or extract the original file from the <code>.rpm</code> file.</p>"},{"location":"lac/u7b/#reflection-questions","title":"Reflection Questions","text":"<ul> <li>What happens if you manually modify a file, then verify with <code>rpm -V</code>?</li> <li>Can you identify if changes were made outside of DNF/RPM?</li> <li>What types of files are typically most important to verify?</li> </ul>"},{"location":"lac/u7b/#example-of-real-world-security-tools","title":"Example of Real-World Security Tools","text":"<p>Large enterprises often use tools like AIDE (Advanced Intrusion Detection Environment) or Tripwire to baseline their systems and detect changes over time.</p> <p>AIDE can be installed easily with <code>dnf</code>, so you can play around with it if you want. To set up AIDE on your system (as root):</p> <pre><code>dnf install aide -y\n\naide --init\n\n# Copy the default database to use as your database\ncp /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz\n\n# Then, to run a check with aide (this will take a few minutes):\naide --check\n</code></pre> <p>AIDE compares the current state of the system to a known baseline.</p> <p>This is foundational to change management, compliance, and intrusion detection.</p>"},{"location":"lac/u7b/#resources","title":"Resources","text":"<ul> <li>RPM Man Page</li> <li>AIDE Documentation</li> <li>Verifying RPM Packages</li> <li>Using sha256sum</li> </ul>"},{"location":"lac/u7b/#downloads","title":"Downloads","text":""},{"location":"lac/u7intro/","title":"Package Management & Patching","text":""},{"location":"lac/u7intro/#under-construction","title":"Under Construction","text":""},{"location":"lac/u7lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u7lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Rocky Documentation</li> <li>Rocky DNF Guidance</li> <li>Rocky Repository Guidance</li> </ul>"},{"location":"lac/u7lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u7lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u7_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u7_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u7lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>A couple commands to get the noodle and fingers warmed up.</p> <p>For clarity:</p> <p>DNF is the 'frontend' aspect of the Rocky package management apparatus and RPM (RHEL package manager) is the 'backend'. The frontend abstracts away and automates the necessary commands required to install and manipulate packages.</p> <p>RPM allows for finer control compared to its related frontend and is intended for more advanced use cases. The Debian/Ubuntu equivalents are the apt frontend and dpkg backend.</p> <p>Investigate the man pages for additional information.</p> <pre><code>cd ~\nrpm -qa | more\nrpm -qa | wc -l\n# pick any &lt;name of package&gt; from the above list\n\nrpm -qi {name of package}\nrpm -qa | grep -i imagemagick\n\ndnf install imagemagick\n\n# What is the error here? Read it\ndnf install ImageMagick\n\n# What are some of the dependencies here? Look up the urw-base35\n# and see what functionality that adds.\nrpm -qa | grep -i imagemagick\n\n# Why did this work when the other one didn\u2019t with dnf?\n</code></pre>"},{"location":"lac/u7lab/#math-practice","title":"Math Practice:","text":"<p>Some fun with the command line and basic scripting tools. I want you to see some of the capabilities that are available to you. Your system can do a lot of basic arithmetic for you and this is a very small set of examples.</p> <pre><code># Check to see if you have bc tool.\nrpm -q bc\n\n#Install it if you need to\ndnf install bc\n\nfor i in 'seq 1 5'; do free | grep -i mem | awk '{print $3}'; done\n\n# Collect the 5 numbers (what do these numbers represent? Use free to find out)\necho \"(79 + 79 + 80 + 80 + 45) / 5\" | bc\n\n# Your numbers will vary. Is this effective? Is it precise enough?\necho \"(79 + 79 + 80 + 80 + 45) / 5\" | bc -l\n# Is this precise enough for you?\n\n# Read the man to see what the -l option does to bc\nman bc\n</code></pre> <p>It would be astute to point out that I did not have you do bash arithmetic. There is a major limitation of using bash for that purpose in that it only wants to deal with integers (whole numbers) and you will struggle to represent statistical data with precision. There are very useful tools though, and I would highly encourage you to examine them. http://tldp.org/LDP/abs/html/arithexp.html</p>"},{"location":"lac/u7lab/#lab","title":"Lab \ud83e\uddea","text":"<p>Log into your Rocky server and become root.</p>"},{"location":"lac/u7lab/#rpm","title":"RPM:","text":"<p>RPM is the Redhat package manager. It is a powerful tool to see what is installed on your system and to see what dependencies exist with different software packages. This is a tool set that was born of the frustration of \u201cdependency nightmare\u201d where system admins used to compile from source code only to find they had dependencies. RPM helps to de-conflict and save huge amounts of time and engineering headaches.</p> <p>Run through these commands and read <code>man rpm</code> to see what they do.</p> <pre><code># Read about the capabilities of systemd\nrpm -qi systemd\n\n# query the package given\nrpm -q systemd\n\n# query all packages on the system (is better used with | more or | grep)\nrpm -qa\n\n#for example shows all kernels and kernel tools\nrpm -qa | grep -i kernel\n\n# List out files, but only show the configuration files\nrpm -qc systemd\n\n# What good information do you see here? Why might it be good to know\n# that some piece of software was installed last night, if there is now\n# a problem with the system starting last night?\nrpm -qi systemd\n\n# Will list all the files in the package. Why might this be useful to you to know?\nrpm -ql systemd\n\n# List capabilities on which this package depends\nrpm -qR systemd\n\n# Probably going to scroll too fast to read. This output is in reverse order.\nrpm -q -changelog systemd\n\n# So let\u2019s make it useful with this command\nrpm -q -changelog systemd | more\n\n# What are some of the oldest entries?\n# What is the most recent entry?\n# Is there a newer version of systemd for you to use?\n\n# If there isn\u2019t don\u2019t worry about it.\ndnf update systemd\n</code></pre> <p>Use <code>rpm -qa | more</code> to find 3 other interesting packages and perform <code>rpm -qi &lt;package&gt;</code> on them to see information about them.</p>"},{"location":"lac/u7lab/#dnf","title":"DNF:","text":"<p>DNF is the front end package manager implemented into Rocky and derives its roots from Yum, a long decrepit version of Linux called Yellow dog. It is originally the Yellowdog Update Manager. It has a very interesting history surrounding the PS3, but that and other nostalgia can be found here: https://en.wikipedia.org/wiki/Yellow_Dog_Linux if you\u2019re interested.</p> <p>We\u2019re going to use DNF to update our system. RHEL and CentOS systems look to repositories of software for installation and updates. We have a base set of them provided with the system, supported by the vendor or open source communities, but we can also create our own from file systems or web pages. We\u2019ll be mostly dealing with the defaults and how to enable or disable them, but there are many configurations that can be made to customize software deployment.</p> <pre><code># Checking how dnf is configured and seeing it\u2019s available repositories\ncat /etc/dnf/dnf.conf\n\n# has some interesting information about what is or isn\u2019t going to be checked.\n# You can include a line here called exclude= to remove packages from installation\n# by name. Where a repo conflicts with this, this takes precedence.\ndnf repolist\ndnf history\n\n# Checking where repos are stored and what they look like\nls /etc/yum.repos.d/\n\n# Repos are still stored in /etc/yum.repos.d\ncat /etc/yum.repos.d/rocky.repo\n</code></pre> <p>The mirror list system uses the connecting IP address of the client and the update status of each mirror to pick current mirrors that are geographically close to the client. You should use this for Rocky updates unless you are manually picking other mirrors.</p> <p>If the mirrorlist does not work for you, you can try the commented out baseurl line instead.</p> <pre><code>[baseos]\nname=Rocky Linux $releasever - BaseOS\nmirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=BaseOS-$releasever$rltype\n#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/BaseOS/$basearch/os/\ngpgcheck=1\nenabled=1\ncountme=1\nmetadata_expire=6h\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9\n#Output truncated for brevity\u2019s sake\u2026.\n</code></pre> <p>Something you\u2019ll find out in the next section looking at repos is that when they are properly defined they are enabled by default. enabled=1 is implied and doesn\u2019t need to exist when you create a repo.</p> <pre><code># Let\u2019s disable a repo and see if the output changes at all\ndnf config-manager --disable baseos\n\n# Should now have the line enabled=0 (or false, turned off)\ncat /etc/yum.repos.d/rocky.repo\n\n[baseos]\nname=Rocky Linux $releasever - BaseOS\nmirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=BaseOS-$releasever$rltype\n# baseurl=http://dl.rockylinux.org/$contentdir/$releasever/BaseOS/$basearch/os/\ngpgcheck=1\nenabled=0\ncountme=1\nmetadata_expire=6h\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9\n# Output truncated for brevity\u2019s sake\u2026.\n\n# Re-enable the repo and verify the output\ndnf config-manager --enable base\n\n# Should now have the line enabled=1 (or true, turned back on)\ncat /etc/yum.repos.d/rocky.repo\n\n# Output:\n[baseos]\nname=Rocky Linux $releasever - BaseOS\nmirrorlist=https://mirrors.rockylinux.org/mirrorlist?arch=$basearch&amp;repo=BaseOS-$releasever$rltype\n#baseurl=http://dl.rockylinux.org/$contentdir/$releasever/BaseOS/$basearch/os/\ngpgcheck=1\nenabled=1\ncountme=1\nmetadata_expire=6h\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-Rocky-9\n# Output truncated for brevity\u2019s sake\u2026.\n</code></pre>"},{"location":"lac/u7lab/#installing-software-you-were-asked-by-an-application-team","title":"Installing software you were asked by an application team:","text":"<p>So someone has asked for some software and assured you it\u2019s been tested in similar environments, so you go to install it on their system for them.</p> <pre><code># See if we already have a version.\nrpm -qa mariadb\n\n# See if dnf knows about it\ndnf search mariadb\ndnf search all mariadb\n\n# What is DNF showing you? What are the differences between these commands based on the output?\n\n# Try to install it\ndnf install mariadb\n# hit \u201cN\u201d\n\n# Make note of any dependencies that are added on top of mariadb (there\u2019s at least one)\n# What does DNF do with the transaction when you cancel it? Can you compare this\n# to what you might have used before with YUM? How are they different?\n# (You can look it up if you don\u2019t know.)\n\n# Ok, install it\ndnf -y install mariadb\n\n# Will just assume yes to everything you say.\n# You can also set this option in /etc/dnf/dnf.conf to always assume yes,\n# it\u2019s just safer in an enterprise environment to be explicit.\n</code></pre>"},{"location":"lac/u7lab/#removing-packages-with-dnf","title":"Removing packages with dnf:","text":"<p>Surprise, the user calls back because that install has made the system unstable. They are asking for you to remove it and make the system back to the recent version.</p> <pre><code>dnf remove mariadb\n# hit \u201cN\u201d\n\n# this removes mariadb from your system\ndnf -y remove mariadb\n\n# But did this remove those dependencies from earlier?\nrpm -q {dependency}\nrpm -qi {dependency}\n\n# How are you going to remove that if it\u2019s still there?\n# Checking where something came from. What package provides something in your system\n\n# One of the most useful commands dnf provides is the ability to know \u201cwhat provides\u201d\n# something. Sar and iostat are powerful tools for monitoring your system.\n# Let\u2019s see how we get them or where they came from, if we already have them.\n# Maybe we need to see about a new version to work witha new tool.\ndnf whatprovides iostat\ndnf whatprovides sar\n\n# Try it on some other tools that you regularly use to see where they come from.\ndnf whatprovides systemd\ndnf whatprovides ls\ndnf whatprovides python\n\n# Using Dnf to update your system or individual packages\n# Check for how many packages need update\ndnf update\n\n# How many packages are going to update?\n# Is one of them the kernel?\n# What is the size in MB that is needed?\n# Hit \u201cN\u201d\n\n# Your system would have stored those in /var/cache/dnf\n# Let\u2019s check to see if we have enough space to hold those\ndf -h /var/cache/dnf\n\n# Is there more free space than there is needed size in MB from earlier?\n# There probably is, but this becomes an issue. You\u2019d be surprised.\n\n# Let\u2019s see how that changes if we exclude the kernel\ndnf update --exclude=kernel\n\n# How many packages are going to update?\n# Is one of them the kernel?\n# What is the size in MB that is needed?\n# Hit \u201cN\u201d\n</code></pre> <p>You can update your system if you like. You\u2019d have to reboot for your system to take the new kernel. If you do that you can then redo the grubby portion and the ls /boot/ will show the new installed kernel, unless you excluded it.</p>"},{"location":"lac/u7lab/#using-dnf-to-install-group-packages","title":"Using dnf to install group packages:","text":"<p>Maybe we don\u2019t even know what we need to get a project going. We know that we need to have a web server running but we don\u2019t have an expert around to tell us everything that may help to make that stable. We can scour the interwebs (our normal job) but we also have a tool that will give us the base install needed for RHEL or CentOS to run that server.</p> <pre><code>dnf grouplist\ndnf group install \u201cDevelopment Tools\u201d\n\n# How many packages are going to update?\n# Is one of them the kernel?\n# What is the size in MB that is needed?\n# Hit \u201cN\u201d\n# Do you see a pattern forming?\n</code></pre> <p>If you install this you\u2019re going to have developer tools installed on the server but they won\u2019t be configured. How would you figure out what tools and versions were just installed? How might you report this for your own documentation and to a security team that keeps your security baselines?</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u7ws/","title":"Worksheet","text":""},{"location":"lac/u7ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u7ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Semantic Versioning</li> <li>Rocky Documentation</li> <li>Rocky DNF Guidance</li> </ul>"},{"location":"lac/u7ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u7_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u7_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u7ws/#unit-7-recording","title":"Unit 7 Recording","text":""},{"location":"lac/u7ws/#discussion-post-1","title":"Discussion Post #1","text":"<ol> <li> <p>Why is software versioning so important to software security?</p> </li> <li> <p>Can you find 3 reasons, from the internet, AI, or your peers?</p> </li> </ol>"},{"location":"lac/u7ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   You are new to a Linux team. A ticket has come in from an application team and has already been escalated to your manager.  They want software installed on one of their servers but you cannot find any documentation. Your security team is out to lunch and not responding.  You remember from some early documentation that you read that all the software in the internal repos you currently have are approved for deployment on servers. You want to also verify by checking other servers that this software exists.  This is an urgent task and your manager is hovering.   <ol> <li> <p>How can you check all the repos on your system to see which are active?</p> </li> <li> <p>How would you check another server to see if the software was installed there?</p> </li> <li> <p>If you find the software, how might you figure out when it was installed? (Time/Date)</p> </li> </ol>"},{"location":"lac/u7ws/#discussion-post-3","title":"Discussion Post #3","text":"<p>Scenario:</p>   Looking at the concept of group install from DNF or Yum. Why do you think an administrator may never want to use that in a running system? Why might an engineer want to or not want to use that? This is a thought exercise, so it\u2019s not a \u201cright or wrong\u201d answer it\u2019s for you to think about.   <ol> <li> <p>What is the concept of software bloat, and how do you think it relates?</p> </li> <li> <p>What is the concept of a security baseline, and how do you think it relates?</p> </li> <li> <p>How do you think something like this affects performance baselines?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u7ws/#definitions","title":"Definitions","text":"<p>Yum:</p> <p>DNF:</p> <p>Repo:</p> <p>GPG Key:</p> <p>Software dependency:</p> <p>Software version:</p> <p>Semantic Version:</p>"},{"location":"lac/u7ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>What is semantic versioning? https://semver.org/</li> </ol>"},{"location":"lac/u7ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How does security as a system administrator differ from what you expected?</p> </li> </ol>"},{"location":"lac/u8b/","title":"Bonus","text":"<p>NOTE: This is an optional bonus section. You do not need to read it, but if you're interested in digging deeper, this is for you.</p>"},{"location":"lac/u8b/#bash-the-essential-skill-for-any-linux-administrator","title":"Bash: The Essential Skill for Any Linux Administrator","text":"<p>If you're planning to work with Linux, you\u2019ll use Bash every day -- whether troubleshooting servers, automating tasks, or managing system configurations.</p>"},{"location":"lac/u8b/#why-is-bash-important","title":"Why is bash important?","text":"<ul> <li>Bash is everywhere:</li> <li>Bash is the default shell on most Linux distributions (Ubuntu, RedHat, Arch, etc.)</li> <li>It automates common sysadmin tasks (backups, log analysis, deployments)</li> <li>Bash is essential for DevOps and administrative workflows (writing scripts, configuring CI/CD pipelines).</li> </ul>"},{"location":"lac/u8b/#why-learn-bash","title":"Why learn Bash?","text":"<ul> <li>You can automate repetitive or complex tasks.</li> <li>You can manage anything on your system using Bash (files, processes, services, etc.).</li> <li>Bash works across almost all major Linux distributions.</li> </ul> <p>Bash scripting turns manual commands into powerful, reusable automation.</p>"},{"location":"lac/u8b/#writing-your-first-script","title":"Writing Your First Script","text":"<p>Let's create a simple script that prints a message.</p> <ul> <li>Create a script file: <pre><code>$ touch first-script.sh\n</code></pre></li> <li>Make it executable: <pre><code>$ chmod +x first-script.sh\n</code></pre></li> <li>Open it in a text editor (e.g., <code>vi</code>): <pre><code>$ vi first-script.sh\n</code></pre></li> <li>Add the following code: <pre><code>#!/bin/bash\necho \"Hello, admin!\"\n</code></pre></li> <li>Run the script: <pre><code>$ ./first-script.sh\n</code></pre></li> <li>Expected output:</li> </ul> <pre><code>Hello, admin!\n</code></pre> <ul> <li>Key Takeaways:</li> <li>The <code>#!/bin/bash</code> shebang line tells the system which interpreter to use to     execute the script.</li> <li><code>chmod +x</code> makes the script executable.</li> <li><code>./</code> is required because the script is not in the system\u2019s <code>PATH</code>.</li> </ul>"},{"location":"lac/u8b/#10-common-control-operators","title":"10 Common Control Operators","text":"<p>These operators allow you to chain and control command execution in Bash.</p> Operator Purpose Example <code>;</code> Run multiple commands sequentially <code>mkdir test; cd test</code> <code>&amp;&amp;</code> Run second command only if first succeeds <code>mkdir test &amp;&amp; cd test</code> <code>\\|\\|</code> Run second command only if first fails <code>mkdir test \\|\\| echo \"Failed\"</code> <code>&amp;</code> Run a command in the background <code>sleep 60 &amp;</code> <code>\\|</code> Pipe output from one command to another <code>ls \\| grep \".txt\"</code> <code>()</code> Run commands in a subshell <code>(cd /tmp &amp;&amp; ls)</code> <code>{}</code> Run commands in the current shell <code>{ cd /tmp; ls; }</code> <code>&gt;</code> Redirect output to a file (overwrite) <code>echo \"log\" &gt; file.txt</code> <code>&gt;&gt;</code> Redirect output (append) <code>echo \"log\" &gt;&gt; file.txt</code> <code>$(...)</code> Capture command output <code>DATE=$(date)</code> <ul> <li>Why does this matter?</li> <li>These operators control execution flow and are fundamental to Bash scripting.</li> </ul>"},{"location":"lac/u8b/#10-common-conditionals","title":"10 Common Conditionals","text":"<p>Bash conditionals allow scripts to make decisions.</p> Test Meaning Example <code>[ -f FILE ]</code> File exists <code>[ -f /etc/passwd ]</code> <code>[ -d DIR ]</code> Directory exists <code>[ -d /home/user ]</code> <code>[ -n STR ]</code> String is non-empty <code>[ -n \"$USER\" ]</code> <code>[ -z STR ]</code> String is empty <code>[ -z \"$VAR\" ]</code> <code>[ \"$A\" = \"$B\" ]</code> Strings are equal <code>[ \"$USER\" = \"root\" ]</code> <code>[ \"$A\" != \"$B\" ]</code> Strings are not equal <code>[ \"$USER\" != \"admin\" ]</code> <code>[ NUM1 -eq NUM2 ]</code> Numbers are equal <code>[ 5 -eq 5 ]</code> <code>[ NUM1 -gt NUM2 ]</code> NUM1 is greater than NUM2 <code>[ 10 -gt 5 ]</code> <code>[ \"$?\" -eq 0 ]</code> Last command was successful <code>command &amp;&amp; echo \"Success\"</code> <code>[ -x FILE ]</code> File is executable <code>[ -x script.sh ]</code> <ul> <li>Why does this matter?</li> <li>These tests are used in if-statements and loops.</li> </ul>"},{"location":"lac/u8b/#10-bash-scripting-scenarios","title":"10 Bash Scripting Scenarios","text":"<p>Below are 10 real-world examples of using bash from the command line.</p> Scenario Solution Cont'd. Check if a file exists before deleting <code>if [ -f \"data.txt\" ]; then rm data.txt; fi</code> Backup a file before modifying <code>cp config.conf config.bak</code> Create a log entry every hour <code>echo \"$(date): Check OK\" &gt;&gt; log.txt</code> Monitor disk space <code>df -h</code> <code>awk '$5 &gt; 90 {print \"Low disk: \"$1}'</code> Check if a service is running <code>systemctl is-active nginx</code> <code>systemctl restart nginx</code> List large files in a directory <code>find /var/log -size +100M -exec ls -lh {} \\;</code> Change all <code>.txt</code> files to <code>.bak</code> <code>for file in *.txt; do mv \"$file\" \"${file%.txt}.bak\"; done</code> Check if a user is logged in <code>who</code> <code>grep \"admin\"</code> Kill a process by name <code>pkill -f \"python server.py\"</code> Find and replace text in files <code>sed -i 's/old/new/g' file.txt</code> <ul> <li>Why does this matter?</li> <li>These scenarios show how Bash automates real-world tasks.</li> </ul>"},{"location":"lac/u8b/#debugging-bash-scripts","title":"Debugging Bash Scripts","text":"<p>Debugging tools help troubleshoot Bash scripts.</p> Command Purpose <code>set -x</code> Print each command before execution <code>set -e</code> Exit script if any command fails <code>trap '...' ERR</code> Run a custom error handler when a command fails <code>echo \"$VAR\"</code> Print variable values for debugging <code>bash -x script.sh</code> Run script with debugging enabled <p>Using <code>set -x</code> and <code>echo</code> (or <code>printf</code>) are some of the most common methods of troubleshooting.</p>"},{"location":"lac/u8b/#example-debugging-script","title":"Example Debugging Script","text":"<pre><code>#!/bin/bash\nset -xe  # Enable debugging and exit on failure\nmkdir /tmp/mydir\ncd /tmp/mydir\nrm -rf /tmp/mydir\n</code></pre>"},{"location":"lac/u8b/#next-steps","title":"Next Steps","text":"<p>Now that you understand the fundamentals, here\u2019s what to do next:</p> <ul> <li>Practice writing scripts:</li> <li>Automate a daily task (e.g., installing a program, creating backups, user management)</li> <li>Master error handling:</li> <li>Learn signals and <code>trap</code>, and learn about logging techniques.</li> <li>Explore advanced topics:</li> <li>Look into writing functions, using arrays, and job control.</li> <li>Read <code>man bash</code>:</li> <li>The ultimate built-in reference.</li> <li>This resource has everything you need to know about Bash and then some!</li> <li>Join ProLUG community:</li> <li>Learn from others, contribute, and improve your Linux skillset.</li> </ul> <p>\ud83d\ude80 Happy scripting!</p>"},{"location":"lac/u8b/#downloads","title":"Downloads","text":""},{"location":"lac/u8intro/","title":"Scripting","text":""},{"location":"lac/u8intro/#overview","title":"Overview","text":"<p>This unit focuses on scripting and system checks in Linux environments, with particular emphasis on bash scripting for system administration tasks. It covers:</p> <ul> <li> <p>Bash Scripting Fundamentals: Mastery of shell scripting is essential for automating routine   administrative tasks, implementing monitoring solutions, and creating custom tools that enhance   system management capabilities.</p> </li> <li> <p>System Monitoring and Checks: Linux administrators must continuously monitor system health,   resource utilization, and potential security issues. This unit explores techniques for creating   scripts that perform automated system checks, gather performance metrics, and alert administrators   to potential problems.</p> </li> <li> <p>Logical Flow and Decision Making: The ability to implement complex decision-making logic in scripts   is crucial for handling various system conditions and scenarios. Students will learn to use conditional   statements, comparison operators, and truth tables to create intelligent scripts that can adapt to   different situations.</p> </li> <li> <p>Automation and Scheduled Tasks: Effective system administration requires automating repetitive tasks   and scheduling routine maintenance. This unit covers techniques for creating scripts that can be executed   automatically through cron jobs or systemd timers, reducing manual intervention.</p> </li> </ul>"},{"location":"lac/u8intro/#learning-objectives","title":"Learning Objectives","text":"<ol> <li> <p>Create and Execute Bash Scripts:</p> </li> <li> <p>Develop proficiency in writing and executing bash scripts for system administration tasks.</p> </li> <li> <p>Learn to use variables, conditional statements, and loops effectively in scripts.</p> </li> <li> <p>Apply Logical Structures and Decision Making:</p> </li> <li> <p>Master the use of if/then/else statements, case statements, and logical operators.</p> </li> <li>Understand truth tables and how they apply to script logic.</li> <li> <p>Learn to implement complex decision trees that handle multiple conditions.</p> </li> <li> <p>Develop Error Handling and Logging:</p> </li> <li> <p>Implement robust error detection and handling in scripts.</p> </li> <li>Create comprehensive logging systems that facilitate troubleshooting.</li> <li> <p>Design scripts that can recover from common error conditions.</p> </li> <li> <p>Analyze and Improve Script Maintainability:</p> </li> <li>Recognize patterns of poor script design and implement improvements.</li> <li>Organize code with functions and meaningful variable names.</li> <li>Document scripts effectively for future maintenance.</li> </ol>"},{"location":"lac/u8intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>The skills taught in this unit are essential for several critical reasons:</p> <ul> <li> <p>Efficiency and Automation:   In enterprise environments, manual administration of systems is time-consuming and error-prone.   Scripting allows administrators to automate routine tasks, significantly reducing the time required   and minimizing human error. This automation is particularly valuable for tasks that must be performed   consistently across multiple systems.</p> </li> <li> <p>Scalability and Consistency:   As infrastructure grows, manual administration becomes increasingly impractical. Scripts enable   administrators to implement consistent configurations and perform identical operations across dozens,   hundreds, or even thousands of systems simultaneously. This scalability is essential in modern data   centers and cloud environments.</p> </li> <li> <p>Knowledge Transfer and Documentation:   Scripts serve as executable documentation of system procedures and configurations. When an   administrator creates a script to perform a specific task, they are effectively documenting that   process in a format that can be shared, reviewed, and executed by others. This facilitates knowledge   transfer within teams and ensures operational continuity.</p> </li> </ul>"},{"location":"lac/u8intro/#prerequisites","title":"Prerequisites","text":"<p>Before diving into the scripting and system checks covered in this unit, learners should possess the following foundational knowledge and skills:</p> <ul> <li> <p>Command-Line Proficiency:   A solid understanding of the Linux command line interface is essential. Students should be   comfortable navigating the file system, executing commands, and interpreting command output.   This includes familiarity with common utilities such as grep, awk, sed, and find.</p> </li> <li> <p>Basic Text Editing Skills:   Since scripts are text files, the ability to create and modify text files using editors like   vi, vim, nano, or emacs is necessary. Students should be able to open files, make changes, save   modifications, and exit editors efficiently.</p> </li> <li> <p>Fundamental Linux System Architecture:   An understanding of the Linux file hierarchy, process management, and service control is required.   Students should know where configuration files are typically located, how to check system status, and   how to start and stop services.</p> </li> <li> <p>Basic Programming Concepts:   While this unit will teach scripting from the ground up, familiarity with basic programming concepts   such as variables, conditions, loops, and functions will accelerate learning. Students who have experience   with any programming language will find these concepts transferable to bash scripting.</p> </li> </ul>"},{"location":"lac/u8intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Bash (Bourne Again Shell)</p> <p>Script</p> <p>Variables</p> <p>Conditional Statements</p> <p>Loops</p> <p>Exit Status</p> <p>Command Substitution</p> <p>Interpreted Program</p> <p>Compiled Program</p> <p>Truth Table</p> <p>And/Or Logic</p> <p>Single/Dual/Multiple Alternative Logic</p> <p>Cron</p> <p>System Check</p> <p>Monitoring</p> <p>Function</p> <p>Parameter Expansion</p>"},{"location":"lac/u8lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u8lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>Wikipedia Page for Compilers</li> <li>Wikipedia Page for the C Programming Lang</li> <li>Wikipedia Page for Truth Table</li> <li>CProgramming.com Introductory</li> <li>Unit #1 Bonus (VIM) Page</li> <li>Unit #8 Bonus (Bash Scripting) Page</li> </ul>"},{"location":"lac/u8lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u8lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u8_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u8_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u8lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<pre><code>vi /etc/passwd\n# Put a # in front of all your local users you created in a lab a few weeks back\n</code></pre> <p>Review how to use vi, if you have a problem getting out or saving your file or use Unit #1 Bonus (Vim) Page to brush up on your Vim Skills.</p> <pre><code># Let us locate and inspect the GNU C Compiler Package\nrpm -qa | grep -i gcc\ndnf whatprovides gcc\ndnf search gcc\nCheck out all the options of different compilers\n\n# Now lets install it\ndnf install gcc\n# Look at what is going to be installed.\n\nrpm -qi gcc\n# Look at this package to see a little about what gcc does\n# Repeat steps 2-6 for the software package strace\n</code></pre>"},{"location":"lac/u8lab/#compilers","title":"Compilers","text":"<p>A brief look at compilers and compiling code So we did all this just to show you a quick rundown of how compiled code works on your system. We are going to be doing scripting today, which is not compiled, but rather interpreted code according to a type of interpreter so we\u2019ll just breeze through this part. You can come back and play with this at your leisure, I will provide links for more study.</p> <pre><code>Let\u2019s write a C program\nmkdir c_practice\ncd c_practice\n\n#Start a new file with Vi, in this case I am going with 'a'\nvi a.c\n\n#Add this to the file:\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n\nmain()\n{\n\nprintf(\"My first compiled program \\n\");\n\nreturn 0;\n}\n</code></pre> <pre><code>#Let\u2019s use gcc to compile that program\ngcc a.c\n#This will create a file for you called a.out\n#If there is an error, does it still work?\n\n#Alternatively, and more correctly, use this:\ngcc -o firstprogram a.c\n#Which will create an executable file called first program\nls -salh\n#Will show you all your files. Note how big those compiled programs are.\n#Execute your programs\n./a.out\n./firstprogram\n\n#Both of these should do the exact same thing, as they are the same code.\n#Watch what your system is doing when you call it via strace\nstrace ./a.out\nstrace ./firstprogram\n</code></pre>"},{"location":"lac/u8lab/#lab","title":"Lab \ud83e\uddea","text":"<p>Log into your Rocky server and become root.</p>"},{"location":"lac/u8lab/#module-21-scripting","title":"Module 2.1: Scripting","text":"<p>After all that pre-lab discussion, we won\u2019t be using <code>gcc</code> today\u2014or compiling any programs, for that matter. Instead, we\u2019ll focus on scripting, where we write code that the system interprets and executes step by step. Think of it like reading lines from a play, following sheet music, or executing a script\u2014each command is processed in order.</p> <p>There are plenty of resources available to learn scripting, but the key to improving is daily practice. If you\u2019re serious about getting better, I recommend studying additional concepts over time. However, to get started, you only need to understand three fundamental ideas:</p> <ol> <li>Input and Output - How to receive input and where to send the output.</li> <li>Conditionals - How to test and evaluate conditions.</li> <li>Loops - How to repeat actions efficiently.</li> </ol>"},{"location":"lac/u8lab/#22-getting-input","title":"2.2 Getting Input","text":"<p>Let\u2019s use examples from our Operate Running Systems lab to see what it looks like to gather system information and store it in variables. Variables in scripting can be thought of as named boxes where we put things we want to look at or compare later. We can, by and large, stuff anything we want into these boxes.</p> <pre><code># Try this:\n\necho $name  # No output\nuname\nname=`uname`\necho $name\n\necho $kernel  # No output\nuname -r\nkernel=`uname -r`\necho $kernel\n\necho $PATH  # This will have output because it is an environment variable\n</code></pre> <p>There will be output because this is one of those special variables that make up your environment variables. You can see them with:</p> <pre><code>printenv | more\n</code></pre> <p>These should not be changed, but if necessary, they can be. If you overwrite any, you can reset them by re-logging into your shell.</p> <p>We can package things in variables and then reference them by their name preceded by a <code>$</code>.</p> <pre><code># Try this to get numerical values from your system for later use in conditional tests.\ncat /proc/cpuinfo  # Not very good as a count\ncat /proc/cpuinfo | grep -i proc  # Shows processor count but not ideal for testing\ncat /proc/cpuinfo | grep -i proc | wc -l  # Outputs a usable number\nnumProc=`cat /proc/cpuinfo | grep -i proc | wc -l`\necho $numProc\n\nfree -m  # Displays memory info\nfree -m | grep -i mem  # Filters output\nfree -m | grep -i mem | awk '{print $2}'  # Extracts total memory value\nmemSize=`free -m | grep -i mem | awk '{print $2}'`\necho $memSize\n</code></pre>"},{"location":"lac/u8lab/#23-checking-exit-codes","title":"2.3 Checking Exit Codes","text":"<p>One of the most important inputs in scripting is checking the exit code (<code>$?</code>) of a command. This allows us to determine whether a command succeeded or failed.</p> <pre><code>ps -ef | grep -i httpd | grep -v grep\necho $?\n# Output: 1 (Nothing found, not good \"0\")\n\nps -ef | grep -i httpd\nroot      5514 17748  0 08:46 pts/0    00:00:00 grep --color=auto -i httpd\necho $?\n# Output: 0 (Process found, exit code is 0)\n</code></pre> <p>Checking for installed packages:</p> <pre><code>rpm -qa | grep -i superprogram\necho $?\n# Output: 1 (Program not found)\n\nrpm -qa | grep -i gcc\nlibgcc-4.8.5-11.el7.x86_64\ngcc-4.8.5-11.el7.x86_64\necho $?\n# Output: 0 (GCC is found)\n</code></pre> <p><code>$?</code> only holds the exit status of the last executed command, so store it immediately:</p> <pre><code>rpm -qa | grep -i superprogram\nsuperCheck=$?\n\nrpm -qa | grep -i gcc\ngccCheck=$?\n\necho $superCheck\necho $gccCheck\n</code></pre>"},{"location":"lac/u8lab/#24-testing-and-evaluating-conditions","title":"2.4 Testing and Evaluating Conditions","text":""},{"location":"lac/u8lab/#241-basics-of-logic-and-truth-tests","title":"2.4.1 Basics of Logic and Truth Tests","text":"<p>I commonly say that \u201cAll engineering is the test for truth.\u201d This is not meant as a philosophical statement but a practical one. We take input, verify it, and compare it to our expectations. If it matches, the result is <code>true</code>; otherwise, it is <code>false</code>.</p> <p>Testing for what something <code>is</code> is much easier than testing for what something <code>is not</code>, as logically, there are infinite possibilities for what something could <code>not</code> be.</p> <p>Continue exploring these concepts by practicing input handling, storing values in variables, and testing conditions to build efficient scripts.</p>"},{"location":"lac/u8lab/#25-exercise","title":"2.5 Exercise","text":"<p>The <code>Red bunny</code> is tall. We look at our examples and see that this is not true, so the statement evaluates to <code>false</code>. The <code>Blue bunny</code> is short. We look at our examples and see that this is not true, so the statement evaluates to <code>false</code>.</p>"},{"location":"lac/u8lab/#the-idea-of-and-and-or","title":"The Idea of <code>AND</code> and <code>OR</code>","text":"<ul> <li><code>AND</code> is a restricting test.</li> <li><code>OR</code> is an inclusive test.</li> </ul> <p>I will prove that here shortly.</p> <ul> <li><code>ANDing</code> checks both sides for truth and evaluates to true only if <code>both</code> sides are true.</li> <li><code>ORing</code> allows either side to be true, and the statement still evaluates to true. This makes OR a more inclusive test.</li> </ul>"},{"location":"lac/u8lab/#and-examples","title":"<code>AND</code> Examples","text":"<ul> <li> <p>The <code>right bunny</code> is <code>Red</code> and <code>Tall</code>.</p> </li> <li> <p>This evaluates to <code>true</code> for the Red test but <code>false</code> for the Tall test.</p> </li> <li> <p>The statement evaluates to <code>false</code>.</p> </li> <li> <p>The <code>left bunny</code> is <code>Blue</code> and <code>Tall</code>.</p> </li> <li>This evaluates to <code>true</code> for the Blue test and <code>true</code> for the Tall test.</li> <li>The statement evaluates to <code>true</code>.</li> </ul>"},{"location":"lac/u8lab/#or-examples","title":"<code>OR</code> Examples","text":"<ul> <li> <p>The <code>right bunny</code> is <code>Red</code> or <code>Tall</code>.</p> </li> <li> <p>This evaluates to <code>true</code> for the Red test but <code>false</code> for the Tall test.</p> </li> <li> <p>The statement evaluates to <code>true</code>.</p> </li> <li> <p>The <code>left bunny</code> is <code>Red</code> or <code>Short</code>.</p> </li> <li>This evaluates to <code>false</code> for Red and <code>false</code> for Short.</li> <li>The statement evaluates to <code>false</code>.</li> </ul>"},{"location":"lac/u8lab/#26-truth-tables","title":"2.6 - Truth Tables","text":"<p>Google Truth Tables to see engineering diagrams commonly used for testing truth in complex statements. We will not draw them out in this lab, as there are already well-documented examples. This is a well-known, solved, and understood concept in the engineering world. Instead of reinventing those diagrams, refer to the following link for more details:</p> <p>Truth Table - Wikipedia</p>"},{"location":"lac/u8lab/#27-flow-in-a-program","title":"2.7 - Flow in a program","text":"<ul> <li>All programs start at the top and run to the bottom. Data never flow back towards the start, unless on a separate path from a decision which always returns to the original path.</li> </ul> <p>When we start thinking about how to lay something out and logically work through it, the idea of a formalized flow chart can help us get a handle on what we're seeing.</p> <p>ome common symbols you'll see as we go through drawing out our logic. This example creates a loop in the program until some decision evaluates to yes (true).</p>"},{"location":"lac/u8lab/#28-3-types-of-decisions","title":"2.8 - 3 Types of Decisions","text":"<p>There are 3 primary types of decisions you\u2019ll run into with scripting, they are:</p> <ol> <li><code>Single</code> alternative</li> <li><code>Dual</code> alternative</li> <li><code>Multiple</code> alternative</li> </ol>"},{"location":"lac/u8lab/#281-single-alternative-ifthen","title":"2.8.1 - Single Alternative <code>if/then</code>","text":"<p>Single alternatives either occur or they do not. They only branch from the primary path if the condition occurs. They either can or cannot occur, depending on the condition, but compared to alternative paths where a decision must occur if these do not evaluate to true, they are simply passed over.</p> <p>Evaluate these from earlier and look at the difference.</p> <p><code>if [ $superCheck -eq \"0\" ]; then echo \"super exists\"; fi</code></p> <p><code>if [ $gccCheck -eq \"0\" ]; then echo \"gcc exists\"; fi</code></p> <p>You\u2019ll note that only one of them caused any output to come to the screen, the other simply ran and the condition never had to execute.</p>"},{"location":"lac/u8lab/#282-dual-alternative-ifthenelse","title":"2.8.2 - Dual alternative (if/then/else)","text":"<p>Dual alternatives forces the code to split. A decision must be made. These are logically <code>if, then, else</code>. We test for a truth, and then, if that condition does not exist we execute the alternative. If you\u2019re a parent or if you ever had a parent, this is the dreaded <code>or else</code>. One of two things is going to happen here, the path splits.</p> <p><code>if [ $superCheck -eq \"0\" ]; then echo \"super exists\"; else echo \"super does not exist\"; fi</code> super does not exist</p> <p><code>if [ $gccCheck -eq \"0\" ]; then echo \"gcc exists\"; else echo \"gcc does not exist\"; fi</code> gcc exists</p>"},{"location":"lac/u8lab/#283-multiple-alternative-ifthenelifelse-or-case","title":"2.8.3 - Multiple Alternative (if/then/elif/\u2026/else or Case)","text":"<p>Multiple alternatives provide a branch for any numbers of ways that a program can go. They can be structured as if, then, <code>else if</code> <code>elif</code> in bash, <code>else</code>. They can also be framed in the case statement, which can select any number of cases (like doors) that can be selected from. There should always be a default <code>else</code> value for case statements, that is to say, if one of the many conditions don\u2019t exist there is something that happens anyways (*) in case statements.</p> <p>superCheck=4 <code>if [ $superCheck -eq \"0\" ]; then echo \"super exists\"; elif [ $superCheck -gt \"1\" ]; then echo \"something is really wrong\"; else echo \"super does not exist\"; fi</code></p> <p>gccCheck=5 <code>if [ $gccCheck -eq \"0\" ]; then echo \"gcc exists\"; elif [ $gccCheck -gt \"1\" ]; then echo \"something is really wrong\"; else echo \"gcc does not exist\"; fi</code></p> <p>Set those variables to the conditions of 0, 1, and <code>anything else</code> to see what happens.</p> <p>Think about why greater than 1 does not hit the condition of 1. Might it be easier to think of as greater than or equal to 2? Here\u2019s a list of things you can test against. http://tldp.org/LDP/abs/html/tests.html</p> <p>Also a huge concept we don\u2019t have a lot of time to cover is found here: File test operators http://tldp.org/LDP/abs/html/fto.html, do files exist and can you do operating system level things with them?</p> <p>We didn\u2019t get to go into case, but they are pretty straight forward with the following examples: http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_03.html</p> <p>We didn\u2019t get to explore these much earlier, but to test <code>AND</code> and <code>OR</code> functionality use this.</p> <p><code>AND</code> condition <code>if [ $gccCheck -eq \"0\" -a $superCheck -eq \"1\" ]; then echo \"We can install someprogram\"; else echo \"We can't install someprogram\"; fi</code> We can't install someprogram</p> <p>OR condition <code>if [ $gccCheck -eq \"0\" -o $superCheck -eq \"1\" ]; then echo \"We can install someprogram\"; else echo \"We can't install someprogram\"; fi</code> We can't install someprogram</p>"},{"location":"lac/u8lab/#284-looping-around","title":"2.8.4 - Looping around","text":"<p>As with everything today, this is simply a primer and there are hundreds to thousands of examples online a simple google away. There are only two types of loops; counting loops and conditional loops. At the most basic level, we use counting loops when we (or the system) know how many times we want to go through something. Some examples of this are actual hard counts, lists, or lengths of files typically by line. While loops will continue until a condition exists or stops existing. The difference is until that condition occurs there\u2019s no reasonable way of knowing how many times the loop may have to occur.</p> <p><code>For</code> loops</p> <p>Counting is iteration.</p> <p>We can count numbers <code>for i in 1 2 3 4 5; do echo \"the value now is $i\"; done</code></p> <p>We can count items <code>for dessert in pie cake icecream sugar soda; do echo \"this is my favorite $dessert\"; done</code></p> <p>But, it\u2019s impractical to count for ourselves sometimes so we let the system do it for us.</p> <p><code>seq 100</code> \\ <code>seq 4 100</code> \\ <code>seq 6 2 100</code> \\ <code>man seq</code></p> <p>What did each of those do? Let\u2019s put them in a loop we can use</p> <p>Maybe we want to count our 1000 servers and connect to them by name. for i in <code>seq 1000</code>; do echo \"Connecting to server p01awl$i\"; done</p> <p>Maybe we need to create a list of all our servers and put it in a list for i in <code>seq 1000</code>; do echo \"p01awl$i\" &gt;&gt; serverfile; done</p> <p>Maybe someone else gave us a list of servers and we need to read from that list to connect and do work. for server in <code>cat serverfile</code>; do echo \"connecting to server $server\"; done</p> <p>So, while those are even just a limited set of cases those are all times when, at the start, we know how many times we\u2019re going to go through the loop. Counting or For loops always have a set number of times they\u2019re going to run. That can change, but when it starts the end number of runs is known.</p> <p><code>While</code> loops</p> <p>While loops are going to test conditions and loop while that condition evaluates to true. We can invert that, as we can with all logic, but I find that testing for truth is always easiest.</p> <p>It is important to remember that <code>CRTL + C</code> will break you out of loops, as that will come handy here.</p> <p>Administrators often find themselves looking at data and needing to refresh that data. One of the simplest loops is an infinite loop that always tests the condition of true (which always evaluates to true) and then goes around again. This is especially useful when watching systems for capacity issues during daemon or program startups.</p> <p><code>while true; do date; free -m; uptime; sleep 2; done</code></p> <p>This will run until you break it with <code>CTRL + C</code>. This will loop over the date, <code>free -m</code>, <code>uptime</code>, and <code>sleep 2</code> commands until the condition evaluates to false, which it will never do.</p> <p>Let\u2019s run something where we actually have a counter and see what that output is</p> <p><code>counter=0</code> <code>while [[ $counter -lt 100 ]]; do echo \"counter is at $counter\"; (( counter++ )); done</code> What numbers were counted through?</p> <p>If you immediately run this again, what happens? Why didn\u2019t anything happen?</p> <p>Reset counter to 0 <code>counter=0</code></p> <p>Re-run the above loop. Why did it work this time?</p> <p>Reset the counter and run it again. Try moving the counter to before the output. Can you make it count from 1 to 100? Can you make it count from 3 to 251? Are there challenges to getting that to work properly?</p> <p>What if we wanted something to happen for every MB of free RAM on our system? Could we do that?</p> <p>memFree=<code>free -m | grep -i mem | awk '{print $2}'</code> counter=0 <code>while [[ $counter -lt $memFree ]]; do echo \"counter is at $counter\"; (( counter++ )); done</code></p>"},{"location":"lac/u8lab/#30-scripting-system-checks","title":"3.0 - Scripting System Checks","text":"<p>The main thing we haven\u2019t covered is what to actually do with these things we\u2019ve done. We can put them into a file and then execute them sequentially until the file is done executing. To do that we need to know the interpreter (bash is default) and then what we want to do.</p> <p><code>touch scriptfile.sh</code> <code>chmod 755 scriptfile.sh</code> #let\u2019s just make it executable now and save trouble later <code>vi scriptfile.sh</code></p> <p>add the following lines:</p> <pre><code>#!/bin/bash\n\necho \"checking system requirements\"\n\nrpm -qa | grep -i gcc &gt; /dev/null\ngccCheck=$?\n\nrpm -qa | grep -i superprogram &gt; /dev/null\nsuperCheck=$?\n\nif [ $gccCheck -eq \"0\" -a $superCheck -eq \"1\" ]\n  then echo \"We can install someprogram\"\nelse\n  echo \"We can't install someprogram\"\nfi\n</code></pre> <p>Execute this with the command\\ <code>./scriptfile.sh</code></p> <p>and you\u2019ll have your first completed script.</p> <p>run the command\\ <code>strace ./scriptfile.sh</code></p> <p>to see what is happening with your system when it interprets this script.</p> <p>There are a lot of ways to use these tools. There are a lot of things you can do and include with scripts. This is just meant to teach you the basics and give you some confidence that you can go out there and figure out the rest. You can develop things that solve your own problems or automate your own tasks.</p>"},{"location":"lac/u8ws/","title":"Worksheet","text":""},{"location":"lac/u8ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u8ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>TLDP Bash Beginner's Guide</li> <li>devhints.io - Bash Scripting Cheatsheet</li> <li>Bash Hacker's Wiki</li> </ul>"},{"location":"lac/u8ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u8_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u8_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u8ws/#unit-8-recording","title":"Unit 8 Recording","text":""},{"location":"lac/u8ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Scenario:</p>   It\u2019s a 2 week holiday in your country and most of the engineers and architects who designed the system are out of town.  You\u2019ve noticed a pattern of logs filling up on a set of web servers from increased traffic. Your research shows, and then you verify, that the logs are being sent off real time to Splunk. Your team has just been deleting the logs every few days, but one of the 3rd shift engineers didn\u2019t read the notes and your team suffered downtime.  How might you implement a simple fix to stop gap the problem before all the engineering resources come back next week?   <ol> <li> <p>What resources helped you answer this?</p> </li> <li> <p>Why can\u2019t you just make a design fix and add space in /var/log on all these systems?</p> </li> <li> <p>Why can\u2019t you just make a design change and logrotate more often so this doesn\u2019t happen?</p> </li> <li> <p>For 2,3 if you are ok with that, explain your answer. (This isn\u2019t a trick, maybe there is a valid reason.)</p> </li> </ol>"},{"location":"lac/u8ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   You are the only Linux Administrator at a small healthcare company. The engineer/admin before you left you a lot of scripts to untangle. This is one of our many tasks as administrators, so you set out to accomplish it. You start to notice that he only ever uses nested `if` statements in bash.  You also notice that every loop is a conditional `while true`, and then he breaks the loop after a decision test each loop. You know his stuff works, but you think it could be more easily written for supportability, for you and future admins. You decide to write up some notes by reading some google, AI, and talking to your peers.   <ol> <li> <p>Compare the use of nested if versus case statement in bash.</p> </li> <li> <p>Compare the use of conditional and counting loops. Under what circumstances would you use one or the other?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u8ws/#definitions","title":"Definitions","text":"<p>Variables:</p> <p>Interpreted program:</p> <p>Compiled program:</p> <p>Truth table:</p> <p>AND/OR logic:</p> <p>Single/Dual/Multiple alternative logic:</p>"},{"location":"lac/u8ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Read:</p> </li> <li> <p>https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html</p> </li> <li>https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_02.html</li> <li>https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_03.html</li> </ol> <p>What did you learn about capabilities of bash that can help you in your scripting?</p> <ol> <li>If you want to dig more into truth tables and logic, this is a good start: https://en.wikipedia.org/wiki/Truth_table</li> </ol>"},{"location":"lac/u8ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>Just knowing a lot about scripting doesn\u2019t help much against actually doing it in    a practical sense.    What things are you doing currently at work or in a lab that you can apply some of    this logic to?</p> </li> </ol>"},{"location":"lac/u9intro/","title":"Containerization on Linux","text":""},{"location":"lac/u9intro/#overview","title":"Overview","text":"<p>In this unit, we dive into the modern world of containerization, focusing on Podman\u2014an open-source, daemon-less container engine. As Linux administrators, understanding containerization is crucial for supporting developers, managing production systems, and deploying services efficiently.</p> <p>We\u2019ll explore what containers are, how to manage them, and how to build container images.</p>"},{"location":"lac/u9intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>Containerization is a critical part of modern IT, powering development pipelines (CI/CD), cloud deployments, and microservices. As Linux system administrators, we are expected to support and troubleshoot containers, manage container infrastructure, and ensure smooth operations across development and production environments.</p> <p>This unit focuses on Podman, a secure, rootless, and daemon-less alternative to Docker, widely used in enterprise environments like Red Hat and Rocky Linux. Whether you work in a NOC, DevOps, or traditional SysAdmin role, understanding containerization is essential to being an effective part of any IT team.</p>"},{"location":"lac/u9intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this unit, you will be able to:</p> <ul> <li>Explain what containers are and how they fit into modern Linux system administration</li> <li>Run and manage Podman containers, including starting, stopping, and inspecting containers</li> <li>Build custom container images using Dockerfiles and Podman</li> <li>Analyze container processes, logs, and network interactions for troubleshooting</li> </ul>"},{"location":"lac/u9intro/#prerequisites","title":"Prerequisites","text":"<p>Before starting Unit 9, you should have:</p> <ul> <li>Basic understanding of Linux command line and shell operations</li> <li>Familiarity with package management and system services on RHEL-based systems (Rocky/Red Hat)</li> <li>Root or sudo access to a Linux system (Rocky 9 or equivalent)</li> <li>Completed previous units on system administration fundamentals (file permissions, processes, networking)</li> <li>Optional but recommended: Initial exposure to virtualization or application deployment concepts</li> </ul>"},{"location":"lac/u9intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>Containers</p> <p>Virtual Machines</p> <p>Podman</p> <p>Images</p> <p>Dockerfiles</p> <p>Virtualization</p> <p>Daemon-less</p>"},{"location":"lac/u9lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"lac/u9lab/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Killercoda Labs</li> <li>https://podman.io/docs</li> <li>https://docs.docker.com/build/concepts/dockerfile/</li> <li>https://docs.podman.io/en/latest/markdown/podman-exec.1.html</li> </ul>"},{"location":"lac/u9lab/#required-materials","title":"Required Materials","text":"<ul> <li>Rocky 9.4+ - ProLUG Lab</li> <li>Or comparable Linux box</li> <li>root or sudo command access</li> </ul>"},{"location":"lac/u9lab/#downloads","title":"Downloads","text":"<p>The lab has been provided for convenience below:</p> <ul> <li>\ud83d\udce5 u9_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u9_lab(<code>.docx</code>)</li> </ul>"},{"location":"lac/u9lab/#pre-lab-warmup","title":"Pre-Lab Warmup","text":"<ol> <li> <p><code>which podman</code></p> </li> <li> <p><code>dnf whatprovides podman</code></p> </li> <li> <p><code>rpm -qi podman</code>    When was this installed?    What version is it?    Why might this be important to know?</p> </li> <li> <p><code>podman images</code></p> </li> <li> <p><code>podman ps</code>    What do you learn from those two commands?    Why might it be important to know on a system?</p> </li> </ol>"},{"location":"lac/u9lab/#lab","title":"Lab \ud83e\uddea","text":""},{"location":"lac/u9lab/#building-and-running-containers","title":"Building and running containers","text":"<p>Your tasks in this lab are designed to get you thinking about how container deployments interact with our Linux systems that we support.</p> <ol> <li>Pull and run a container</li> </ol> <pre><code>podman run -dt -p 8080:80/tcp docker.io/library/httpd\n</code></pre> <p>What do you see on your screen as this happens?</p> <ol> <li>Check your images again (from your earlier exercises)</li> </ol> <pre><code>podman images\n</code></pre> <p>Is there a new image, and if so, what do you notice about it?</p> <ol> <li>Check your podman running containers</li> </ol> <pre><code>podman ps\n</code></pre> <p>What appears to be happening? Can you validate this with your Linux knowledge?</p> <pre><code>ss -ntulp\ncurl 127.0.0.1:8080\n</code></pre> <ol> <li>Inspect the running pod</li> </ol> <pre><code>podman inspect -l\n</code></pre> <p>What format is the output in? What important information might you want from this in the future?</p> <pre><code>podman logs -l\n</code></pre> <p>What info do you see in the logs? Do you see your connection attempt from earlier? What is the return code and why is that important for troubleshooting?</p> <pre><code>podman top -l\n</code></pre> <p>What processes is the pod running? What other useful information might you find here? Why might it be good to know the user being run within the pod?</p> <ol> <li>Stop the pod by its name</li> </ol> <pre><code>podman stop &lt;podname&gt;\n</code></pre> <p>Can you verify it is stopped from your previous commands?</p> <pre><code>podman ps\nss -ntulp\ncurl 127.0.0.1:8080\n</code></pre> <p>Does the container still exist? Why might you want to know this?</p> <pre><code>podman image\n</code></pre>"},{"location":"lac/u9lab/#build-an-application-in-a-container","title":"Build an application in a container","text":"<p>The ProLUG lab will already have a version of this setup for you to copy and run. If you are in a different environment, follow https://docs.docker.com/build/concepts/dockerfile/ for the general same steps.</p> <ol> <li>Setup your lab environment</li> </ol> <pre><code>[root@rocky11 stream]# cd /lab_work/\n[root@rocky11 lab_work]# ls\n[root@rocky11 lab_work]# mkdir scott_lab9\n[root@rocky11 lab_work]# cd scott_lab9/\n[root@rocky11 scott_lab9]# ls\n[root@rocky11 scott_lab9]# cp /labs/lab9.tar.gz .\n[root@rocky11 scott_lab9]# tar -xzvf lab9.tar.gz\nlab9/\nlab9/Dockerfile\nlab9/hello.py\n[root@rocky11 scott_lab9]# ls\nlab9 lab9.tar.gz\n[root@rocky11 scott_lab9]# cd lab9\n[root@rocky11 lab9]# pwd\n/lab_work/scott_lab9/lab9\n[root@rocky11 lab9]# ls\nDockerfile hello.py\n</code></pre> <ol> <li>Create a docker image from the docker file:</li> </ol> <pre><code>time podman build -t scott_hello .\n#Use your name\n</code></pre> <p>What output to your screen do you see as you build this? Approximately how long did it take?</p> <p>If this breaks in the lab, how might you fix it? What do you suspect?</p> <ol> <li>Verify that you have built the container</li> </ol> <pre><code>podman images\n</code></pre> <ol> <li>Run the container as a daemon</li> </ol> <pre><code>podman run -dt localhost/scott_example\n</code></pre> <ol> <li>Verify the name and that it is running</li> </ol> <pre><code>podman ps\n</code></pre> <ol> <li>Exec into the pod and see that you are on the Ubuntu container</li> </ol> <pre><code>podman exec -it festive_pascal sh\ncat /etc/*release\nexit\n</code></pre>"},{"location":"lac/u9lab/#conclusion","title":"Conclusion","text":"<p>There are a lot of ways to use these tools. There are a lot of ways you will support them. At the end of the day you're a Linux System Administrator, you're expected to understand everything that goes on in your system. To this end, we want to know the build process and run processes so we can help the engineers we support keep working in a Linux environment.</p> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"lac/u9ws/","title":"Worksheet","text":""},{"location":"lac/u9ws/#instructions","title":"Instructions","text":"<p>Fill out the worksheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"lac/u9ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>Dockerfile Reference Page</li> <li>Podman Command List</li> </ul>"},{"location":"lac/u9ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u9_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u9_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"lac/u9ws/#unit-9-recording","title":"Unit 9 Recording","text":""},{"location":"lac/u9ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>It\u2019s a slow day in the NOC and you have heard that a new system of container deployments are being used by your developers. Do some reading about containers, docker, and podman.</p> <ol> <li> <p>What resources helped you answer this?</p> </li> <li> <p>What did you learn about that you didn\u2019t know before?</p> </li> <li> <p>What seems to be the major benefit of containers?</p> </li> <li> <p>What seems to be some obstacles to container deployment?</p> </li> </ol>"},{"location":"lac/u9ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Scenario:</p>   You get your first ticket about a problem with containers. One of the engineers is trying to move his container up to the Dev environment shared server. He sends you over this information about the command he\u2019s trying to run.  <pre><code>[developer1@devserver read]$ podman ps\nCONTAINER ID  IMAGE       COMMAND     CREATED     STATUS      PORTS       NAMES\n[developer1@devserver read]$ podman images\nREPOSITORY                TAG                IMAGE ID      CREATED      SIZE\nlocalhost/read_docker     latest             2c0728a1f483  5 days ago   68.2 MB\ndocker.io/library/python  3.13.0-alpine3.19  9edd75ff93ac  3 weeks ago  47.5 MB\n[developer1@devserver read]$ podman run -dt -p 8080:80/tcp docker.io/library/httpd\n</code></pre>  You decide to check out the server  <pre><code>[developer1@devserver read] ss -ntulp\nNetid   State    Recv-Q   Send-Q      Local Address:Port        Peer Address:Port         Process\nudp     UNCONN   0        0           127.0.0.53%lo:53               0.0.0.0:*             users:((\"systemd-resolve\",pid=166693,fd=13))\ntcp     LISTEN   0        80              127.0.0.1:3306             0.0.0.0:*             users:((\"mariadbd\",pid=234918,fd=20))\ntcp     LISTEN   0        128               0.0.0.0:22               0.0.0.0:*             users:((\"sshd\",pid=166657,fd=3))\ntcp     LISTEN   0        4096        127.0.0.53%lo:53               0.0.0.0:*             users:((\"systemd-resolve\",pid=166693,fd=14))\ntcp     LISTEN   0        4096                    *:8080                   *:*             users:((\"node_exporter\",pid=662,fd=3))\n</code></pre> <ol> <li> <p>What do you think the problem might be?</p> </li> <li> <p>How will you test this?</p> </li> <li> <p>The developer tells you that he\u2019s pulling a local image. Do you find this to be    true, or is something else happening in their <code>run</code> command?</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"lac/u9ws/#definitions","title":"Definitions","text":"<p>Container:</p> <p>Docker:</p> <p>Podman:</p> <p>CI/CD:</p> <p>Dev/Prod Environments (Development/Production Environments):</p> <p>Dockerfile:</p> <p>Docker/Podman images:</p> <p>Repository:</p>"},{"location":"lac/u9ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Find a blog on deployment of some service or application in a container that interests you.    See if you can get the deployment working in the lab.</p> </li> <li> <p>What worked well?</p> </li> <li>What did you have to troubleshoot?</li> <li> <p>What documentation can you make to be able to do this faster next time?</p> </li> <li> <p>Run this scenario and play with K3s: https://killercoda.com/k3s/scenario/intro</p> </li> </ol>"},{"location":"lac/u9ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How can you apply this now in your current role in IT? If you\u2019re not in IT, how    can you look to put something like this into your resume or portfolio?</p> </li> </ol>"},{"location":"psc/contributing/","title":"Contributing","text":"<p> Contributing to the ProLUG Linux Systems Security Course Book </p> <p>The Professional Linux Users Group (ProLUG) provides a set of requirements and guidelines to contribute to this project. Below are steps to ensure contributors are adhering to those guidelines and fostering a productive version control environment.</p>"},{"location":"psc/contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How to be a Successful Contributor</li> <li>Signing your Git Commits with SSH</li> <li>Syncing your Fork with the Upstream ProLUG Repo</li> <li>Basic Contribution Workflow</li> <li>Comment First</li> <li>Create a Fork</li> <li>Clone the Fork to your Local Machine</li> <li>Create a New Branch</li> <li>Understand a few Best Practices</li> <li>Commit and Push your Changes</li> <li>Comment your Changes</li> <li>Create a Pull Request</li> <li>Supporting Material</li> </ul>"},{"location":"psc/contributing/#how-to-be-a-successful-contributor","title":"How to be a Successful Contributor","text":"<p>To be an effective contributor understanding Git, whether through the command line or an external tool, will be an important part of contributing. To this effect it is important that any individual who contributes to this project have a working understanding of committing, merging, and other fundamental Git workflows.</p> <p>For clarity this project utilizes GitHub for remote repositories and CI/CD testing pipeline workflows. Git and GitHub are two separate entities where GitHub provides the hosting services and Git provides the version control.</p> <p>Prospective contributors are directed to several resources should they feel their competency with Git or GitHub falls short:</p> <p>Git documentation:</p> <ul> <li>https://git-scm.com/doc</li> </ul> <p>Git and GitHub video tutorials:</p> <ul> <li>ByteByteGo's Git Explained in 4 Minutes (4m)</li> <li>Fireship's How to use Git and Github (12m)</li> <li>freeCodeCamp's Git and GitHub Crash Course (1hr)</li> </ul>"},{"location":"psc/contributing/#signing-your-git-commits-with-ssh","title":"Signing your Git Commits with SSH","text":"<p>Contributors who elect to contribute through the command line will need to verify their identities before their commits can be accepted. This step is not required if contributors will be submitting changes via GitHub.com itself since users will have verified their identities with GitHub's own verification process.</p> <p>To reiterate, individuals contributing via command line will need to sign their commits through SSH. Signing GitHub commits helps ProLUG validate incoming commits from trusted contributors that reside outside the GitHub ecosystem. It can be quite trivial to impersonate users on GitHub and it is in the best interest of the project and contributors to observe this security practice.</p> <p>It should also be noted that GitHub supplies tools like GitHub CLI that abstract away the process of signing and verifying commits from the command line. GitHub provides a <code>gh auth login</code> function to facilitate the procedure which contributors can employ without the necessary changes suggested below.</p> <p>To Sign your Git Commits with SSH:</p> <p>Generate an SSH key pair if you don't have one:</p> <pre><code>ssh-keygen -t ed25519\n</code></pre> <p>Add SSH public key ('.pub' suffix) to GitHub as \"Signing Key\". </p> <p>* GitHub.com -&gt; Profile -&gt; Settings -&gt; GPG and SSH Keys -&gt; Add SSH Key -&gt; Drop down -&gt; Signing Key</p> <p>Below is a bash script that will attempt to configure signing Git commits on a localhost:</p> <pre><code>#!/bin/bash\nGH_USERNAME=\"YourUsername\"\ngit config --global gpg.format ssh\ngit config --global user.signingkey ~/.ssh/id_ed25519.pub\ngit config --global tag.gpgSign true\ngit config --global commit.gpgSign true\nmkdir -p ~/.config/git\ntouch ~/.config/git/allowed_signers\necho \"${GH_USERNAME} $(cat ~/.ssh/id_ed25519.pub)\" &gt; ~/.config/git/allowed_signers\ngit config --global gpg.ssh.allowedSignersFile ~/.config/git/allowed_signers\n# Make a commit to verify\ngit log --show-signature -1\n</code></pre> <p>Make a commit after running those commands and then use <code>git log --show-signature -1</code>. You should see something like <code>Good \"git\" signature for &lt;yourname&gt; with ED25519 key SHA256:abcdef...</code> if it worked.</p> <p></p> <p>Your commits should now be verified from your account. This helps us ensure that valid users are contributing to this project. Unverified commits will be scrutinized and likely discarded.</p>"},{"location":"psc/contributing/#syncing-your-fork-with-the-upstream-prolug-repo","title":"Syncing your Fork with the Upstream ProLUG Repo","text":"<p>In an effort to minimize merge conflicts we strongly suggest forks remain up to date with the original repository before committing changes. This will help us reduce pull request management overhead.</p>  Pull requests with substantial merge conflicts may be rejected.  <p>You can do this from the GitHub web UI easily with the <code>Sync Fork</code> button. If you want to do this from the terminal, you can add a new <code>git remote</code> called <code>upstream</code>.</p> <pre><code>git remote add upstream https://github.com/ProfessionalLinuxUsersGroup/psc.git\n</code></pre> <p>Then, to sync your local fork with the original repo, do a <code>git pull</code> from the <code>upstream</code> remote.</p> <pre><code>git pull upstream main\n</code></pre> <p>This fork should now be up to date with the original upstream repository.</p>"},{"location":"psc/contributing/#basic-contribution-workflow","title":"Basic Contribution Workflow","text":"<p>You'll create your own fork of the repository using the GitHub web UI, create a branch, make changes, push to your fork, then open a pull request.</p>"},{"location":"psc/contributing/#comment-first","title":"Comment First","text":"<p>If you'd like to work on a specific worksheet or lab, please let us know first by commenting on the issue so you can be assigned to it. This way, other contributors can see that someone is already working on it.</p> <p>This helps the repository maintainers and contributors attain a high degree of visibility and collaboration before merging changes.</p>"},{"location":"psc/contributing/#create-a-fork","title":"Create a Fork","text":"<p>Go to the original repository link. Click on \"Fork\" on the top right. Now you'll have your own version of the repository that you can clone.</p> <pre><code>git clone git@github.com:YOUR_USERNAME/psc.git\n# Or, with https:\ngit clone https://github.com/YOUR_USERNAME/psc.git\n</code></pre>"},{"location":"psc/contributing/#clone-the-fork-to-your-local-machine","title":"Clone the Fork to your Local Machine","text":"<p>Then you'll need to clone your fork down to your local machine in order to work on it.</p> <pre><code>git clone git@github.com:yourname/psc.git\n</code></pre>"},{"location":"psc/contributing/#create-a-new-branch","title":"Create a New Branch","text":"<p>Whenever making changes contributors are highly encouraged to create a branch with an appropriate name. Switch to that branch, then make changes there.</p> <p>For example, if you're working on the Unit 1 Worksheet:</p> <pre><code>git branch unit1-worksheet\ngit switch unit1-worksheet\n# Or, simply:\ngit switch -c unit1-worksheet\n</code></pre> <p>Make changes to the <code>u1ws.md</code>.</p>"},{"location":"psc/contributing/#consider-a-few-useful-practices","title":"Consider a few Useful Practices","text":"<p>The practices presented below are not required to contribute to the ProLUG course books but can streamline contributing to any project and are considered to some as best practice or incredibly useful when engaging in version control with Git.</p>"},{"location":"psc/contributing/#git-rebasing","title":"Git Rebasing","text":"FIRST AND FOREMOST, ONLY REBASE IN LOCAL REPOSITORIES. NEVER REBASE   A PUBLIC BRANCH OR REPOSITORY UNLESS YOU FULLY UNDERSTAND THE CONSEQUENCES.   YOU HAVE BEEN WARNED. <p>Proper implementation of rebasing can leave a clean, and easily readable commit history for all concerned parties. Rebasing can also facilitate the management of branches and working directories in a notably active project.</p> <p>The Git documentation provides a succinct explanation of its utility but also how it could potentially ruin a project and erase the work of other contributors.</p> <p>Rebasing also plays a role in facilitating any commit reverts that may need to be made in the future. More on that will follow.</p> USE REBASING WISELY <p>Git Rebasing documentation: https://git-scm.com/book/en/v2/Git-Branching-Rebasing</p>"},{"location":"psc/contributing/#commit-early-often-and-squashing-commits","title":"Commit Early, Often, and Squashing Commits","text":"<p>It is great practice to commit early, and often. This however can produce hard to read commits for repo maintainers and contributors. Squashing commits, which is a type of rebasing, can be utilized to compress a large number of commits made in a local repository before being pushed into a remote repository and eventual pull requests.</p> <p>Below is an example of 4 local commits squashed into a single commit that was pushed remotely:</p> <p></p> <p>Squashing commits can improve readability, but its primary utility, especially for larger projects, may be in addressing an event where rolling back several commits due to a bug or test can be done with a single commit revert.</p> <p>freeCodeCamp has a great write-up on this procedure. When done appropriately this can greatly facilitate the development process. Contributors are strongly encouraged to begin exploring these types of workflows if they never have.</p> AGAIN, USE REBASING AND SQUASHING WISELY"},{"location":"psc/contributing/#git-stashing","title":"Git Stashing","text":"<p>Another useful practice is to employ \"stashing\" uncommitted files in a local repository. This is useful in many contexts including stashing local changes to resolve recently introduced remote vs. local repo conflicts, or quickly switching working spaces.</p> <p>Stashing effectively unstages any changes made in the local repo and saves them to be applied later. This can further help facilitate a rebase or merge before committing changes upstream for instance.</p> <p>More on this here:</p> <p>https://www.atlassian.com/git/tutorials/saving-changes/git-stash</p> <p>https://git-scm.com/book/en/v2/Git-Tools-Stashing-and-Cleaning</p>"},{"location":"psc/contributing/#commit-and-push-your-changes","title":"Commit and Push your Changes","text":"<p>First make sure your forked repo is up-to-date with the original. Create your commit (make sure it's signed!), then push changes to your own fork on the new branch.</p> <pre><code>git commit -m \"descriptive commit message\"\ngit push origin unit1-worksheet\n</code></pre>"},{"location":"psc/contributing/#comment-your-changes","title":"Comment your Changes","text":"<p>Before creating a pull request, make a comment on the issue containing your changes. We're doing this since the GitHub organization feature is paid and we are doing this for free, so there is only one person who is able to merge pull requests at the moment.</p>"},{"location":"psc/contributing/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Now you'll be able to go to the original repository link and go to the \"Pull Requests\" tab and create a new pull request. Select your branch <code>unit1-worksheet</code>, and create a description and mention an issue by number (e.g., <code>#5</code>).</p>"},{"location":"psc/contributing/#supporting-material","title":"Supporting Material","text":"<p>Below are links to the necessary materials to build out the course templates:</p> <ul> <li>Look over the template pages wiki, or directly here:</li> <li>Pages: intro,     bonus,     lab,     worksheet</li> </ul> <p>Ancillary unit videos provided by Scott:</p> <ul> <li>https://www.youtube.com/watch?v=eHB8WKWz2eQ&amp;list=PLyuZ_vuAWmprPIqsG11yoUG49Z5dE5TDu</li> </ul> <p>PDF and docs directly related to each Unit of the course:</p> <ul> <li>https://discord.com/channels/611027490848374811/1098309490681598072</li> </ul>"},{"location":"psc/contributors/","title":"Contributors","text":"<p> ProLUG Contributors </p>"},{"location":"psc/development/","title":"Development","text":"<p> Contributing and Local Development </p> <p>It is strongly encouraged that contributors test their changes before making commits. To help facilitate this process a set of instructions and guidelines are provided below. These guidelines are by no means a requirement or the only set of procedures to locally develop on this project.</p> <p>The examples, code, and commands provided below were developed using such technologies as Ansible, containers, bash scripts, and more.</p>"},{"location":"psc/development/#build-dependencies","title":"Build Dependencies","text":"<p>The ProLUG Security Course (PSC) utilizes mdBook (markdown Book), a friendly and popular markdown utility that quickly exports files and web structures for documentation or general website use cases.</p> <p>Utilizing mdBook this course then deploys the exported web structure to a Git Pages workflow and runner that then produces an easily navigable website.</p> <p>Below is the current workflow that deploys the Git Page for the course:</p> <p>To achieve this workflow locally the following environment and dependencies are required:</p> 1. A localhost, this could be a container, virtual machine, or local machine 2. The following packages installed on such machine: - httpd or apache - git - gcc - rust - cargo 3. And a clone of a ProLUG repository"},{"location":"psc/development/#building-deploying-and-developing-locally","title":"Building, Deploying, and Developing Locally","text":"<p>Below is a set of scripts and Ansible-Playbooks that can quickly achieve this environment in an automated fashion. They are only designed to \"standup\" these machines, they are otherwise unintelligent and will not manage or cleanup environments if things go awry.</p>"},{"location":"psc/development/#ansible-playbook","title":"Ansible-Playbook","text":"<p>https://github.com/ProfessionalLinuxUsersGroup/psc/blob/main/src/assets/deploy/ansible-playbook.yml</p> <p>To use this playbook, your machine(s)/containers must be configured correctly for Ansible. If you don't know the requirements to administer a machine via Ansible, documentation has been provided below.</p>  This playbook will need to be modified based on which distribution or package management tool is configured.  <p>Getting started with Ansible: https://docs.ansible.com/ansible/latest/getting_started/index.html</p>"},{"location":"psc/development/#bash-script","title":"Bash Script","text":"<p>Many of these commands assume a root user.</p> <p>Export and execute this script to your machine/container.</p>   Dependencies can total over ~500MB compressed and 1-2GB unpackaged or more.  Debian containers/machines will require building many of these packages from source or adding additional repositories as Debian has a far slower package version adoption rate for stability, thus is not recommended for deploying mdBook.   <p>These scripts will take up to 5-7 minutes to download the necessary dependencies and compile mdBook depending on the machine/container's capabilities.</p> <p>Tested with Rocky 9 and Ubuntu 24.04 Containers.</p> <p>APT frontends:</p> <pre><code>#!/bin/bash\napt-get update\napt-get -y install apache2 git gcc rustc-1.80 cargo-1.80\ncargo-1.80 install --locked mdbook\nsystemctl enable apache2 &amp;&amp; systemctl start apache2\ncd &amp;&amp; git clone https://github.com/ProfessionalLinuxUsersGroup/psc\necho 'PATH=$PATH:~/.cargo/bin/' | tee -a ~/.profile\nexport PATH=$PATH:~/.cargo/bin/ &amp;&amp; echo $PATH\ncd ~/psc &amp;&amp; mdbook build -d /var/www/html\nsystemctl restart apache2\n</code></pre> <p>DNF frontends:</p> <pre><code>#!/bin/bash\ndnf update\ndnf install -y httpd git gcc rust cargo\ncargo install --locked mdbook\nsystemctl enable httpd &amp;&amp; systemctl start httpd\ncd &amp;&amp; git clone https://github.com/ProfessionalLinuxUsersGroup/psc\necho 'PATH=$PATH:~/.cargo/bin/' | tee -a ~/.bash_profile\nexport PATH=$PATH:~/.cargo/bin/ &amp;&amp; echo $PATH\ncd ~/psc &amp;&amp; mdbook build -d /var/www/html\nsystemctl restart httpd\n</code></pre>"},{"location":"psc/development/#from-here-you-can-use-such-commands-from-your-localhost-to-implement-changes","title":"From here you can use such commands from your localhost to implement changes:","text":"<pre><code>cd {working psc directory} #for example: /root/psc or ~/psc\nmdbook build -d /var/www/html\nsystemctl restart {httpd or apache}\n</code></pre> <p>These commands will switch your shell into the appropriate directory, execute the necessary cargo binaries located in its installed PATH, build the mdBook from any files that were changed, and then finally restart the web server.</p> <p>From there you should be able to see any changes you have made are reflected.</p>"},{"location":"psc/development/#or-send-commands-over-to-a-networked-container-or-machine","title":"Or send commands over to a networked container or machine:","text":"<p>Note: To minimize complexity and given the nature of commands over SSH, these commands will need to utilize absolute paths.</p> <pre><code>scp {working directory}/{targeted document} {TARGET_IP}:/root/psc/src/{targeted document}\nssh {TARGET_IP} \"cd /root/psc &amp;&amp; ~/.cargo/bin/mdbook build -d /var/www/html &amp;&amp; systemctl restart httpd\"\n</code></pre> <p>An example of the workflow after making changes:</p> <pre><code>scp src/development.md 172.16.15.8:/root/psc/src/\nssh 172.16.15.8 \"cd /root/psc &amp;&amp; ~/.cargo/bin/mdbook build -d /var/www/html &amp;&amp; systemctl restart httpd\"\n</code></pre> <p></p>"},{"location":"psc/outro/","title":"Outro","text":"<p> Under Construction </p>"},{"location":"psc/project/","title":"Project","text":"<p> ProLUG Security Engineering - Final Project </p> <p>Students wishing to complete the Security Engineering course are expected to devise  and complete a capstone project, to be turned in at the end of the course.</p> <p>The instructions, expectations, and deliverables for the project are listed on this page.  </p>"},{"location":"psc/project/#instructions","title":"Instructions","text":"<ol> <li> <p>We have picked up a new client. They are requesting we help them adhere to the HIPAA    compliance standard. Review an explanation of the standard here: https://www.hhs.gov/hipaa/for-professionals/security/laws-regulations/index.html</p> </li> <li> <p>If you are in the EU and want to substitute GDPR, you may do so. https://gdpr.eu/what-is-gdpr/</p> </li> <li> <p>Build the documentation for HIPAA Compliance.</p> </li> <li> <p>How are we implementing Risk analysis and management?</p> </li> <li>What are our safeguards?<ol> <li>Administrative</li> <li>Physical</li> <li>Technical</li> </ol> </li> <li>How do we form Business Associate Agreements</li> <li> <p>What are our documentation practices?</p> <ol> <li>Policies</li> <li>Procedures</li> <li>Update and review cadence</li> </ol> </li> <li> <p>Prepare to Present (https://www.overleaf.com/ is a great alternative to Powerpoint)</p> </li> <li> <p>Setup a 15-20 slide deck on what you did</p> <ol> <li>Project purpose</li> <li>Diagram</li> <li>Build Process</li> <li>What did you learn?</li> <li>How are you going to apply this?</li> </ol> </li> <li> <p>Do any of you want to present?</p> </li> <li>Let Scott know (@het_tanis) and we\u2019ll get you a slot in the last few weeks.</li> </ol>"},{"location":"psc/project/#deliverables","title":"Deliverables","text":"<ol> <li>A 15-20 slide presentation of the above material that you would present to a group    (presenting to us is voluntary, but definitely possible.)</li> <li>This can be done with Microsoft PowerPoint, LibreOffice Impress, or      overleaf.com.</li> </ol>"},{"location":"psc/prolug/","title":"Prolug","text":"<p> The Professional Linux Users Group (ProLUG) </p>"},{"location":"psc/prolug/#in-the-beginning","title":"In the Beginning","text":"<p>Founded approximately 15 years ago, the Professional Linux User Group (ProLUG) began as a vision of Het Tanis, known by his community alias 'Scott Champine.' Het identified the need for an informal yet structured space where Linux professionals could share knowledge, collaborate, and grow together. What started as local in-person meetups quickly gained traction, thanks to the increasing demand for open-source collaboration and the widespread adoption of Linux in both enterprises and personal projects.</p>"},{"location":"psc/prolug/#why-prolug-started","title":"Why ProLUG Started","text":"<p>ProLUG was born out of the recognition that Linux professionals often face challenges that are best solved through peer collaboration and hands-on experience. The community\u2019s founding principles were rooted in creating an environment where newcomers could learn from experienced professionals, and seasoned users could gain exposure to advanced topics and emerging technologies. Its core mission was simple yet impactful: to provide continuous growth opportunities in Linux system administration, automation, and cloud technologies.</p> <p>Some of the key motivations behind ProLUG's formation include:</p> <ul> <li>Peer Support: Helping members solve technical challenges through discussion and advice from experts.</li> <li>Knowledge Sharing: Encouraging open sharing of tips, tricks, configurations, and scripts related to Linux and open-source tools.</li> <li>Hands-on Learning: Providing access to practical labs, exercises, and real-world scenarios for hands-on training.</li> <li>Community Mentorship: Offering a space for members to mentor and be mentored by others in different stages of their careers.</li> <li>Certification Prep: Assisting members in preparing for recognized industry certifications.</li> </ul>"},{"location":"psc/prolug/#the-expansion-into-an-online-community","title":"The Expansion into an Online Community","text":"<p>While initially focused on local in-person meetings, ProLUG embraced online platforms to extend its reach globally. The switch to a virtual model enabled:</p> <ul> <li>Global Networking: Professionals and enthusiasts from around the world could now connect, learn, and collaborate without geographical limitations.</li> <li>24/7 Discussion: Via platforms like Discord, members could share insights, discuss Linux problems, and exchange ideas anytime, anywhere.</li> <li>Greater Diversity: The online expansion diversified the member base, incorporating individuals from various industries and technical backgrounds, creating a rich environment for problem-solving.</li> </ul>"},{"location":"psc/prolug/#interactive-labs-and-training-programs","title":"Interactive Labs and Training Programs","text":"<p>One of ProLUG\u2019s most successful expansions has been its focus on interactive, hands-on labs. To bridge the gap between theory and practice, Het Tanis launched a series of labs on platforms like Killercoda, covering a variety of topics including:</p> <ul> <li>Linux Essentials and System Administration</li> <li>Ansible Automation</li> <li>Kubernetes and Container Orchestration</li> <li>Security and Network Hardening</li> </ul> <p>With over 50 interactive labs available and more being continuously developed, members benefit from practical scenarios that simulate real-world challenges. The labs cater to beginners, intermediates, and experts, ensuring everyone has something to gain.</p>"},{"location":"psc/prolug/#certification-and-career-development","title":"Certification and Career Development","text":"<p>In 2024, ProLUG launched its first structured certification course: Enterprise Linux Administration. This program was designed to provide a comprehensive curriculum covering topics such as:</p> <ul> <li>Advanced Linux system configuration</li> <li>Enterprise networking and services</li> <li>Security management</li> <li>Scripting and automation</li> </ul> <p>The first cohort of graduates successfully completed the program in January 2025, marking a major milestone in ProLUG\u2019s commitment to professional development. Many graduates have reported success stories, such as landing new jobs, securing promotions, or gaining confidence in their Linux expertise.</p>"},{"location":"psc/prolug/#what-is-a-user-group","title":"What is a User Group?","text":"<p>A user group is a community of individuals who come together to share common interests, typically in a specific area of technology, such as Linux. These groups can be local or online and serve as platforms for:</p> <ul> <li>Collaboration: Members work together to troubleshoot, build projects, and share experiences.</li> <li>Networking: Opportunities to connect with professionals, mentors, and employers within the field.</li> <li>Learning: Workshops, presentations, and discussions that cover new and emerging technologies.</li> <li>Career Growth: Access to resources, training programs, and job opportunities.</li> </ul> <p>ProLUG is a prime example of how a user group can grow beyond its initial purpose, evolving into a vibrant global community with practical learning opportunities and real-world outcomes.</p>"},{"location":"psc/prolug/#success-stories","title":"Success Stories","text":"<p>Being part of ProLUG has proven highly beneficial for many members, with success stories ranging from career advancements to personal growth:</p> <ul> <li>Job Opportunities: Members have found jobs in system administration, DevOps, and cloud engineering roles through networking within ProLUG.</li> <li>Certifications: Many members have successfully obtained Linux-related certifications, including RHCSA, RHCE, and LFCS, using ProLUG\u2019s resources and mentorship programs.</li> <li>Skill Development: Through interactive labs and group discussions, members have honed skills in automation (Ansible), scripting (Bash, Python), containerization (Docker, Kubernetes), and more.</li> <li>Mentorship Relationships: Senior professionals have mentored newcomers, creating a cycle of continuous learning and knowledge sharing.</li> </ul>"},{"location":"psc/prolug/#current-milestones","title":"Current Milestones","text":"<ul> <li>3,000+ Members: ProLUG\u2019s global community continues to grow rapidly, attracting Linux enthusiasts and professionals from various backgrounds.</li> <li>50+ Interactive Labs: Covering diverse topics, from basic Linux administration to advanced enterprise systems management.</li> <li>Ongoing Training Programs: Continuous updates to certification preparation courses, interactive workshops, and guided lab exercises.</li> </ul> <p>ProLUG\u2019s commitment to fostering a collaborative environment has made it a go-to community for anyone interested in Linux. Whether you're a beginner looking to learn the basics or an experienced professional aiming to advance your career, ProLUG offers a pathway to success.</p>"},{"location":"psc/resources/","title":"Resources","text":"<p> Resources </p> <p>Running list of all links, may need further categorization at a later date.</p> Description Link TBD TBD TBD TBD TBD TBD"},{"location":"psc/syllabus/","title":"Course Syallabus","text":"<p>Welcome to the ProLUG Security Engineering Course Book.</p>"},{"location":"psc/syllabus/#this-book","title":"This Book","text":"<p>Contains all materials pertaining to the course including links to external resources. It has been put together with care by a number of ProLUG group members referencing original instructional materials produced by Scott Champine (Het Tanis).</p> <p>The content is version controlled with Git and stored here: https://github.com/ProfessionalLinuxUsersGroup/psc/</p> <p>Furthermore, the book has been built with mdbook for ease of navigation. Be sure to try the search functionality.</p>"},{"location":"psc/syllabus/#course-description","title":"Course Description","text":"<p>This course addresses how to secure Linux a corporate environment. This course will focus on adhering to regulations, best practices, and industry standards. This course will expose the concepts of controls, their implementation, and how they fit into overall security posture. The learner will practice securely building, deploying, integrating, and monitoring Linux systems. Standard security documentation and reporting will be practiced throughout, to better prepare the learner for the industry.</p>"},{"location":"psc/syllabus/#prerequisites-andor-corequisites","title":"Prerequisite(s) and/or Corequisite(s):","text":"<p>Prerequisites: None</p> <p>Credit hours: N/A</p> <p>Contact hours: 100 (40 Theory Hours, 60 Lab Hours)</p>"},{"location":"psc/syllabus/#course-summary","title":"Course Summary","text":""},{"location":"psc/syllabus/#major-instructional-areas","title":"Major Instructional Areas","text":"<ul> <li>Build Standards and Compliance</li> <li>Securing the Network Connection</li> <li>User Access and System Integration</li> <li>Bastion Hosts and Air-Gaps</li> <li>Updating Systems and Patch Cycles</li> <li>Monitoring and Parsing Logs</li> <li>Monitoring and Alerting</li> <li>Configuration drift and Remediation</li> <li>Certificate and Key Madness</li> </ul>"},{"location":"psc/syllabus/#course-objectives","title":"Course Objectives","text":"<ul> <li>Build and configure a Linux system to adhere to compliance frameworks</li> <li>Integrating Linux to a network in a secure fashion</li> <li>Integrating Linux with Enterprise Identity and Access Management (IAM) frameworks</li> <li>Implement User ingress controls to a system/network with bastion frameworks</li> <li>Updating Linux to resolve security vulnerabilities and reporting out to security teams</li> <li>Design logging workflows to move event logging off of systems for real time monitoring</li> <li>Monitoring and alerting on events in Linux</li> <li>Maintaining system configuration drift and remediation</li> </ul>"},{"location":"psc/syllabus/#written-discussions","title":"Written Discussions","text":"<p>Are assigned as 'Discussion Posts' within each unit. Discussions generally take place within the Discord Server under #prolug-projects. More specifically, each unit will contain links to particular discussion posts within #prolug-projects.</p>"},{"location":"psc/syllabus/#completing-the-course","title":"Completing the Course","text":"<p>In order to complete this course students must participate in group discussions and complete provided labs. Additionally, students are to propose and complete a final project involving skills learned from the course.</p>"},{"location":"psc/syllabus/#recommended-tools-resources-and-frameworks","title":"Recommended Tools, Resources, and Frameworks","text":"<ul> <li>Killercoda: https://killercoda.com/</li> <li>STIG Resources: https://public.cyber.mil/stigs/srg-stig-tools/</li> <li>Recommended (but not required) STIG Viewer: v2.18</li> <li>NIST: https://www.nist.gov/</li> <li>Open Worldwide Application Security Project Top 10: https://owasp.org/www-project-top-ten/</li> <li>CIS Controls and Benchmarks: https://www.cisecurity.org/cis-benchmarks</li> </ul>"},{"location":"psc/syllabus/#required-resources","title":"Required Resources","text":""},{"location":"psc/syllabus/#option-1-killercoda-machine","title":"Option #1 (Killercoda Machine)","text":"<p>Cloud Lab server running Ubuntu on Killercoda.</p> <p>Minimal resources can accomplish our tasks</p> <ul> <li>1 CPU</li> <li>2 GB Ram</li> <li>30 GB Hard Drive</li> <li>Network Interface (IP already setup)</li> </ul>"},{"location":"psc/syllabus/#option-2-home-lab","title":"Option #2 (Home Lab)","text":"<p>Local VM server running: RHEL, Fedora, Rocky</p> <p>Minimal resources</p> <ul> <li>1 CPU</li> <li>2GB RAM</li> <li>Network Interface (Bridged)</li> </ul>"},{"location":"psc/syllabus/#option-3-prolug-remote-lab","title":"Option #3 (ProLUG Remote Lab)","text":"<p>ProLUG Lab access to Rocky 9.4+ instance.</p> <p>Minimal resources can accomplish our tasks</p> <ul> <li>1 CPU</li> <li>4 GB RAM</li> <li>Network Interface (IP already setup)</li> </ul> <p></p>"},{"location":"psc/syllabus/#course-plan","title":"Course Plan","text":""},{"location":"psc/syllabus/#instructional-methods","title":"Instructional Methods","text":"<p>This course is designed to promote learner-centered activities and support the development of Linux security skills. The course utilizes individual and group learning activities, performance-driven assignments, problem-based cases, projects, and discussions. These methods focus on building engaging learning experiences conducive to development of critical knowledge and skills that can be effectively applied in professional contexts.</p>"},{"location":"psc/syllabus/#class-size","title":"Class Size","text":"<p>This class will effectively engage 40-60 learners.</p>"},{"location":"psc/syllabus/#class-schedule","title":"Class Schedule","text":"<p>https://discord.com/events/611027490848374811/1353330418669326407</p> <p>Class will meet over weekend (Brown bag) sessions. 1 time per week, for 10 weeks. There will be a total of 10 sessions.</p> Session Topic 1 Unit 1 - Build Standards and Compliance 2 Unit 2 - Securing the network connection 3 Unit 3 - User Access and system integration 4 Unit 4 - Bastion hosts and airgaps 5 Unit 5 - Updating systems and patch cycles 6 Unit 6 - Monitoring and parsing logs 7 Unit 7 - Monitoring and alerting 8 Unit 8 - Configuration drift and remediation 9 Unit 9 - Certificate and key madness 10 Unit 10 - Recap and final project"},{"location":"psc/syllabus/#suggested-learning-approach","title":"Suggested Learning Approach","text":"<p>In this course, you will be studying individually and within a group of your peers, primarily in a lab environment. As you work on the course deliverables, you are encouraged to share ideas with your peers and instructor, work collaboratively on projects and team assignments, raise questions, and provide constructive feedback.</p>"},{"location":"psc/u10intro/","title":"U10intro","text":"<p> Under Construction </p>"},{"location":"psc/u10lab/","title":"U10lab","text":"<p> Under Construction </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u10lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u10lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u10_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u10_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u10ws/","title":"U10ws","text":"<p> Under Construction </p>"},{"location":"psc/u1intro/","title":"Build Standards and Compliance","text":""},{"location":"psc/u1intro/#overview","title":"Overview","text":"<p>Building standards and compliance in cybersecurity engineering ensures that systems adhere to industry best practices, regulatory requirements, and security frameworks, reducing risks and vulnerabilities.</p> <p>By implementing structured guidelines through tools and frameworks like STIGs (Security Technical Implementation Guides) and the NIST CS (National Institute of Standards and Technology Cyber Security) framework, organizations can maintain resilience against evolving threats while ensuring accountability and regulatory alignment.</p> <p>This chapter will present critical knowledge in implementing security controls in information systems.</p>"},{"location":"psc/u1intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of Unit 1 students will have foundational knowledge and skills of the concepts below:</p> <ol> <li>Security Frameworks such as STIGs, CIS Controls, NIST Cybersecurity Framework</li> <li>Regulatory Compliance and Industry Standards when administering and building systems</li> <li>Skills and concepts in interacting with STIG remediation processes</li> <li>Understanding Risk Management and concepts surrounding risk vectors to organizations</li> <li>STIG Remediation and documentation skills</li> </ol>"},{"location":"psc/u1intro/#relevance-context","title":"Relevance &amp; Context","text":"<p>As the shepherds of sensitive data and systems, it is the ethical and legal duty of individuals that administer and build these systems to protect them from malicious actors with no regard for propriety. To be successful in securing systems students will need to thoroughly understand the cybersecurity landscape, its myriad potential threats, and the tools engineers and administrators have at their disposal.</p> <p>The concepts presented in this unit play a pivotal role in organizing and structuring a resilient security posture against threats to enterprise and organizational entities. They provide processes and procedures that engineers and administrators can implement to significantly reduce the attack surface of the systems they administer along with building a system of logging and documentation in the eventuality of a security incident.</p> <p>By thoroughly understanding these concepts students will be armed with a set of tools in the eternal and ever evolving landscape of cybersecurity.</p>"},{"location":"psc/u1intro/#prerequisites","title":"Prerequisites","text":"<p>Students should have a strong understanding of such skills as presented in the Linux Administration Course including:</p> <ol> <li>The Command Line Interface and BASH shell skills</li> <li>Installing and Updating Linux System Packages</li> <li>Interacting with command line tools such as: <code>systemctl</code>, <code>mount</code>, <code>grep</code>, and <code>ss</code></li> <li>Ability to interact with basic SQL queries using MariaDB</li> <li>Students will need to download the latest STIG viewer, v2.18</li> </ol>"},{"location":"psc/u1intro/#key-terms-and-definitions","title":"Key terms and Definitions","text":"<p>CIA Triad Regulatory Compliance HIPAA Industry Standards PCI/DSS Security Frameworks CIS STIG</p>"},{"location":"psc/u1lab/","title":"Lab","text":"<p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u1lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u1lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u1_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u1_lab(<code>.docx</code>)</li> </ul>"},{"location":"psc/u1lab/#module-1-exploring-system-information","title":"Module 1: Exploring System Information","text":""},{"location":"psc/u1lab/#exercise-11-familiarizing-ourselves-with-the-system","title":"Exercise 1.1: Familiarizing ourselves with the System","text":"<pre><code>mount | grep -i noexec\n\nmount | grep -i nodev\n\nmount | grep -i nosuid\n\n# Approximately how many of your mounted filesystems have each of these values?\n</code></pre>"},{"location":"psc/u1lab/#exercise-12-checking-mounted-systems","title":"Exercise 1.2: Checking Mounted Systems","text":"<pre><code>sysctl -a | grep -i ipv4\n\nsysctl -a | grep -i ipv6\n\n# How many of each are there?\n</code></pre> <pre><code>sysctl -a | grep -i ipv4 | grep -i forward\n\n# Does IPv4 forward on interfaces?\n</code></pre> <pre><code>lsmod | grep -i tables\n\n# What type of tables exist?\n</code></pre>"},{"location":"psc/u1lab/#module-2-prelab","title":"Module 2: PreLAB","text":"<ol> <li> <p>Download the STIG Viewer 2.18 from - https://public.cyber.mil/stigs/downloads/ </p> </li> <li> <p>Download the STIG for Mariadb and the import it into your STIG viewer.    </p> </li> </ol>"},{"location":"psc/u1lab/#module-3-lab","title":"Module 3: Lab","text":"<p>This lab is designed to have the engineer practice securing a Linux server or service against a set of configuration standards. These standards are sometimes called benchmarks, checklists, or guidelines. The engineer will be using STIG Viewer 2.18 to complete this lab.</p>"},{"location":"psc/u1lab/#mariadb-service-configuration","title":"MariaDB Service configuration:","text":"<ol> <li>Connect to a hammer server.</li> <li>Install MariaDB.</li> </ol> <pre><code>dnf install mariadb-server\n\n# Ensure that it is running\n\nsystemctl start mariadb\n\nsystemctl status mariadb\n\nss -ntulp | grep 3306\n</code></pre> <ul> <li> <p>Check and remediate v-253666 STIG.   </p> </li> <li> <p>What is the problem?</p> </li> <li>What is the fix?</li> <li>What type of control is being implemented?</li> <li>Is it set properly on your system?</li> </ul> <p>Connect to MariaDB locally.</p> <pre><code>mysql\n</code></pre> <p>Run the SQL command in the STIG's Fix Text section:</p> <pre><code>SELECT user, max_user_connections FROM mysql.user;\n</code></pre> <p></p> <p>Can you remediate this finding?   </p> <ul> <li>Check and remediate <code>v-253677 STIG</code></li> <li>What is the problem?</li> <li>What is the fix?</li> <li>What type of control is being implemented?</li> <li>Is it set properly on your system?</li> <li>Check and remediate <code>v-253678 STIG</code></li> <li>What is the problem?</li> <li>What is the fix?</li> <li>What type of control is being implemented?</li> <li>Is it set properly on your system?</li> <li>Check and remediate <code>v-253734 STIG</code></li> <li>What is the problem?</li> <li>What is the fix?</li> <li>What type of control is being implemented?</li> <li>Is it set properly on your system?</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u1ws/","title":"Worksheet","text":""},{"location":"psc/u1ws/#instructions","title":"Instructions","text":"<p>Fill out this sheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"psc/u1ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://public.cyber.mil/stigs/downloads</li> <li>https://excalidraw.com</li> <li>https://www.open-scap.org</li> <li>https://www.sans.org/information-security-policy</li> <li>https://www.sans.org/blog/the-ultimate-list-of-sans-cheat-sheets</li> </ul>"},{"location":"psc/u1ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u1_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u1_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"psc/u1ws/#unit-1-recording","title":"Unit 1 Recording","text":""},{"location":"psc/u1ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>The first question of this course is, \u201cWhat is Security?\u201d</p> <ol> <li>Describe the CIA Triad.</li> <li>What is the relationship between Authority, Will, and Force as they relate to security?</li> <li>What are the types of controls and how do they relate to the above question?</li> </ol>"},{"location":"psc/u1ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Find a STIG or compliance requirement that you do not agree is necessary for a server or service build.</p> <ol> <li>What is the STIG or compliance requirement trying to do?</li> <li>What category and type of control is it?</li> <li>Defend why you think it is not necessary. (What type of defenses do you think you could present?)</li> </ol>   Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"psc/u1ws/#definitions","title":"Definitions","text":"<p>CIA Triad:</p> <p>Regulatory Compliance:</p> <p>HIPAA:</p> <p>Industry Standards:</p> <p>PCI/DSS:</p> <p>Security Frameworks:</p> <p>CIS:</p> <p>STIG:</p>"},{"location":"psc/u1ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>Research a risk management framework. https://csrc.nist.gov/projects/risk-management/about-rmf</p> </li> <li> <p>What are the areas of concern for risk management?</p> </li> <li> <p>Research the difference between quantitative and qualitative risks.</p> </li> <li> <p>Why might you use one or the other?</p> </li> <li> <p>Research ALE, SLE, and ARO.</p> </li> <li>What are these terms in relation to?</li> <li>How do these help in the risk discussion?</li> </ol>"},{"location":"psc/u1ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you\u2019ve learned in your current role?</p> </li> </ol>"},{"location":"psc/u2intro/","title":"U2intro","text":"<p> Unit 2 - Securing the Network Connection </p>"},{"location":"psc/u2intro/#overview","title":"Overview","text":"<p>Understanding and implementing network standards and compliance measures can make security controls of critical importance very effective.</p> <p>This unit introduces foundational knowledge on analyzing, configuring, and hardening networking components using tools and frameworks like STIGs, OpenSCAP, and DNS configurations.</p>"},{"location":"psc/u2intro/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of Unit 2 students will have foundational knowledge and skills of the concepts below:</p> <ol> <li>Identifying and analyzing STIGs related to Linux networking.</li> <li>Understand and configure secure name resolution using nsswitch.conf and DNS.</li> <li>Utilizing tools like tcpdump, ngrep, ss, and netstat to monitor network behavior.</li> <li>Applying OpenSCAP and SCC tools for network compliance assessments.</li> <li>Exploring known network-based exploits and understanding their anatomy via the Diamond Model of Intrusion Analysis.</li> </ol>"},{"location":"psc/u2intro/#relevance-and-context","title":"Relevance and Context","text":"<p>Networks represent one of the most common attack vectors in enterprise systems. Misconfigured name resolution, open ports, and insecure protocols are all doorways to intrusion. As system engineers, building resilient systems requires a deep understanding of how data flows through these pathways and what tools can monitor and secure them.</p> <p>By learning to assess and remediate network-related STIGs and implementing structured standards, students will gain the skills to reduce ingress risk and respond effectively to threats. These skills are not only crucial for compliance but also for real-world defense.</p>"},{"location":"psc/u2intro/#prerequisites","title":"Prerequisites","text":"<p>To be successful, students should have a working understanding of skills and tools including:</p> <ol> <li>The Command Line Interface and BASH shell skills</li> <li>Installing and Updating Linux System Packages</li> <li>Network concepts including TCP/IP, DNS, and more</li> <li>Interacting with command line tools such as: <code>sysctl</code>, <code>firewalld</code>, <code>grep</code>, and <code>oscap</code></li> <li>Ability to edit files with <code>vim</code></li> <li>Students will need to download the latest STIG viewer, v2.18</li> </ol>"},{"location":"psc/u2intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>sysctl nsswitch.conf DNS Openscap CIS Benchmarks ss/netstat tcpdump ngrep</p>"},{"location":"psc/u2lab/","title":"U2lab","text":"<p> Unit 2 Lab - Securing the Network Connection </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u2lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server Root or sudo command access STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/)</p>"},{"location":"psc/u2lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.docx</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u2_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u2_lab(<code>.docx</code>)</li> </ul>"},{"location":"psc/u2lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <pre><code>sysctl -a | grep -i ipv4 | grep -i forward\n# Does this system appear to be set to forward? Why or why not?\n\nsysctl -a | grep -i ipv4 | grep -i martian\n# What are martians and is this system allowing them?\n\nsysctl -a | grep -i panic\n# How does this system handle panics?\n\nsysctl -a | grep -i crypto\n# What are the settings you see? Is FIPS enabled?\n\ncat /proc/cmdline\nfips-mode-setup --check\nsestatus\ncat /etc/selinux/config\n</code></pre> <p>What information about the security posture of the system can you see here? Can you verify SELINUX status? Can you verify FIPS status?</p> <p>Download the STIG Viewer 2.18 from - https://public.cyber.mil/stigs/downloads/</p> <p></p> <p>Download the STIG for RHEL 9 and the import it into your STIG viewer</p> <p></p> <p>Create a checklist from the opened STIG for RHEL 9</p> <p></p>"},{"location":"psc/u2lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to have the engineer practice securing a Linux server or service against a set of configuration standards. These standards are sometimes called benchmarks, checklists, or guidelines. The engineer will be using STIG Viewer 2.18 to complete this lab.</p>"},{"location":"psc/u2lab/#network-service-configuration","title":"Network Service configuration","text":"<p>Connect to a hammer server Filter by ipv4 and see how many STIGs you have.</p> <p></p>"},{"location":"psc/u2lab/#examine-stig-v-257957","title":"Examine STIG V-257957","text":"<p>What is the problem? What is the fix? What type of control is being implemented? Is it set properly on your system?</p> <pre><code>sysctl -a | grep -i ipv4 | grep -i syncookies\n</code></pre> <p></p> <p>Can you remediate this finding? In this case it\u2019s already correctly set. But if we needed to, we would set that value in /etc/sysctl.d/00- remediate.conf And then reload sysctl with <code>sysctl --system</code></p>"},{"location":"psc/u2lab/#check-and-remediate-v-257958-stig","title":"Check and remediate V-257958 STIG","text":"<p>What is the problem? What is the fix? What type of control is being implemented? Is it set properly on your system?</p> <p></p> <p>How would you go about remediating this on your system?</p>"},{"location":"psc/u2lab/#check-and-remediate-v-257960-and-v-257961-stigs","title":"Check and remediate V-257960 and V-257961 STIGs","text":"<p>What is the problem? How are they related? What is the fix? What type of control is being implemented? Is it set properly on your system?</p>"},{"location":"psc/u2lab/#filter-by-firewall","title":"Filter by firewall","text":"<p>How many STIGS do you see?</p> <p></p> <p>What do these STIGS appear to be trying to do? What types of controls are they?</p>"},{"location":"psc/u2lab/#firewall-port-exposure","title":"Firewall port exposure","text":"<p>Scenario:</p>   Your team needs to use node_exporter with Prometheus to allow scraping of system information back to your network monitoring solution. You are running a firewall, so you need to expose the port that node_exporter runs on to the network outside of your system."},{"location":"psc/u2lab/#expose-a-network-port-through-your-firewall","title":"Expose a network port through your firewall","text":"<pre><code># Verify that your firewall is running\nsystemctl status firewalld\n\n# Verify that your firewall has the service defined\nfirewall-cmd --get-services | grep -i node\nls /usr/lib/firewalld/services | grep -i node\n\n# Verify that the service is not currently enabled for node_exporter\nfirewall-cmd --list-services\n\n# Examine the structure of the firewall .xml file\ncat /usr/lib/firewalld/services/prometheus-node-exporter.xml\n\n# Enable the service through your firewall\nfirewall-cmd --permanent --add-service=prometheus-node-exporter\n\n# Reload so the changes take effect\nfirewall-cmd --reload\n\n# Verify that the service is currently enabled for node_exporter\nfirewall-cmd --list-services\n</code></pre>"},{"location":"psc/u2lab/#automate-stig-remediation-on-a-system","title":"Automate STIG remediation on a system","text":"<p>There are many options and the STIG remediation steps are well known. Here the learner will examine a few ways to generate Ansible and Shell fixes to your system. Then one can apply all of them, or just some of them. This is the real value of a security engineer focused Linux engineer, the trade-off between security and productivity.</p>"},{"location":"psc/u2lab/#download-and-extract-a-stig-remediation-tool","title":"Download and extract a STIG remediation tool","text":"Note: If any lab download does not work, check the <code>/labs</code> folder on the server for a <code>[course]_[unit#].zip</code> file to complete the activities.  <pre><code>cd /root\nmkdir stigs\ncd stigs\nwget -O U_RHEL_9_V2R4_STIG_Ansible.zip https://dl.dod.cyber.mil/wp-content/uploads/stigs/zip/U_RHEL_9_V2R4_STIG_Ansible.zip\nunzip U_RHEL_9_V2R4_STIG_Ansible.zip\nmkdir ansible\ncp rhel9STIG-ansible.zip ansible/\ncd ansible\nunzip rhel9STIG-ansible.zip\n</code></pre>"},{"location":"psc/u2lab/#examine-the-default-values-for-stigs","title":"Examine the default values for STIGS","text":"<pre><code>cd /root/stigs/ansible/roles/rhel9STIG/defaults/\nvim main.yml\n</code></pre> <p>Search for a few of the STIG numbers you used earlier and see their default values.</p> <ul> <li>use /257784 to search</li> </ul>"},{"location":"psc/u2lab/#examine-the-playbook-to-see-how-those-are-applied-in-a-running-system","title":"Examine the playbook to see how those are applied in a running system.","text":"<pre><code>vim /root/stigs/ansible/roles/rhel9STIG/tasks/main.yml\n</code></pre> <ul> <li>use /257784 to search for the STIG from above and see how it is fixed in the playbook.</li> </ul>"},{"location":"psc/u2lab/#create-an-ansible-playbook-from-openscap","title":"Create an Ansible playbook from OpenSCAP","text":"<pre><code>dnf -y install openscap-scanner openscap-utils openscap-scanner scap-security-guide\ncd /root\nmkdir openscap\ncd openscap\n\n# Generate the Ansible\noscap xccdf generate fix --profile ospp --fix-type ansible /usr/share/xml/scap/ssg/content/ssg-rhel9-ds.xml &gt; draft-disa-remediate.yml\n\n# Examine the file\nvim draft-disa-remediate.yml\n\n# Generate a BASH version\noscap xccdf generate fix --profile ospp --fix-type bash /usr/share/xml/scap/ssg/content/ssg-rhel9-ds.xml &gt; draft-disa-remediate.sh\n\n# Examine the file\nvim draf-disa-remediate.sh\n</code></pre> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u2ws/","title":"U2ws","text":"<p> Unit 2 Worksheet - Securing the Network Connection </p>"},{"location":"psc/u2ws/#instructions","title":"Instructions","text":"<p>Fill out this sheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"psc/u2ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://www.sans.org/information-security-policy/</li> <li>https://www.sans.org/blog/the-ultimate-list-of-sans-cheat-sheets/</li> <li>https://docs.rockylinux.org/gemstones/core/view_kernel_conf/</li> <li>https://ciq.com/blog/demystifying-and-troubleshooting-name-resolution-in-rocky-linux/</li> <li>https://www.activeresponse.org/wp-content/uploads/2013/07/diamond.pdf</li> </ul>"},{"location":"psc/u2ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u2_worksheet(<code>.txt</code>)</li> <li>\ud83d\udce5 u2_worksheet(<code>.docx</code>)</li> </ul>"},{"location":"psc/u2ws/#unit-2-recording","title":"Unit 2 Recording","text":""},{"location":"psc/u2ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>There are 401 stigs for RHEL 9. If you filter in your STIG viewer for <code>sysctl</code> there are 33 (mostly network focused), ssh - 39, and network - 58. Now there are some overlaps between those, but review them and answer these questions</p> <ol> <li>As systems engineers why are we focused on protecting the network portion of our    server builds?</li> <li>Why is it important to understand all the possible ingress points to our servers that    exist?</li> <li>Why is it so important to understand the behaviors of processes that are      connecting on those ingress points?</li> </ol>"},{"location":"psc/u2ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Read this: https://ciq.com/blog/demystifying-and-troubleshooting-name-resolution-in-rocky-linux/ or similar blogs on DNS and host file configurations.</p> <ol> <li> <p>What is the significance of the nsswitch.conf file?</p> </li> <li> <p>What are security problems associated with DNS and common exploits? (May have    to look into some more blogs or posts for this)</p> </li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"psc/u2ws/#definitions","title":"Definitions","text":"<p>sysctl:</p> <p>nsswitch.conf:</p> <p>DNS:</p> <p>Openscap:</p> <p>CIS Benchmarks:</p> <p>ss/netstat:</p> <p>tcpdump:</p> <p>ngrep:</p>"},{"location":"psc/u2ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>See if you can find any DNS exploits that have been used and written up in the    diamond model of intrusion analysis format. If you can, what are the primary actors    and actions that made up the attack?</li> </ol>"},{"location":"psc/u2ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you've learned in your current role?</p> </li> </ol>"},{"location":"psc/u3intro/","title":"U3intro","text":"<p> Unit 3 - User Access and System Integration </p>"},{"location":"psc/u3intro/#under-construction","title":"Under Construction","text":""},{"location":"psc/u3intro/#overview","title":"Overview","text":""},{"location":"psc/u3intro/#learning-objectives","title":"Learning Objectives","text":"<p>1. 2. 3.</p>"},{"location":"psc/u3intro/#relevance-and-context","title":"Relevance and Context","text":""},{"location":"psc/u3intro/#prerequisites","title":"Prerequisites","text":"<p>To be successful, students should have a working understanding of skills and tools including:</p> <p>1. 2. 3.</p>"},{"location":"psc/u3intro/#key-terms-and-definitions","title":"Key Terms and Definitions","text":"<p>PAM AD LDAP sssd oddjob krb5 realm/realmd wheel (system group in RHEL)</p>"},{"location":"psc/u3lab/","title":"U3lab","text":"<p> Unit 3 Lab - User Access and System Integration </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u3lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ ) Download the STIG for RHEL 9 and the import it into your STIG viewer Create a checklist from the opened STIG for RHEL 9</p>"},{"location":"psc/u3lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.docx</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u3_lab(<code>.pdf</code>)</li> <li>\ud83d\udce5 u3_lab(<code>.docx</code>)</li> </ul> <p>EXERCISES (Warmup to quickly run through your system and familiarize yourself)</p> <pre><code>ls -l /etc/pam.d/\n# What are the permissions and names of files? Can everyone read them?\n\ncat /etc/pam.d/sshd\n\n# What information do you see in this file?\n# Does any of it look familiar to you?\n</code></pre>"},{"location":"psc/u3lab/#pre-lab-warm-up","title":"Pre-Lab Warm-Up","text":"<p>Download the STIG Viewer 2.18 from - https://public.cyber.mil/stigs/downloads/</p> <p></p> <p>Download the STIG for RHEL 9 and the import it into your STIG viewer</p> <p></p> <p>Create a checklist from the opened STIG for RHEL 9</p> <p></p>"},{"location":"psc/u3lab/#lab","title":"Lab \ud83e\uddea","text":"<p>This lab is designed to have the engineer practice securing a Linux server or service against a set of configuration standards. These standards are sometimes called benchmarks, checklists, or guidelines. The engineer will be using STIG Viewer 2.18 to complete this lab.</p>"},{"location":"psc/u3lab/#pam-configuration","title":"PAM configuration","text":"<p>Connect to a hammer server Filter by pam and see how many STIGS you have. (Why is it really only 16?)</p> <p></p>"},{"location":"psc/u3lab/#examine-stig-v-257986","title":"Examine STIG V-257986","text":"<p>What is the problem? What is the fix? What type of control is being implemented? Is it set properly on your system?</p> <pre><code>grep -i pam /etc/ssh/sshd_config\n</code></pre> <p></p> <p>Can you remediate this finding?</p>"},{"location":"psc/u3lab/#check-and-remediate-stig-v-258055","title":"Check and remediate STIG V-258055","text":"<p>What is the problem? What is the fix? What type of control is being implemented? Are there any major implications to think about with this change on your system? Why or why not? Is it set properly on your system? How would you go about remediating this on your system?</p>"},{"location":"psc/u3lab/#check-and-remediate-stig-v-258098","title":"Check and remediate STIG V-258098","text":"<p>What is the problem? What is the fix? What type of control is being implemented? Is it set properly on your system?</p>"},{"location":"psc/u3lab/#filter-by-password-complexity","title":"Filter by \u201cpassword complexity\u201d","text":"<p>How many are there? What are the password complexity rules? Are there any you haven\u2019t seen before?</p>"},{"location":"psc/u3lab/#filter-by-sssd","title":"Filter by sssd","text":"<p>How many STIGS do you see? What do these STIGS appear to be trying to do? What types of controls are they?</p>"},{"location":"psc/u3lab/#openldap-setup","title":"OpenLDAP Setup","text":"<p>You will likely not build an LDAP server in a real world environment. We are doing it for understanding and ability to complete the lab. In a normal corporate environment this is likely Active Directory.</p> <p>To simplify some of the typing in this lab, there is a file located at <code>/lab_work/identity_and_access_management.tar.gz</code> that you can pull down to your system with the correct <code>.ldif</code> files.</p> <pre><code>[root@hammer1 ~]# cp /lab_work/identity_and_access_management.tar.gz .\n[root@hammer1 ~]# tar -xzvf identity_and_access_management.tar.gz\n</code></pre>"},{"location":"psc/u3lab/#install-and-configure-openldap","title":"Install and configure OpenLDAP","text":""},{"location":"psc/u3lab/#1-stop-the-warewulf-client","title":"1. Stop the warewulf client","text":"<pre><code>[root@hammer1 ~]# systemctl stop wwclient\n</code></pre>"},{"location":"psc/u3lab/#2-edit-your-etchosts-file","title":"2. Edit your /etc/hosts file","text":"<p>Look for and edit the line that has your current server</p> <pre><code>[root@hammer1 ~]# vi /etc/hosts\n</code></pre> <p>Entry for hammer1 for example: <code>192.168.200.151 hammer1 hammer1-default ldap.prolug.lan ldap</code></p>"},{"location":"psc/u3lab/#3-setup-dnf-repo","title":"3. Setup dnf repo","text":"<pre><code>[root@hammer1 ~]# dnf config-manager --set-enabled plus\n[root@hammer1 ~]# dnf repolist\n[root@hammer1 ~]# dnf -y install openldap-servers openldap-clients openldap\n</code></pre>"},{"location":"psc/u3lab/#4-start-slapd-systemctl","title":"4. Start slapd systemctl","text":"<pre><code>[root@hammer1 ~]# systemctl start slapd\n[root@hammer1 ~]# ss -ntulp | grep slapd\n</code></pre>"},{"location":"psc/u3lab/#5-allow-ldap-through-the-firewall","title":"5. Allow ldap through the firewall","text":"<pre><code>[root@hammer1 ~]# firewall-cmd --add-service={ldap,ldaps} --permanent\n[root@hammer1 ~]# firewall-cmd --reload\n[root@hammer1 ~]# firewall-cmd --list-all\n</code></pre>"},{"location":"psc/u3lab/#6-generate-a-password-our-example-uses-testpassword-this-will-return-a-salted-ssha-password-save-this-password-and-salted-hash-for-later-input","title":"6. Generate a password (Our example uses <code>testpassword</code>) This will return a salted SSHA password. Save this password and salted hash for later input","text":"<pre><code>[root@hammer1 ~]# slappasswd\n</code></pre> <p>Output:</p>   New password:   Re-enter new password:   {SSHA}wpRvODvIC/EPYf2GqHUlQMDdsFIW5yig"},{"location":"psc/u3lab/#7-change-the-password","title":"7. Change the password","text":"<pre><code>[root@hammer1 ~]# vi changerootpass.ldif\n</code></pre> <pre><code>dn: olcDatabase={0}config,cn=config\nchangetype: modify\nreplace: olcRootPW\nolcRootPW: {SSHA}vKobSZO1HDGxp2OElzli/xfAzY4jSDMZ\n</code></pre> <pre><code>[root@hammer1 ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f changerootpass.ldif\n</code></pre> <p>Output:</p>   SASL/EXTERNAL authentication started   SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth   SASL SSF: 0   modifying entry \"olcDatabase={0}config,cn=config\""},{"location":"psc/u3lab/#8-generate-basic-schemas","title":"8. Generate basic schemas","text":"<pre><code>ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif\nldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif\nldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif\n</code></pre>"},{"location":"psc/u3lab/#9-set-up-the-domain-use-the-password-you-generated-earlier","title":"9. Set up the domain (USE THE PASSWORD YOU GENERATED EARLIER)","text":"<pre><code>[root@hammer1 ~]# vi setdomain.ldif\n</code></pre> <pre><code>dn: olcDatabase={1}monitor,cn=config\nchangetype: modify\nreplace: olcAccess\nolcAccess: {0}to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\"\nread by dn.base=\"cn=Manager,dc=prolug,dc=lan\" read by * none\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nreplace: olcSuffix\nolcSuffix: dc=prolug,dc=lan\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nreplace: olcRootDN\nolcRootDN: cn=Manager,dc=prolug,dc=lan\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}s4x6uAxcAPZN/4e3pGnU7UEIiADY0/Ob\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nadd: olcAccess\nolcAccess: {0}to attrs=userPassword,shadowLastChange by\ndn=\"cn=Manager,dc=prolug,dc=lan\" write by anonymous auth by self write by * none\nolcAccess: {1}to dn.base=\"\" by * read\nolcAccess: {2}to * by dn=\"cn=Manager,dc=prolug,dc=lan\" write by * read\n</code></pre>"},{"location":"psc/u3lab/#10-run-it","title":"10. Run it","text":"<pre><code>[root@hammer1 ~]# ldapmodify -Y EXTERNAL -H ldapi:/// -f setdomain.ldif\n</code></pre> <p>Output:</p>   SASL/EXTERNAL authentication started   SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth   SASL SSF: 0   modifying entry \"olcDatabase={1}monitor,cn=config\"   modifying entry \"olcDatabase={2}mdb,cn=config\"   modifying entry \"olcDatabase={2}mdb,cn=config\"   modifying entry \"olcDatabase={2}mdb,cn=config\"   modifying entry \"olcDatabase={2}mdb,cn=config\""},{"location":"psc/u3lab/#11-search-and-verify-the-domain-is-working","title":"11. Search and verify the domain is working.","text":"<pre><code>[root@hammer1 ~]# ldapsearch -H ldap:// -x -s base -b \"\" -LLL \"namingContexts\"\n</code></pre> <p>Output:</p>   dn:   namingContexts: dc=prolug,dc=lan"},{"location":"psc/u3lab/#12-add-the-base-group-and-organization","title":"12. Add the base group and organization.","text":"<pre><code>[root@hammer1 ~]# vi addou.ldif\n</code></pre> <pre><code>dn: dc=prolug,dc=lan\nobjectClass: top\nobjectClass: dcObject\nobjectclass: organization\no: My prolug Organisation\ndc: prolug\n\ndn: cn=Manager,dc=prolug,dc=lan\nobjectClass: organizationalRole\ncn: Manager\ndescription: OpenLDAP Manager\n\ndn: ou=People,dc=prolug,dc=lan\nobjectClass: organizationalUnit\nou: People\n\ndn: ou=Group,dc=prolug,dc=lan\nobjectClass: organizationalUnit\nou: Group\n</code></pre> <pre><code>[root@hammer1 ~]# ldapadd -x -D cn=Manager,dc=prolug,dc=lan -W -f addou.ldif\n</code></pre>"},{"location":"psc/u3lab/#13-verifying","title":"13. Verifying","text":"<pre><code>[root@hammer1 ~]# ldapsearch -H ldap:// -x -s base -b \"\" -LLL \"+\"\n[root@hammer1 ~]# ldapsearch -x -b \"dc=prolug,dc=lan\" ou\n</code></pre>"},{"location":"psc/u3lab/#14-add-a-user","title":"14. Add a user","text":"<p>Generate a password (use testuser1234)</p> <pre><code>[root@hammer1 ~]# slappasswd\n</code></pre> <pre><code>[root@hammer1 ~]# vi adduser.ldif\n</code></pre> <pre><code>dn: uid=testuser,ou=People,dc=prolug,dc=lan\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: shadowAccount\ncn: testuser\nsn: temp\nuserPassword: {SSHA}yb6e0ICSdlZaMef3zizvysEzXRGozQOK\nloginShell: /bin/bash\nuidNumber: 15000\ngidNumber: 15000\nhomeDirectory: /home/testuser\nshadowLastChange: 0\nshadowMax: 0\nshadowWarning: 0\n\ndn: cn=testuser,ou=Group,dc=prolug,dc=lan\nobjectClass: posixGroup\ncn: testuser\ngidNumber: 15000\nmemberUid: testuser\n</code></pre> <pre><code>[root@hammer1 ~]# ldapadd -x -D cn=Manager,dc=prolug,dc=lan -W -f adduser.ldif\n</code></pre>"},{"location":"psc/u3lab/#16-verify-that-your-user-is-in-the-system","title":"16. Verify that your user is in the system.","text":"<pre><code>[root@hammer1 ~]# ldapsearch -x -b \"ou=People,dc=prolug,dc=lan\"\n</code></pre>"},{"location":"psc/u3lab/#17-secure-the-system-with-tls-accept-all-defaults","title":"17. Secure the system with TLS (accept all defaults)","text":"<pre><code>[root@hammer1 ~]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/pki/tls/ldapserver.key -out /etc/pki/tls/ldapserver.crt\n[root@hammer1 ~]# chown ldap:ldap /etc/pki/tls/{ldapserver.crt,ldapserver.key}\n</code></pre> <pre><code>[root@hammer1 ~]# ls -l /etc/pki/tls/ldap*\n</code></pre> <p>Output:</p>   -rw-r--r--. 1 ldap ldap 1224 Apr 12 18:23 /etc/pki/tls/ldapserver.crt   -rw-------. 1 ldap ldap 1704 Apr 12 18:22 /etc/pki/tls/ldapserver.key   <pre><code>[root@hammer1 ~]# vi tls.ldif\n</code></pre> <pre><code>dn: cn=config\nchangetype: modify\nadd: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/pki/tls/ldapserver.crt\n\nadd: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/pki/tls/ldapserver.key\n\nadd: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/pki/tls/ldapserver.crt\n</code></pre> <pre><code>[root@hammer1 ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f tls.ldif\n</code></pre>"},{"location":"psc/u3lab/#18-fix-the-etcopenldapldapconf-to-allow-for-certs","title":"18. Fix the /etc/openldap/ldap.conf to allow for certs","text":"<pre><code>[root@hammer1 ~]# vi /etc/openldap/ldap.conf\n</code></pre> <pre><code>#\n# LDAP Defaults\n#\n\n# See ldap.conf(5) for details\n# This file should be world readable but not world writable.\n\n#BASE dc=example,dc=com\n#URI ldap://ldap.example.com ldap://ldap-master.example.com:666\n\n#SIZELIMIT 12\n#TIMELIMIT 15\n#DEREF never\n\n# When no CA certificates are specified the Shared System Certificates\n# are in use. In order to have these available along with the ones specified # by TLS_CACERTDIR one has to include them explicitly:\n\nTLS_CACERT /etc/pki/tls/ldapserver.crt\nTLS_REQCERT never\n\n# System-wide Crypto Policies provide up to date cipher suite which should\n# be used unless one needs a finer grinded selection of ciphers. Hence, the\n# PROFILE=SYSTEM value represents the default behavior which is in place\n# when no explicit setting is used. (see openssl-ciphers(1) for more info)\n#TLS_CIPHER_SUITE PROFILE=SYSTEM\n\n# Turning this off breaks GSSAPI used with krb5 when rdns = false\nSASL_NOCANON on\n</code></pre> <pre><code>[root@hammer1 ~]# systemctl restart slapd\n</code></pre>"},{"location":"psc/u3lab/#sssd-configuration-and-realmd-join-to-ldap","title":"SSSD Configuration and Realmd join to LDAP","text":"<p>SSSD can connect a server to a trusted LDAP system and authenticate users for access to local resources. You will likely do this during your career and it is a valuable skill to work with.</p>"},{"location":"psc/u3lab/#1-install-sssd-configure-and-validate-that-the-user-is-seen-by-the-system","title":"1. Install sssd, configure, and validate that the user is seen by the system","text":"<pre><code>[root@hammer1 ~]# dnf install openldap-clients sssd sssd-ldap oddjob-mkhomedir authselect\n[root@hammer1 ~]# authselect select sssd with-mkhomedir --force\n[root@hammer1 ~]# systemctl enable --now oddjobd.service\n[root@hammer1 ~]# systemctl status oddjobd.service\n</code></pre>"},{"location":"psc/u3lab/#2-uncomment-and-fix-the-lines-in-etcopenldapldapconf","title":"2. Uncomment and fix the lines in /etc/openldap/ldap.conf","text":"<pre><code>[root@hammer1 ~]# vi /etc/openldap/ldap.conf\n</code></pre> <p>Output:</p>   BASE dc=prolug,dc=lan   URI ldap://ldap.ldap.lan/"},{"location":"psc/u3lab/#3-edit-the-sssdconf-file","title":"3. Edit the sssd.conf file","text":"<pre><code>[root@hammer1 ~]# vi /etc/sssd/sssd.conf\n</code></pre> <pre><code>[domain/default]\nid_provider = ldap\nautofs_provider = ldap\nauth_provider = ldap\nchpass_provider = ldap\nldap_uri = ldap://ldap.prolug.lan/\nldap_search_base = dc=prolug,dc=lan\n#ldap_id_use_start_tls = True\n#ldap_tls_cacertdir = /etc/openldap/certs\ncache_credentials = True\n#ldap_tls_reqcert = allow\n\n[sssd]\nservices = nss, pam, autofs\ndomains = default\n\n[nss]\nhomedir_substring = /home\n</code></pre> <pre><code>[root@hammer1 ~]# chmod 0600 /etc/sssd/sssd.conf\n[root@hammer1 ~]# systemctl start sssd\n[root@hammer1 ~]# systemctl status sssd\n</code></pre>"},{"location":"psc/u3lab/#4-validate-that-the-user-can-be-seen","title":"4. Validate that the user can be seen","text":"<pre><code>[root@hammer1 ~]# id testuser\n</code></pre> <p>Output:</p>   uid=15000(testuser) gid=15000 groups=15000   <p>Congratulations! Look at you, doing all the Linux.</p>"},{"location":"psc/u3lab/#please-reboot-the-the-lab-machine-when-done","title":"Please reboot the the lab machine when done.","text":"<pre><code>[root@hammer1 ~]# reboot\n</code></pre>"},{"location":"psc/u3ws/","title":"U3ws","text":"<p> Unit 3 Worksheet - User Access and System Integration </p>"},{"location":"psc/u3ws/#instructions","title":"Instructions","text":"<p>Fill out this sheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"psc/u3ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://www.sans.org/information-security-policy/</li> <li>https://www.sans.org/blog/the-ultimate-list-of-sans-cheat-sheets/</li> <li>https://docs.rockylinux.org/guides/security/pam/</li> <li>https://docs.rockylinux.org/guides/security/authentication/active_directory_authentication/</li> <li>https://docs.rockylinux.org/books/admin_guide/06-users/</li> </ul>"},{"location":"psc/u3ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u3_worksheet(<code>.pdf</code>)</li> <li>\ud83d\udce5 u3_worksheet(<code>.txt</code>)</li> </ul>"},{"location":"psc/u3ws/#unit-3-recording","title":"Unit 3 Recording","text":""},{"location":"psc/u3ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>There are 16 Stigs that involve PAM for RHEL 9. Read the guide from Rocky Linux here: https://docs.rockylinux.org/guides/security/pam/</p> <ol> <li>What are the mechanisms and how do they affect PAM functionality?</li> <li>Review <code>/etc/pam.d/sshd</code> on a Linux system.      What is happening in that file relative to these functionalities?</li> <li>What are the common PAM modules?</li> <li>Review <code>/etc/pam.d/sshd</code> on a Linux system.      What is happening in that file relative to these functionalities?</li> <li>Look for a blog post or article about PAM that discusses real world application.    Post it here and give us a quick synopsis. (Bonus arbitrary points if you find one of our ProLUG members blogs on the subject.)</li> </ol>"},{"location":"psc/u3ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Read about active directory (or LDAP) configurations of Linux via <code>sssd</code> here: https://docs.rockylinux.org/guides/security/authentication/active_directory_authentication</p> <ol> <li>Why do we not want to just use local authentication in Linux? Or really any system?</li> <li>There are 4 SSSD STIGS.</li> <li>What are they?</li> <li>What do they seek to do with the system?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"psc/u3ws/#definitions","title":"Definitions","text":"<p>PAM:</p> <p>AD:</p> <p>LDAP:</p> <p>sssd:</p> <p>oddjob:</p> <p>krb5:</p> <p>realm/realmd:</p> <p>wheel (system group in RHEL):</p>"},{"location":"psc/u3ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li>How does <code>/etc/security/access.conf</code> come into play with pam_access?    Read up on it here: https://man7.org/linux/man-pages/man8/pam_access.8.html</li> <li>Can you find any other good resources?</li> <li>What is the structure of the access.conf file directives?</li> <li>What other important user access or user management information do you learn by    reading this? https://docs.rockylinux.org/books/admin_guide/06-users/</li> <li>What is the contents of the <code>/etc/login.defs</code> file? Why do you care?</li> </ol>"},{"location":"psc/u3ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you've learned in your current role?</p> </li> </ol>"},{"location":"psc/u4intro/","title":"U4intro","text":"<p> Under Construction </p>"},{"location":"psc/u4lab/","title":"U4lab","text":"<p> Unit 4 Lab - Bastions </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u4lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u4lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u4_lab(<code>.pdf</code>)</li> </ul>"},{"location":"psc/u4lab/#prelab","title":"PreLAB","text":"<p>Review lab diagram for the Bastion design.</p> <p></p>"},{"location":"psc/u4lab/#lab","title":"LAB","text":"<p>This lab is designed to have the engineer practice securing a Linux environment by the use of bastion hosts and jailing users as they enter an air-gapped environment.</p>"},{"location":"psc/u4lab/#jailing-a-user","title":"Jailing a User","text":"<ol> <li> <p>Follow the lab here answering the questions below as you progress:    https://killercoda.com/het-tanis/course/Linux-Labs/204-building-a-chroot-jail</p> </li> <li> <p>If you were to write out the high level steps of building a chroot jail, what would they be?</p> </li> <li> <p>Think about what you did in the lab and what extra (or less) you might give a user/process.</p> </li> <li>What directories are needed?</li> <li>What executables might you give the jailed user/process?</li> <li>If you give an executable, why is it important to give the link libraries that it uses?</li> <li>What are the special files that you made with mknod and why must they be there?      (try removing them or redoing the lab without them. How does it break?)</li> </ol>"},{"location":"psc/u4lab/#building-a-bastion","title":"Building a Bastion","text":"<ol> <li> <p>Follow the lab here: https://killercoda.com/het-tanis/course/Linux-Labs/210-building-a-bastion-host</p> </li> <li> <p>If you were to write out the high level steps of building a bastion host, what would they be?</p> </li> <li> <p>When you jump into the bastion host, do you have any options other than the one you have given yourself?</p> </li> <li> <p>How did you test that you couldn\u2019t leave the jailed environment?</p> </li> <li>How effective do you think this is as a technical preventative control against user      breakout in the jail, having a 20 second timeout?</li> </ol>"},{"location":"psc/u4lab/#digging-deeper-challenge-not-required-for-finishing-lab","title":"Digging Deeper challenge (not required for finishing lab)","text":"<ol> <li> <p>Fix the drawing from the lab with excalidraw and properly replace it here:    https://github.com/het-tanis/prolug-labs/tree/main/Linux-Labs/210-building-a-bastion-host</p> </li> <li> <p>Do a pull request and get some github street cred or something.</p> </li> </ol> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u4ws/","title":"U4ws","text":"<p> Unit 4 Worksheet - Bastions and Jailing Users </p>"},{"location":"psc/u4ws/#instructions","title":"Instructions","text":"<p>Fill out this sheet as you progress through the lab and discussions. Hold your worksheets until the end to turn them in as a final submission packet.</p>"},{"location":"psc/u4ws/#resources-important-links","title":"Resources / Important Links","text":"<ul> <li>https://www.sans.org/information-security-policy/</li> <li>https://www.sans.org/blog/the-ultimate-list-of-sans-cheat-sheets/</li> <li>https://aws.amazon.com/search/?searchQuery=air+gapped#facet_type=blogs&amp;page=1</li> <li>https://aws.amazon.com/blogs/security/tag/bastion-host/</li> </ul>"},{"location":"psc/u4ws/#downloads","title":"Downloads","text":"<p>The worksheet has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u4_worksheet(<code>.pdf</code>)</li> <li>\ud83d\udce5 u4_worksheet(<code>.txt</code>)</li> </ul>"},{"location":"psc/u4ws/#unit-3-recording","title":"Unit 3 Recording","text":""},{"location":"psc/u4ws/#discussion-post-1","title":"Discussion Post #1","text":"<p>Review some of the blogs here:</p> <ul> <li> <p>https://aws.amazon.com/search/?searchQuery=air+gapped#facet_type=blogs&amp;page=1</p> </li> <li> <p>https://aws.amazon.com/blogs/security/tag/bastion-host/</p> </li> </ul> <p>Or find some on your own about air-gapped systems.</p> <ol> <li>What seems to be the theme of air-gapped systems?</li> <li>What seems to be their purpose?</li> <li>If you use google, or an AI, what are some of the common themes that come up when    asked about air-gapped or bastion systems?</li> </ol>"},{"location":"psc/u4ws/#discussion-post-2","title":"Discussion Post #2","text":"<p>Do a Google or AI search of topics around jailing a user or processes in Linux.</p> <ol> <li>Can you enumerate the methods of jailing users?</li> <li>Can you think of when you\u2019ve been jailed as a Linux user?    If not, can you think of the useful ways to use a jail?</li> </ol>  Submit your input by following the link below.  The discussion posts are done in Discord threads. Click the 'Threads' icon on the top right and search for the discussion post.   <ul> <li>Link to Discussion Posts</li> </ul>"},{"location":"psc/u4ws/#definitions","title":"Definitions","text":"<p>Air-gapped</p> <p>Bastion</p> <p>Jailed process</p> <p>Isolation</p> <p>Ingress</p> <p>Egress</p> <p>Exfiltration</p> <p>Cgroups</p> <p>Namespaces</p> <ul> <li>Mount</li> <li>PID</li> <li>IPC</li> <li>UTS</li> </ul>"},{"location":"psc/u4ws/#digging-deeper","title":"Digging Deeper","text":"<ol> <li> <p>While this isn\u2019t, strictly speaking, an automation course there is some value in    looking at automation of the bastion deployments. Check out this ansible code: https://github.com/het-tanis/stream_setup/blob/master/roles/bastion_deploy/tasks/main.yml</p> </li> <li> <p>Does the setup make sense to you with our deployment?</p> </li> <li> <p>What can improve and make this better?</p> </li> <li> <p>Find a blog or github where someone else deploys a bastion. Compare it to our    process.</p> </li> <li> <p>Knowing what you now know about bastions, jails, and air-gapped systems. Reflect    on the first 3 weeks, all the STIGs you\u2019ve reviewed and touched. Do any of them    seem moot, or less necessary if applied in an air-gapped environment?</p> </li> <li> <p>Does your answer change if you read about Zero Trust and know how much of a hot      topic that is in the security world now?</p> <ol> <li>Why or why not?</li> </ol> </li> <li> <p>Think of a Linux system where you would like to deploy a bastion (If you cannot think    of one, use ProLUG Lab). Draw out how you think the system works in    excalidraw.com.</p> </li> </ol>"},{"location":"psc/u4ws/#reflection-questions","title":"Reflection Questions","text":"<ol> <li> <p>Does it matter if the user knows that they are jailed? Why or why not?</p> </li> <li> <p>What questions do you still have about this week?</p> </li> <li> <p>How are you going to use what you\u2019ve learned in your current role?</p> </li> </ol>"},{"location":"psc/u5intro/","title":"U5intro","text":"<p> Under Construction </p>"},{"location":"psc/u5lab/","title":"U5lab","text":"<p> Under Construction </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u5lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u5lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u5_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u5_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u5ws/","title":"U5ws","text":"<p> Under Construction </p>"},{"location":"psc/u6intro/","title":"U6intro","text":"<p> Under Construction </p>"},{"location":"psc/u6lab/","title":"U6lab","text":"<p> Under Construction </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u6lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u6lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u6_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u6_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u6ws/","title":"U6ws","text":"<p> Under Construction </p>"},{"location":"psc/u7intro/","title":"U7intro","text":"<p> Under Construction </p>"},{"location":"psc/u7lab/","title":"U7lab","text":"<p> Under Construction </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u7lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u7lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u7_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u7_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u7ws/","title":"U7ws","text":"<p> Under Construction </p>"},{"location":"psc/u8intro/","title":"U8intro","text":"<p> Under Construction </p>"},{"location":"psc/u8lab/","title":"U8lab","text":"<p> Under Construction </p>   If you are unable to finish the lab in the ProLUG lab environment we ask you `reboot` the machine from the command line so that other students will have the intended environment."},{"location":"psc/u8lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u8lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u8_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u8_lab(<code>.docx</code>)</li> </ul>   Be sure to `reboot` the lab machine from the command line when you are done."},{"location":"psc/u8ws/","title":"U8ws","text":"<p> Under Construction </p>"},{"location":"psc/u9intro/","title":"U9intro","text":"<p> Under Construction </p>"},{"location":"psc/u9lab/","title":"U9lab","text":"<p> Under Construction </p> <p>If you are unable to finish the lab in the ProLUG lab environment we ask you <code>reboot</code> the machine from the command line so that other students will have the intended environment.</p>"},{"location":"psc/u9lab/#required-materials","title":"Required Materials","text":"<p>Putty or other connection tool Lab Server</p> <p>Root or sudo command access</p> <p>STIG Viewer 2.18 (download from https://public.cyber.mil/stigs/downloads/ )</p>"},{"location":"psc/u9lab/#downloads","title":"Downloads","text":"<p>The lab has been provided below. The document(s) can be transposed to the desired format so long as the content is preserved. For example, the <code>.txt</code> could be transposed to a <code>.md</code> file.</p> <ul> <li>\ud83d\udce5 u9_lab(<code>.txt</code>)</li> <li>\ud83d\udce5 u9_lab(<code>.docx</code>)</li> </ul> <p>Be sure to <code>reboot</code> the lab machine from the command line when you are done.</p>"},{"location":"psc/u9ws/","title":"U9ws","text":"<p> Under Construction </p>"}]}